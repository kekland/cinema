// Generated file, do not edit.
// Generated by ffigen
// ignore_for_file: camel_case_types, non_constant_identifier_names, unused_element, unused_field, void_checks, annotate_overrides, no_leading_underscores_for_local_identifiers, library_private_types_in_public_api

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
@ffi.DefaultAsset('darwin_bindings')
library;

import 'dart:ffi' as ffi;
import 'package:objective_c/objective_c.dart' as objc;
import 'package:ffi/ffi.dart' as pkg_ffi;

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVMediaTypeVideo')
external final ffi.Pointer<objc.ObjCObject> _AVMediaTypeVideo;

objc.NSString get AVMediaTypeVideo => objc.NSString.castFromPointer(_AVMediaTypeVideo, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVMediaTypeAudio')
external final ffi.Pointer<objc.ObjCObject> _AVMediaTypeAudio;

objc.NSString get AVMediaTypeAudio => objc.NSString.castFromPointer(_AVMediaTypeAudio, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVMediaTypeText')
external final ffi.Pointer<objc.ObjCObject> _AVMediaTypeText;

objc.NSString get AVMediaTypeText => objc.NSString.castFromPointer(_AVMediaTypeText, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVMediaTypeClosedCaption')
external final ffi.Pointer<objc.ObjCObject> _AVMediaTypeClosedCaption;

objc.NSString get AVMediaTypeClosedCaption =>
    objc.NSString.castFromPointer(_AVMediaTypeClosedCaption, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVMediaTypeSubtitle')
external final ffi.Pointer<objc.ObjCObject> _AVMediaTypeSubtitle;

objc.NSString get AVMediaTypeSubtitle =>
    objc.NSString.castFromPointer(_AVMediaTypeSubtitle, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVMediaTypeTimecode')
external final ffi.Pointer<objc.ObjCObject> _AVMediaTypeTimecode;

objc.NSString get AVMediaTypeTimecode =>
    objc.NSString.castFromPointer(_AVMediaTypeTimecode, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVMediaTypeMetadata')
external final ffi.Pointer<objc.ObjCObject> _AVMediaTypeMetadata;

objc.NSString get AVMediaTypeMetadata =>
    objc.NSString.castFromPointer(_AVMediaTypeMetadata, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVMediaTypeMuxed')
external final ffi.Pointer<objc.ObjCObject> _AVMediaTypeMuxed;

objc.NSString get AVMediaTypeMuxed => objc.NSString.castFromPointer(_AVMediaTypeMuxed, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVMediaTypeHaptic')
external final ffi.Pointer<objc.ObjCObject> _AVMediaTypeHaptic;

objc.NSString get AVMediaTypeHaptic => objc.NSString.castFromPointer(_AVMediaTypeHaptic, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeQuickTimeMovie')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeQuickTimeMovie;

objc.NSString get AVFileTypeQuickTimeMovie =>
    objc.NSString.castFromPointer(_AVFileTypeQuickTimeMovie, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeMPEG4')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeMPEG4;

objc.NSString get AVFileTypeMPEG4 => objc.NSString.castFromPointer(_AVFileTypeMPEG4, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeAppleM4V')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeAppleM4V;

objc.NSString get AVFileTypeAppleM4V => objc.NSString.castFromPointer(_AVFileTypeAppleM4V, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeAppleM4A')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeAppleM4A;

objc.NSString get AVFileTypeAppleM4A => objc.NSString.castFromPointer(_AVFileTypeAppleM4A, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileType3GPP')
external final ffi.Pointer<objc.ObjCObject> _AVFileType3GPP;

objc.NSString get AVFileType3GPP => objc.NSString.castFromPointer(_AVFileType3GPP, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileType3GPP2')
external final ffi.Pointer<objc.ObjCObject> _AVFileType3GPP2;

objc.NSString get AVFileType3GPP2 => objc.NSString.castFromPointer(_AVFileType3GPP2, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeCoreAudioFormat')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeCoreAudioFormat;

objc.NSString get AVFileTypeCoreAudioFormat =>
    objc.NSString.castFromPointer(_AVFileTypeCoreAudioFormat, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeWAVE')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeWAVE;

objc.NSString get AVFileTypeWAVE => objc.NSString.castFromPointer(_AVFileTypeWAVE, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeAIFF')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeAIFF;

objc.NSString get AVFileTypeAIFF => objc.NSString.castFromPointer(_AVFileTypeAIFF, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeAIFC')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeAIFC;

objc.NSString get AVFileTypeAIFC => objc.NSString.castFromPointer(_AVFileTypeAIFC, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeAMR')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeAMR;

objc.NSString get AVFileTypeAMR => objc.NSString.castFromPointer(_AVFileTypeAMR, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeMPEGLayer3')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeMPEGLayer3;

objc.NSString get AVFileTypeMPEGLayer3 =>
    objc.NSString.castFromPointer(_AVFileTypeMPEGLayer3, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeSunAU')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeSunAU;

objc.NSString get AVFileTypeSunAU => objc.NSString.castFromPointer(_AVFileTypeSunAU, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeAC3')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeAC3;

objc.NSString get AVFileTypeAC3 => objc.NSString.castFromPointer(_AVFileTypeAC3, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeEnhancedAC3')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeEnhancedAC3;

objc.NSString get AVFileTypeEnhancedAC3 =>
    objc.NSString.castFromPointer(_AVFileTypeEnhancedAC3, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeJPEG')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeJPEG;

objc.NSString get AVFileTypeJPEG => objc.NSString.castFromPointer(_AVFileTypeJPEG, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeDNG')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeDNG;

objc.NSString get AVFileTypeDNG => objc.NSString.castFromPointer(_AVFileTypeDNG, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeHEIC')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeHEIC;

objc.NSString get AVFileTypeHEIC => objc.NSString.castFromPointer(_AVFileTypeHEIC, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeAVCI')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeAVCI;

objc.NSString get AVFileTypeAVCI => objc.NSString.castFromPointer(_AVFileTypeAVCI, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeHEIF')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeHEIF;

objc.NSString get AVFileTypeHEIF => objc.NSString.castFromPointer(_AVFileTypeHEIF, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeTIFF')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeTIFF;

objc.NSString get AVFileTypeTIFF => objc.NSString.castFromPointer(_AVFileTypeTIFF, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeAppleiTT')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeAppleiTT;

objc.NSString get AVFileTypeAppleiTT => objc.NSString.castFromPointer(_AVFileTypeAppleiTT, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeSCC')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeSCC;

objc.NSString get AVFileTypeSCC => objc.NSString.castFromPointer(_AVFileTypeSCC, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVFileTypeAHAP')
external final ffi.Pointer<objc.ObjCObject> _AVFileTypeAHAP;

objc.NSString get AVFileTypeAHAP => objc.NSString.castFromPointer(_AVFileTypeAHAP, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapListenerBlock_pfv6jd(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapBlockingBlock_pfv6jd(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<ffi.Void>)>()
external ffi.Pointer<objc.ObjCObject> _DarwinBindings_protocolTrampoline_1mbt9g9(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
);

@ffi.Native<
  ffi.Long Function(
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
  )
>()
external int _DarwinBindings_protocolTrampoline_qz1oen(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapListenerBlock_1pl9qdv(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapBlockingBlock_1pl9qdv(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapListenerBlock_jk1ljc(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapBlockingBlock_jk1ljc(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapListenerBlock_xtuoz7(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapBlockingBlock_xtuoz7(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCBlockImpl>,
  )
>()
external void _DarwinBindings_protocolTrampoline_jk1ljc(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapListenerBlock_1s56lr9(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapBlockingBlock_1s56lr9(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapListenerBlock_1hznzoi(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapBlockingBlock_1hznzoi(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetLowQuality')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetLowQuality;

objc.NSString get AVAssetExportPresetLowQuality =>
    objc.NSString.castFromPointer(_AVAssetExportPresetLowQuality, retain: true, release: true);

set AVAssetExportPresetLowQuality(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetLowQuality, retain: false, release: true).ref.release();
  _AVAssetExportPresetLowQuality = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetMediumQuality')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetMediumQuality;

objc.NSString get AVAssetExportPresetMediumQuality =>
    objc.NSString.castFromPointer(_AVAssetExportPresetMediumQuality, retain: true, release: true);

set AVAssetExportPresetMediumQuality(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetMediumQuality, retain: false, release: true).ref.release();
  _AVAssetExportPresetMediumQuality = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetHighestQuality')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetHighestQuality;

objc.NSString get AVAssetExportPresetHighestQuality =>
    objc.NSString.castFromPointer(_AVAssetExportPresetHighestQuality, retain: true, release: true);

set AVAssetExportPresetHighestQuality(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetHighestQuality, retain: false, release: true).ref.release();
  _AVAssetExportPresetHighestQuality = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetHEVCHighestQuality')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetHEVCHighestQuality;

objc.NSString get AVAssetExportPresetHEVCHighestQuality =>
    objc.NSString.castFromPointer(_AVAssetExportPresetHEVCHighestQuality, retain: true, release: true);

set AVAssetExportPresetHEVCHighestQuality(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetHEVCHighestQuality, retain: false, release: true).ref.release();
  _AVAssetExportPresetHEVCHighestQuality = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetHEVCHighestQualityWithAlpha')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetHEVCHighestQualityWithAlpha;

objc.NSString get AVAssetExportPresetHEVCHighestQualityWithAlpha =>
    objc.NSString.castFromPointer(_AVAssetExportPresetHEVCHighestQualityWithAlpha, retain: true, release: true);

set AVAssetExportPresetHEVCHighestQualityWithAlpha(objc.NSString value) {
  objc.NSString.castFromPointer(
    _AVAssetExportPresetHEVCHighestQualityWithAlpha,
    retain: false,
    release: true,
  ).ref.release();
  _AVAssetExportPresetHEVCHighestQualityWithAlpha = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPreset640x480')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPreset640x480;

objc.NSString get AVAssetExportPreset640x480 =>
    objc.NSString.castFromPointer(_AVAssetExportPreset640x480, retain: true, release: true);

set AVAssetExportPreset640x480(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPreset640x480, retain: false, release: true).ref.release();
  _AVAssetExportPreset640x480 = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPreset960x540')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPreset960x540;

objc.NSString get AVAssetExportPreset960x540 =>
    objc.NSString.castFromPointer(_AVAssetExportPreset960x540, retain: true, release: true);

set AVAssetExportPreset960x540(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPreset960x540, retain: false, release: true).ref.release();
  _AVAssetExportPreset960x540 = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPreset1280x720')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPreset1280x720;

objc.NSString get AVAssetExportPreset1280x720 =>
    objc.NSString.castFromPointer(_AVAssetExportPreset1280x720, retain: true, release: true);

set AVAssetExportPreset1280x720(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPreset1280x720, retain: false, release: true).ref.release();
  _AVAssetExportPreset1280x720 = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPreset1920x1080')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPreset1920x1080;

objc.NSString get AVAssetExportPreset1920x1080 =>
    objc.NSString.castFromPointer(_AVAssetExportPreset1920x1080, retain: true, release: true);

set AVAssetExportPreset1920x1080(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPreset1920x1080, retain: false, release: true).ref.release();
  _AVAssetExportPreset1920x1080 = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPreset3840x2160')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPreset3840x2160;

objc.NSString get AVAssetExportPreset3840x2160 =>
    objc.NSString.castFromPointer(_AVAssetExportPreset3840x2160, retain: true, release: true);

set AVAssetExportPreset3840x2160(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPreset3840x2160, retain: false, release: true).ref.release();
  _AVAssetExportPreset3840x2160 = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetHEVC1920x1080')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetHEVC1920x1080;

objc.NSString get AVAssetExportPresetHEVC1920x1080 =>
    objc.NSString.castFromPointer(_AVAssetExportPresetHEVC1920x1080, retain: true, release: true);

set AVAssetExportPresetHEVC1920x1080(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetHEVC1920x1080, retain: false, release: true).ref.release();
  _AVAssetExportPresetHEVC1920x1080 = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetHEVC1920x1080WithAlpha')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetHEVC1920x1080WithAlpha;

objc.NSString get AVAssetExportPresetHEVC1920x1080WithAlpha =>
    objc.NSString.castFromPointer(_AVAssetExportPresetHEVC1920x1080WithAlpha, retain: true, release: true);

set AVAssetExportPresetHEVC1920x1080WithAlpha(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetHEVC1920x1080WithAlpha, retain: false, release: true).ref.release();
  _AVAssetExportPresetHEVC1920x1080WithAlpha = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetHEVC3840x2160')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetHEVC3840x2160;

objc.NSString get AVAssetExportPresetHEVC3840x2160 =>
    objc.NSString.castFromPointer(_AVAssetExportPresetHEVC3840x2160, retain: true, release: true);

set AVAssetExportPresetHEVC3840x2160(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetHEVC3840x2160, retain: false, release: true).ref.release();
  _AVAssetExportPresetHEVC3840x2160 = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetHEVC3840x2160WithAlpha')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetHEVC3840x2160WithAlpha;

objc.NSString get AVAssetExportPresetHEVC3840x2160WithAlpha =>
    objc.NSString.castFromPointer(_AVAssetExportPresetHEVC3840x2160WithAlpha, retain: true, release: true);

set AVAssetExportPresetHEVC3840x2160WithAlpha(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetHEVC3840x2160WithAlpha, retain: false, release: true).ref.release();
  _AVAssetExportPresetHEVC3840x2160WithAlpha = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetHEVC7680x4320')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetHEVC7680x4320;

objc.NSString get AVAssetExportPresetHEVC7680x4320 =>
    objc.NSString.castFromPointer(_AVAssetExportPresetHEVC7680x4320, retain: true, release: true);

set AVAssetExportPresetHEVC7680x4320(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetHEVC7680x4320, retain: false, release: true).ref.release();
  _AVAssetExportPresetHEVC7680x4320 = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetMVHEVC960x960')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetMVHEVC960x960;

objc.NSString get AVAssetExportPresetMVHEVC960x960 =>
    objc.NSString.castFromPointer(_AVAssetExportPresetMVHEVC960x960, retain: true, release: true);

set AVAssetExportPresetMVHEVC960x960(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetMVHEVC960x960, retain: false, release: true).ref.release();
  _AVAssetExportPresetMVHEVC960x960 = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetMVHEVC1440x1440')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetMVHEVC1440x1440;

objc.NSString get AVAssetExportPresetMVHEVC1440x1440 =>
    objc.NSString.castFromPointer(_AVAssetExportPresetMVHEVC1440x1440, retain: true, release: true);

set AVAssetExportPresetMVHEVC1440x1440(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetMVHEVC1440x1440, retain: false, release: true).ref.release();
  _AVAssetExportPresetMVHEVC1440x1440 = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetAppleM4A')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetAppleM4A;

objc.NSString get AVAssetExportPresetAppleM4A =>
    objc.NSString.castFromPointer(_AVAssetExportPresetAppleM4A, retain: true, release: true);

set AVAssetExportPresetAppleM4A(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetAppleM4A, retain: false, release: true).ref.release();
  _AVAssetExportPresetAppleM4A = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetPassthrough')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetPassthrough;

objc.NSString get AVAssetExportPresetPassthrough =>
    objc.NSString.castFromPointer(_AVAssetExportPresetPassthrough, retain: true, release: true);

set AVAssetExportPresetPassthrough(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetPassthrough, retain: false, release: true).ref.release();
  _AVAssetExportPresetPassthrough = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetAppleProRes422LPCM')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetAppleProRes422LPCM;

objc.NSString get AVAssetExportPresetAppleProRes422LPCM =>
    objc.NSString.castFromPointer(_AVAssetExportPresetAppleProRes422LPCM, retain: true, release: true);

set AVAssetExportPresetAppleProRes422LPCM(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetAppleProRes422LPCM, retain: false, release: true).ref.release();
  _AVAssetExportPresetAppleProRes422LPCM = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAssetExportPresetAppleProRes4444LPCM')
external ffi.Pointer<objc.ObjCObject> _AVAssetExportPresetAppleProRes4444LPCM;

objc.NSString get AVAssetExportPresetAppleProRes4444LPCM =>
    objc.NSString.castFromPointer(_AVAssetExportPresetAppleProRes4444LPCM, retain: true, release: true);

set AVAssetExportPresetAppleProRes4444LPCM(objc.NSString value) {
  objc.NSString.castFromPointer(_AVAssetExportPresetAppleProRes4444LPCM, retain: false, release: true).ref.release();
  _AVAssetExportPresetAppleProRes4444LPCM = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapListenerBlock_fgo1sw(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapBlockingBlock_fgo1sw(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapListenerBlock_mpxix1(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinBindings_wrapBlockingBlock_mpxix1(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

final class CGAffineTransform extends ffi.Struct {
  @ffi.Double()
  external double a;

  @ffi.Double()
  external double b;

  @ffi.Double()
  external double c;

  @ffi.Double()
  external double d;

  @ffi.Double()
  external double tx;

  @ffi.Double()
  external double ty;
}

enum AVKeyValueStatus {
  AVKeyValueStatusUnknown(0),
  AVKeyValueStatusLoading(1),
  AVKeyValueStatusLoaded(2),
  AVKeyValueStatusFailed(3),
  AVKeyValueStatusCancelled(4);

  final int value;
  const AVKeyValueStatus(this.value);

  static AVKeyValueStatus fromValue(int value) => switch (value) {
    0 => AVKeyValueStatusUnknown,
    1 => AVKeyValueStatusLoading,
    2 => AVKeyValueStatusLoaded,
    3 => AVKeyValueStatusFailed,
    4 => AVKeyValueStatusCancelled,
    _ => throw ArgumentError('Unknown value for AVKeyValueStatus: $value'),
  };
}

/// WARNING: AVAsynchronousKeyValueLoading is a stub. To generate bindings for this class, include
/// AVAsynchronousKeyValueLoading in your config's objc-protocols list.
///
/// AVAsynchronousKeyValueLoading
interface class AVAsynchronousKeyValueLoading extends objc.ObjCProtocolBase {
  AVAsynchronousKeyValueLoading._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVAsynchronousKeyValueLoading] that points to the same underlying object as [other].
  AVAsynchronousKeyValueLoading.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAsynchronousKeyValueLoading] that wraps the given raw object pointer.
  AVAsynchronousKeyValueLoading.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

enum CMTimeFlags {
  kCMTimeFlags_Valid(1),
  kCMTimeFlags_HasBeenRounded(2),
  kCMTimeFlags_PositiveInfinity(4),
  kCMTimeFlags_NegativeInfinity(8),
  kCMTimeFlags_Indefinite(16),
  kCMTimeFlags_ImpliedValueFlagsMask(28);

  final int value;
  const CMTimeFlags(this.value);

  static CMTimeFlags fromValue(int value) => switch (value) {
    1 => kCMTimeFlags_Valid,
    2 => kCMTimeFlags_HasBeenRounded,
    4 => kCMTimeFlags_PositiveInfinity,
    8 => kCMTimeFlags_NegativeInfinity,
    16 => kCMTimeFlags_Indefinite,
    28 => kCMTimeFlags_ImpliedValueFlagsMask,
    _ => throw ArgumentError('Unknown value for CMTimeFlags: $value'),
  };
}

@ffi.Packed(4)
final class CMTime extends ffi.Struct {
  @ffi.Int64()
  external int value;

  @ffi.Int32()
  external int timescale;

  @ffi.Uint32()
  external int flagsAsInt;

  CMTimeFlags get flags => CMTimeFlags.fromValue(flagsAsInt);

  @ffi.Int64()
  external int epoch;
}

late final _class_AVAsset = objc.getClass("AVAsset");
late final _sel_isKindOfClass_ = objc.registerName("isKindOfClass:");
final _objc_msgSend_19nvye5 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCObject>)
      >
    >()
    .asFunction<
      bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCObject>)
    >();
late final _sel_providesPreciseDurationAndTiming = objc.registerName("providesPreciseDurationAndTiming");
final _objc_msgSend_91o635 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_cancelLoading = objc.registerName("cancelLoading");
final _objc_msgSend_1pl9qdv = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVAssetAsynchronousLoading
extension AVAssetAsynchronousLoading on AVAsset {
  /// providesPreciseDurationAndTiming
  bool get providesPreciseDurationAndTiming {
    objc.checkOsVersionInternal(
      'AVAsset.providesPreciseDurationAndTiming',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_providesPreciseDurationAndTiming);
  }

  /// !
  /// @method		cancelLoading
  /// @abstract		Cancels the loading of all values for all observers.
  /// @discussion	Deallocation or finalization of an instance of AVAsset will implicitly cancel loading if any loading requests are still outstanding.
  void cancelLoading() {
    objc.checkOsVersionInternal('AVAsset.cancelLoading', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_cancelLoading);
  }
}

/// !
/// @enum			AVAssetReferenceRestrictions
/// @abstract		These constants can be passed in to AVURLAssetReferenceRestrictionsKey to control the resolution of references to external media data.
///
/// @constant		AVAssetReferenceRestrictionForbidNone
/// Indicates that all types of references should be followed.
/// @constant		AVAssetReferenceRestrictionForbidRemoteReferenceToLocal
/// Indicates that references from a remote asset (e.g. referenced via http URL) to local media data (e.g. stored in a local file) should not be followed.
/// @constant		AVAssetReferenceRestrictionForbidLocalReferenceToRemote
/// Indicates that references from a local asset to remote media data should not be followed.
/// @constant		AVAssetReferenceRestrictionForbidCrossSiteReference
/// Indicates that references from a remote asset to remote media data stored at a different site should not be followed.
/// @constant		AVAssetReferenceRestrictionForbidLocalReferenceToLocal
/// Indicates that references from a local asset to local media data stored outside the asset's container file should not be followed.
/// @constant		AVAssetReferenceRestrictionForbidAll
/// Indicates that only references to media data stored within the asset's container file should be allowed.
enum AVAssetReferenceRestrictions {
  AVAssetReferenceRestrictionForbidNone(0),
  AVAssetReferenceRestrictionForbidRemoteReferenceToLocal(1),
  AVAssetReferenceRestrictionForbidLocalReferenceToRemote(2),
  AVAssetReferenceRestrictionForbidCrossSiteReference(4),
  AVAssetReferenceRestrictionForbidLocalReferenceToLocal(8),
  AVAssetReferenceRestrictionForbidAll(65535);

  static const AVAssetReferenceRestrictionDefaultPolicy = AVAssetReferenceRestrictionForbidLocalReferenceToRemote;

  final int value;
  const AVAssetReferenceRestrictions(this.value);

  static AVAssetReferenceRestrictions fromValue(int value) => switch (value) {
    0 => AVAssetReferenceRestrictionForbidNone,
    1 => AVAssetReferenceRestrictionForbidRemoteReferenceToLocal,
    2 => AVAssetReferenceRestrictionForbidLocalReferenceToRemote,
    4 => AVAssetReferenceRestrictionForbidCrossSiteReference,
    8 => AVAssetReferenceRestrictionForbidLocalReferenceToLocal,
    65535 => AVAssetReferenceRestrictionForbidAll,
    _ => throw ArgumentError('Unknown value for AVAssetReferenceRestrictions: $value'),
  };

  @override
  String toString() {
    if (this == AVAssetReferenceRestrictionForbidLocalReferenceToRemote)
      return "AVAssetReferenceRestrictions.AVAssetReferenceRestrictionForbidLocalReferenceToRemote, AVAssetReferenceRestrictions.AVAssetReferenceRestrictionDefaultPolicy";
    return super.toString();
  }
}

late final _sel_referenceRestrictions = objc.registerName("referenceRestrictions");
final _objc_msgSend_1m7g6j8 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVAssetReferenceRestrictions
extension AVAssetReferenceRestrictions$1 on AVAsset {
  /// !
  /// @property		referenceRestrictions
  /// @abstract		Indicates the reference restrictions being used by the receiver.
  /// @discussion
  /// For AVURLAsset, this property reflects the value passed in for AVURLAssetReferenceRestrictionsKey, if any. See AVURLAssetReferenceRestrictionsKey below for a full discussion of reference restrictions. The default value for this property is AVAssetReferenceRestrictionForbidLocalReferenceToRemote.
  AVAssetReferenceRestrictions get referenceRestrictions {
    objc.checkOsVersionInternal('AVAsset.referenceRestrictions', iOS: (false, (5, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1m7g6j8(this.ref.pointer, _sel_referenceRestrictions);
    return AVAssetReferenceRestrictions.fromValue(_ret);
  }
}

late final _sel_tracks = objc.registerName("tracks");
final _objc_msgSend_151sglz = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// WARNING: AVAssetTrack is a stub. To generate bindings for this class, include
/// AVAssetTrack in your config's objc-interfaces list.
///
/// !
/// @class		AVAsset
///
/// @abstract
/// An AVAsset is an abstract class that defines AVFoundation's model for timed audiovisual media.
///
/// Each asset contains a collection of tracks that are intended to be presented or processed together, each of a uniform media type, including but not limited to audio, video, text, closed captions, and subtitles.
///
/// @discussion
/// AVAssets are often instantiated via its concrete subclass AVURLAsset with NSURLs that refer to audiovisual media resources, such as streams (including HTTP live streams), QuickTime movie files, MP3 files, and files of other types.
///
/// They can also be instantiated using other concrete subclasses that extend the basic model for audiovisual media in useful ways, as AVComposition does for temporal editing.
///
/// Properties of assets as a whole are defined by AVAsset. Additionally, references to instances of AVAssetTracks representing tracks of the collection can be obtained, so that each of these can be examined independently.
///
/// Because of the nature of timed audiovisual media, upon successful initialization of an AVAsset some or all of the values for its keys may not be immediately available. The value of any key can be requested at any time, and AVAsset will always return its value synchronously, although it may have to block the calling thread in order to do so.
///
/// In order to avoid blocking, clients can register their interest in particular keys and to become notified when their values become available. For further details, see AVAsynchronousKeyValueLoading.h. For clients who want to examine a subset of the tracks, metadata, and other parts of the asset, asynchronous methods like -loadTracksWithMediaType:completionHandler: can be used to load this information without blocking. When using these asynchronous methods, it is not necessary to load the associated property beforehand. Swift clients can also use the load(:) method to load properties in a type safe manner.
///
/// On platforms other than macOS, it is particularly important to avoid blocking.  To preserve responsiveness, a synchronous request that blocks for too long (eg, a property request on an asset on a slow HTTP server) may lead to media services being reset.
///
/// To play an instance of AVAsset, initialize an instance of AVPlayerItem with it, use the AVPlayerItem to set up its presentation state (such as whether only a limited timeRange of the asset should be played, etc.), and provide the AVPlayerItem to an AVPlayer according to whether the items is to be played by itself or together with a collection of other items. Full details available in AVPlayerItem.h and AVPlayer.h.
///
/// AVAssets can also be inserted into AVMutableCompositions in order to assemble audiovisual constructs from one or more source assets.
class AVAssetTrack extends objc.ObjCObjectBase {
  AVAssetTrack._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVAssetTrack] that points to the same underlying object as [other].
  AVAssetTrack.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAssetTrack] that wraps the given raw object pointer.
  AVAssetTrack.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_trackWithTrackID_ = objc.registerName("trackWithTrackID:");
final _objc_msgSend_aclumu = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Int32)
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)
    >();
void _ObjCBlock_ffiVoid_AVAssetTrack_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_AVAssetTrack_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_AVAssetTrack_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
  arg0,
  arg1,
);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_AVAssetTrack_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_AVAssetTrack_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
    arg0,
    arg1,
  );
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_AVAssetTrack_NSError_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
      arg0,
      arg1,
    );
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.listener(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_AVAssetTrack_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>
    >
    ptr,
  ) => objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> fromFunction(
    void Function(AVAssetTrack, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVAssetTrack_NSError_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVAssetTrack.castFromPointer(arg0, retain: true, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: true, release: true),
      ),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> listener(
    void Function(AVAssetTrack, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVAssetTrack_NSError_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVAssetTrack.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_pfv6jd(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> blocking(
    void Function(AVAssetTrack, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVAssetTrack.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVAssetTrack.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_pfv6jd(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>`.
extension ObjCBlock_ffiVoid_AVAssetTrack_NSError_CallExtension
    on objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> {
  void call(AVAssetTrack arg0, objc.NSError? arg1) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl> block,
            ffi.Pointer<objc.ObjCObject> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
          )
        >
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0.ref.pointer, arg1?.ref.pointer ?? ffi.nullptr);
}

late final _sel_loadTrackWithTrackID_completionHandler_ = objc.registerName("loadTrackWithTrackID:completionHandler:");
final _objc_msgSend_vhb0ih = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Int32,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int, ffi.Pointer<objc.ObjCBlockImpl>)
    >();
late final _sel_tracksWithMediaType_ = objc.registerName("tracksWithMediaType:");
final _objc_msgSend_1sotr3r = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
void _ObjCBlock_ffiVoid_NSArray_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSArray_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_NSArray_NSError_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_NSArray_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
  arg0,
  arg1,
);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSArray_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_NSArray_NSError_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_NSArray_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
    arg0,
    arg1,
  );
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_NSArray_NSError_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_NSArray_NSError_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_NSArray_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
      arg0,
      arg1,
    );
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_NSArray_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_NSArray_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_NSArray_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.listener(_ObjCBlock_ffiVoid_NSArray_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_NSArray_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>
    >
    ptr,
  ) => objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_NSArray_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> fromFunction(
    void Function(objc.NSArray?, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_NSError_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSArray.castFromPointer(arg0, retain: true, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: true, release: true),
      ),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> listener(
    void Function(objc.NSArray?, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_NSError_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSArray.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_pfv6jd(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> blocking(
    void Function(objc.NSArray?, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_NSError_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSArray.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_NSError_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSArray.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_pfv6jd(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>`.
extension ObjCBlock_ffiVoid_NSArray_NSError_CallExtension
    on objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> {
  void call(objc.NSArray? arg0, objc.NSError? arg1) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl> block,
            ffi.Pointer<objc.ObjCObject> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
          )
        >
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0?.ref.pointer ?? ffi.nullptr, arg1?.ref.pointer ?? ffi.nullptr);
}

late final _sel_loadTracksWithMediaType_completionHandler_ = objc.registerName(
  "loadTracksWithMediaType:completionHandler:",
);
final _objc_msgSend_o762yo = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_tracksWithMediaCharacteristic_ = objc.registerName("tracksWithMediaCharacteristic:");
late final _sel_loadTracksWithMediaCharacteristic_completionHandler_ = objc.registerName(
  "loadTracksWithMediaCharacteristic:completionHandler:",
);
late final _sel_trackGroups = objc.registerName("trackGroups");

/// AVAssetTrackInspection
extension AVAssetTrackInspection on AVAsset {
  /// !
  /// @property		tracks
  /// @abstract		Provides the array of AVAssetTracks contained by the asset
  objc.NSArray get tracks {
    objc.checkOsVersionInternal('AVAsset.tracks', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_tracks);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		trackWithTrackID:
  /// @abstract		Provides an instance of AVAssetTrack that represents the track of the specified trackID.
  /// @param		trackID
  /// The trackID of the requested AVAssetTrack.
  /// @result		An instance of AVAssetTrack; may be nil if no track of the specified trackID is available.
  /// @discussion	Becomes callable without blocking when the key @"tracks" has been loaded
  AVAssetTrack? trackWithTrackID(int trackID) {
    objc.checkOsVersionInternal('AVAsset.trackWithTrackID:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_aclumu(this.ref.pointer, _sel_trackWithTrackID_, trackID);
    return _ret.address == 0 ? null : AVAssetTrack.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadTrackWithTrackID:completionHandler:
  /// @abstract		Loads an instance of AVAssetTrack that represents the track of the specified trackID.
  /// @param		trackID
  /// The trackID of the requested AVAssetTrack.
  /// @param		completionHandler
  /// A block that is called when the loading is finished, with either the loaded track (which may be nil if no track of the specified trackID is available) or an error.
  void loadTrackWithTrackID(
    int trackID, {
    required objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadTrackWithTrackID:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_vhb0ih(
      this.ref.pointer,
      _sel_loadTrackWithTrackID_completionHandler_,
      trackID,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @method		tracksWithMediaType:
  /// @abstract		Provides an array of AVAssetTracks of the asset that present media of the specified media type.
  /// @param		mediaType
  /// The media type according to which AVAsset filters its AVAssetTracks. (Media types are defined in AVMediaFormat.h.)
  /// @result		An NSArray of AVAssetTracks; may be empty if no tracks of the specified media type are available.
  /// @discussion	Becomes callable without blocking when the key @"tracks" has been loaded
  objc.NSArray tracksWithMediaType(objc.NSString mediaType) {
    objc.checkOsVersionInternal('AVAsset.tracksWithMediaType:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.pointer, _sel_tracksWithMediaType_, mediaType.ref.pointer);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadTracksWithMediaType:completionHandler:
  /// @abstract		Loads an array of AVAssetTracks of the asset that present media of the specified media type.
  /// @param		mediaType
  /// The media type according to which AVAsset filters its AVAssetTracks. (Media types are defined in AVMediaFormat.h.)
  /// @param		completionHandler
  /// A block that is called when the loading is finished, with either the loaded tracks (which may be empty if no tracks of the specified media type are available) or an error.
  void loadTracksWithMediaType(
    objc.NSString mediaType, {
    required objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadTracksWithMediaType:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadTracksWithMediaType_completionHandler_,
      mediaType.ref.pointer,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @method		tracksWithMediaCharacteristic:
  /// @abstract		Provides an array of AVAssetTracks of the asset that present media with the specified characteristic.
  /// @param		mediaCharacteristic
  /// The media characteristic according to which AVAsset filters its AVAssetTracks. (Media characteristics are defined in AVMediaFormat.h.)
  /// @result		An NSArray of AVAssetTracks; may be empty if no tracks with the specified characteristic are available.
  /// @discussion	Becomes callable without blocking when the key @"tracks" has been loaded
  objc.NSArray tracksWithMediaCharacteristic(objc.NSString mediaCharacteristic) {
    objc.checkOsVersionInternal(
      'AVAsset.tracksWithMediaCharacteristic:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_tracksWithMediaCharacteristic_,
      mediaCharacteristic.ref.pointer,
    );
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadTracksWithMediaCharacteristic:completionHandler:
  /// @abstract		Loads an array of AVAssetTracks of the asset that present media with the specified characteristic.
  /// @param		mediaCharacteristic
  /// The media characteristic according to which AVAsset filters its AVAssetTracks. (Media characteristics are defined in AVMediaFormat.h.)
  /// @param		completionHandler
  /// A block that is called when the loading is finished, with either the loaded tracks (which may be empty if no tracks with the specified characteristic are available) or an error.
  void loadTracksWithMediaCharacteristic(
    objc.NSString mediaCharacteristic, {
    required objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadTracksWithMediaCharacteristic:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadTracksWithMediaCharacteristic_completionHandler_,
      mediaCharacteristic.ref.pointer,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @property trackGroups
  /// @abstract
  /// All track groups in the receiver.
  ///
  /// @discussion
  /// The value of this property is an NSArray of AVAssetTrackGroups, each representing a different grouping of tracks in the receiver.
  objc.NSArray get trackGroups {
    objc.checkOsVersionInternal('AVAsset.trackGroups', iOS: (false, (7, 0, 0)), macOS: (false, (10, 9, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_trackGroups);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVMetadataItem is a stub. To generate bindings for this class, include
/// AVMetadataItem in your config's objc-interfaces list.
///
/// AVMetadataItem
class AVMetadataItem extends objc.ObjCObjectBase {
  AVMetadataItem._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMetadataItem] that points to the same underlying object as [other].
  AVMetadataItem.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMetadataItem] that wraps the given raw object pointer.
  AVMetadataItem.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_creationDate = objc.registerName("creationDate");
late final _sel_lyrics = objc.registerName("lyrics");
late final _sel_commonMetadata = objc.registerName("commonMetadata");
late final _sel_metadata = objc.registerName("metadata");
late final _sel_availableMetadataFormats = objc.registerName("availableMetadataFormats");
late final _sel_metadataForFormat_ = objc.registerName("metadataForFormat:");
late final _sel_loadMetadataForFormat_completionHandler_ = objc.registerName(
  "loadMetadataForFormat:completionHandler:",
);

/// AVAssetMetadataReading
extension AVAssetMetadataReading on AVAsset {
  /// creationDate
  AVMetadataItem? get creationDate {
    objc.checkOsVersionInternal('AVAsset.creationDate', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_creationDate);
    return _ret.address == 0 ? null : AVMetadataItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// lyrics
  objc.NSString? get lyrics {
    objc.checkOsVersionInternal('AVAsset.lyrics', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_lyrics);
    return _ret.address == 0 ? null : objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// commonMetadata
  objc.NSArray get commonMetadata {
    objc.checkOsVersionInternal('AVAsset.commonMetadata', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_commonMetadata);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// metadata
  objc.NSArray get metadata {
    objc.checkOsVersionInternal('AVAsset.metadata', iOS: (false, (8, 0, 0)), macOS: (false, (10, 10, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_metadata);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// availableMetadataFormats
  objc.NSArray get availableMetadataFormats {
    objc.checkOsVersionInternal(
      'AVAsset.availableMetadataFormats',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_availableMetadataFormats);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		metadataForFormat:
  /// @abstract		Provides an NSArray of AVMetadataItems, one for each metadata item in the container of the specified format; can subsequently be filtered according to language via +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:], according to locale via +[AVMetadataItem metadataItemsFromArray:withLocale:], or according to key via +[AVMetadataItem metadataItemsFromArray:withKey:keySpace:].
  /// @param		format
  /// The metadata format for which items are requested.
  /// @result		An NSArray containing AVMetadataItems; may be empty if there is no metadata of the specified format.
  /// @discussion	Becomes callable without blocking when the key @"availableMetadataFormats" has been loaded
  objc.NSArray metadataForFormat(objc.NSString format) {
    objc.checkOsVersionInternal('AVAsset.metadataForFormat:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.pointer, _sel_metadataForFormat_, format.ref.pointer);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadMetadataForFormat:completionHandler:
  /// @abstract		Loads an NSArray of AVMetadataItems, one for each metadata item in the container of the specified format; can subsequently be filtered according to language via +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:], according to locale via +[AVMetadataItem metadataItemsFromArray:withLocale:], or according to key via +[AVMetadataItem metadataItemsFromArray:withKey:keySpace:].
  /// @param		format
  /// The metadata format for which items are requested.
  /// @param		completionHandler
  /// A block that is invoked when loading is complete, vending the array of metadata items (which may be empty if there is no metadata of the specified format) or an error.
  void loadMetadataForFormat(
    objc.NSString format, {
    required objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadMetadataForFormat:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadMetadataForFormat_completionHandler_,
      format.ref.pointer,
      completionHandler.ref.pointer,
    );
  }
}

late final _sel_availableChapterLocales = objc.registerName("availableChapterLocales");
late final _sel_chapterMetadataGroupsWithTitleLocale_containingItemsWithCommonKeys_ = objc.registerName(
  "chapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:",
);
final _objc_msgSend_15qeuct = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
late final _sel_loadChapterMetadataGroupsWithTitleLocale_containingItemsWithCommonKeys_completionHandler_ = objc
    .registerName("loadChapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:completionHandler:");
final _objc_msgSend_18qun1e = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_chapterMetadataGroupsBestMatchingPreferredLanguages_ = objc.registerName(
  "chapterMetadataGroupsBestMatchingPreferredLanguages:",
);
late final _sel_loadChapterMetadataGroupsBestMatchingPreferredLanguages_completionHandler_ = objc.registerName(
  "loadChapterMetadataGroupsBestMatchingPreferredLanguages:completionHandler:",
);

/// AVAssetChapterInspection
extension AVAssetChapterInspection on AVAsset {
  /// availableChapterLocales
  objc.NSArray get availableChapterLocales {
    objc.checkOsVersionInternal('AVAsset.availableChapterLocales', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_availableChapterLocales);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		chapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:
  /// @abstract		Provides an array of chapters.
  /// @param		locale
  /// Locale of the metadata items carrying chapter titles to be returned (supports the IETF BCP 47 specification).
  /// @param		commonKeys
  /// Array of common keys of AVMetadataItem to be included; can be nil.
  /// AVMetadataCommonKeyArtwork is the only supported key for now.
  /// @result		An NSArray of AVTimedMetadataGroup.
  /// @discussion
  /// This method returns an array of AVTimedMetadataGroup objects. Each object in the array always contains an AVMetadataItem representing the chapter title; the timeRange property of the AVTimedMetadataGroup object is equal to the time range of the chapter title item.
  ///
  /// An AVMetadataItem with the specified common key will be added to an existing AVTimedMetadataGroup object if the time range (timestamp and duration) of the metadata item and the metadata group overlaps. The locale of items not carrying chapter titles need not match the specified locale parameter.
  ///
  /// Further filtering of the metadata items in AVTimedMetadataGroups according to language can be accomplished using +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:]; filtering of the metadata items according to locale can be accomplished using +[AVMetadataItem metadataItemsFromArray:withLocale:].
  objc.NSArray chapterMetadataGroupsWithTitleLocale(
    objc.NSLocale locale, {
    objc.NSArray? containingItemsWithCommonKeys,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.chapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:',
      iOS: (false, (4, 3, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_15qeuct(
      this.ref.pointer,
      _sel_chapterMetadataGroupsWithTitleLocale_containingItemsWithCommonKeys_,
      locale.ref.pointer,
      containingItemsWithCommonKeys?.ref.pointer ?? ffi.nullptr,
    );
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadChapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:completionHandler:
  /// @abstract		Loads an array of chapters.
  /// @param		locale
  /// Locale of the metadata items carrying chapter titles to be returned (supports the IETF BCP 47 specification).
  /// @param		commonKeys
  /// Array of common keys of AVMetadataItem to be included; if no common keys are required, send an empty list.
  /// AVMetadataCommonKeyArtwork is the only supported key for now.
  /// @param		completionHandler
  /// A block that is invoked when loading is complete, vending the array of timed metadata groups or an error.
  /// @discussion
  /// This method vends an array of AVTimedMetadataGroup objects. Each object in the array always contains an AVMetadataItem representing the chapter title; the timeRange property of the AVTimedMetadataGroup object is equal to the time range of the chapter title item.
  ///
  /// An AVMetadataItem with the specified common key will be added to an existing AVTimedMetadataGroup object if the time range (timestamp and duration) of the metadata item and the metadata group overlaps. The locale of items not carrying chapter titles need not match the specified locale parameter.
  ///
  /// Further filtering of the metadata items in AVTimedMetadataGroups according to language can be accomplished using +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:]; filtering of the metadata items according to locale can be accomplished using +[AVMetadataItem metadataItemsFromArray:withLocale:].
  void loadChapterMetadataGroupsWithTitleLocale(
    objc.NSLocale locale, {
    required objc.NSArray containingItemsWithCommonKeys,
    required objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadChapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_18qun1e(
      this.ref.pointer,
      _sel_loadChapterMetadataGroupsWithTitleLocale_containingItemsWithCommonKeys_completionHandler_,
      locale.ref.pointer,
      containingItemsWithCommonKeys.ref.pointer,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @method		chapterMetadataGroupsBestMatchingPreferredLanguages:
  /// @abstract		Tests, in order of preference, for a match between language identifiers in the specified array of preferred languages and the available chapter locales, and returns the array of chapters corresponding to the first match that's found.
  /// @param			preferredLanguages
  /// An array of language identifiers in order of preference, each of which is an IETF BCP 47 (RFC 4646) language identifier. Use +[NSLocale preferredLanguages] to obtain the user's list of preferred languages.
  /// @result		An NSArray of AVTimedMetadataGroup.
  /// @discussion
  /// Safe to call without blocking when the AVAsset key availableChapterLocales has status AVKeyValueStatusLoaded.
  ///
  /// Returns an array of AVTimedMetadataGroup objects. Each object in the array always contains an AVMetadataItem representing the chapter title; the timeRange property of the AVTimedMetadataGroup object is equal to the time range of the chapter title item.
  ///
  /// All of the available chapter metadata is included in the metadata groups, including items with the common key AVMetadataCommonKeyArtwork, if such items are present. Items not carrying chapter titles will be added to an existing AVTimedMetadataGroup object if the time range (timestamp and duration) of the metadata item and that of the metadata group overlaps. The locale of such items need not match the locale of the chapter titles.
  ///
  /// Further filtering of the metadata items in AVTimedMetadataGroups according to language can be accomplished using +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:]; filtering of the metadata items according to locale can be accomplished using +[AVMetadataItem metadataItemsFromArray:withLocale:].
  /// .
  objc.NSArray chapterMetadataGroupsBestMatchingPreferredLanguages(objc.NSArray preferredLanguages) {
    objc.checkOsVersionInternal(
      'AVAsset.chapterMetadataGroupsBestMatchingPreferredLanguages:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_chapterMetadataGroupsBestMatchingPreferredLanguages_,
      preferredLanguages.ref.pointer,
    );
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadChapterMetadataGroupsBestMatchingPreferredLanguages:completionHandler:
  /// @abstract		Tests, in order of preference, for a match between language identifiers in the specified array of preferred languages and the available chapter locales, and loads the array of chapters corresponding to the first match that's found.
  /// @param			preferredLanguages
  /// An array of language identifiers in order of preference, each of which is an IETF BCP 47 (RFC 4646) language identifier. Use +[NSLocale preferredLanguages] to obtain the user's list of preferred languages.
  /// @param			completionHandler
  /// A block that is invoked when loading is complete, vending the array of timed metadata groups or an error.
  /// @discussion
  /// Returns an array of AVTimedMetadataGroup objects. Each object in the array always contains an AVMetadataItem representing the chapter title; the timeRange property of the AVTimedMetadataGroup object is equal to the time range of the chapter title item.
  ///
  /// All of the available chapter metadata is included in the metadata groups, including items with the common key AVMetadataCommonKeyArtwork, if such items are present. Items not carrying chapter titles will be added to an existing AVTimedMetadataGroup object if the time range (timestamp and duration) of the metadata item and that of the metadata group overlaps. The locale of such items need not match the locale of the chapter titles.
  ///
  /// Further filtering of the metadata items in AVTimedMetadataGroups according to language can be accomplished using +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:]; filtering of the metadata items according to locale can be accomplished using +[AVMetadataItem metadataItemsFromArray:withLocale:].
  void loadChapterMetadataGroupsBestMatchingPreferredLanguages(
    objc.NSArray preferredLanguages, {
    required objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadChapterMetadataGroupsBestMatchingPreferredLanguages:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadChapterMetadataGroupsBestMatchingPreferredLanguages_completionHandler_,
      preferredLanguages.ref.pointer,
      completionHandler.ref.pointer,
    );
  }
}

late final _sel_availableMediaCharacteristicsWithMediaSelectionOptions = objc.registerName(
  "availableMediaCharacteristicsWithMediaSelectionOptions",
);

/// WARNING: AVMediaSelectionGroup is a stub. To generate bindings for this class, include
/// AVMediaSelectionGroup in your config's objc-interfaces list.
///
/// AVMediaSelectionGroup
class AVMediaSelectionGroup extends objc.ObjCObjectBase {
  AVMediaSelectionGroup._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMediaSelectionGroup] that points to the same underlying object as [other].
  AVMediaSelectionGroup.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMediaSelectionGroup] that wraps the given raw object pointer.
  AVMediaSelectionGroup.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_mediaSelectionGroupForMediaCharacteristic_ = objc.registerName(
  "mediaSelectionGroupForMediaCharacteristic:",
);
void _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
  arg0,
  arg1,
);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
    arg0,
    arg1,
  );
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
      arg0,
      arg1,
    );
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.listener(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>(
    pointer,
    retain: retain,
    release: release,
  );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>
    >
    ptr,
  ) => objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> fromFunction(
    void Function(AVMediaSelectionGroup, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVMediaSelectionGroup.castFromPointer(arg0, retain: true, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: true, release: true),
      ),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> listener(
    void Function(AVMediaSelectionGroup, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVMediaSelectionGroup.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_pfv6jd(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>(
      wrapper,
      retain: false,
      release: true,
    );
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> blocking(
    void Function(AVMediaSelectionGroup, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVMediaSelectionGroup.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVMediaSelectionGroup.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_pfv6jd(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>(
      wrapper,
      retain: false,
      release: true,
    );
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>`.
extension ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_CallExtension
    on objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> {
  void call(AVMediaSelectionGroup arg0, objc.NSError? arg1) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl> block,
            ffi.Pointer<objc.ObjCObject> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
          )
        >
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0.ref.pointer, arg1?.ref.pointer ?? ffi.nullptr);
}

late final _sel_loadMediaSelectionGroupForMediaCharacteristic_completionHandler_ = objc.registerName(
  "loadMediaSelectionGroupForMediaCharacteristic:completionHandler:",
);

/// WARNING: AVMediaSelection is a stub. To generate bindings for this class, include
/// AVMediaSelection in your config's objc-interfaces list.
///
/// AVMediaSelection
class AVMediaSelection extends objc.ObjCObjectBase {
  AVMediaSelection._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMediaSelection] that points to the same underlying object as [other].
  AVMediaSelection.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMediaSelection] that wraps the given raw object pointer.
  AVMediaSelection.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_preferredMediaSelection = objc.registerName("preferredMediaSelection");
late final _sel_allMediaSelections = objc.registerName("allMediaSelections");

/// AVAssetMediaSelection
extension AVAssetMediaSelection on AVAsset {
  /// availableMediaCharacteristicsWithMediaSelectionOptions
  objc.NSArray get availableMediaCharacteristicsWithMediaSelectionOptions {
    objc.checkOsVersionInternal(
      'AVAsset.availableMediaCharacteristicsWithMediaSelectionOptions',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_availableMediaCharacteristicsWithMediaSelectionOptions);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		mediaSelectionGroupForMediaCharacteristic:
  /// @abstract		Provides an instance of AVMediaSelectionGroup that contains one or more options with the specified media characteristic.
  /// @param		mediaCharacteristic
  /// A media characteristic for which you wish to obtain the available media selection options. AVMediaCharacteristicAudible, AVMediaCharacteristicLegible, and AVMediaCharacteristicVisual are currently supported.
  ///
  /// Pass AVMediaCharacteristicAudible to obtain the group of available options for audio media in various languages and for various purposes, such as descriptive audio.
  /// Pass AVMediaCharacteristicLegible to obtain the group of available options for subtitles in various languages and for various purposes.
  /// Pass AVMediaCharacteristicVisual to obtain the group of available options for video media.
  /// @result		An instance of AVMediaSelectionGroup. May be nil.
  /// @discussion
  /// Becomes callable without blocking when the key @"availableMediaCharacteristicsWithMediaSelectionOptions" has been loaded.
  ///
  /// If the asset has no AVMediaSelectionGroup containing options with the specified media characteristic, the return value will be nil.
  ///
  /// Filtering of the options in the returned AVMediaSelectionGroup according to playability, locale, and additional media characteristics can be accomplished using the category AVMediaSelectionOptionFiltering defined on AVMediaSelectionGroup.
  AVMediaSelectionGroup? mediaSelectionGroupForMediaCharacteristic(objc.NSString mediaCharacteristic) {
    objc.checkOsVersionInternal(
      'AVAsset.mediaSelectionGroupForMediaCharacteristic:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_mediaSelectionGroupForMediaCharacteristic_,
      mediaCharacteristic.ref.pointer,
    );
    return _ret.address == 0 ? null : AVMediaSelectionGroup.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadMediaSelectionGroupForMediaCharacteristic:completionHandler:
  /// @abstract		Loads an instance of AVMediaSelectionGroup that contains one or more options with the specified media characteristic.
  /// @param		mediaCharacteristic
  /// A media characteristic for which you wish to obtain the available media selection options. AVMediaCharacteristicAudible, AVMediaCharacteristicLegible, and AVMediaCharacteristicVisual are currently supported.
  ///
  /// Pass AVMediaCharacteristicAudible to obtain the group of available options for audio media in various languages and for various purposes, such as descriptive audio.
  /// Pass AVMediaCharacteristicLegible to obtain the group of available options for subtitles in various languages and for various purposes.
  /// Pass AVMediaCharacteristicVisual to obtain the group of available options for video media.
  /// @param		completionHandler
  /// A block that is invoked when loading is complete, vending an instance of AVMediaSelectionGroup (which may be nil) or an error.
  /// @discussion
  /// If the asset has no AVMediaSelectionGroup containing options with the specified media characteristic, the return value will be nil.
  ///
  /// Filtering of the options in the returned AVMediaSelectionGroup according to playability, locale, and additional media characteristics can be accomplished using the category AVMediaSelectionOptionFiltering defined on AVMediaSelectionGroup.
  void loadMediaSelectionGroupForMediaCharacteristic(
    objc.NSString mediaCharacteristic, {
    required objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadMediaSelectionGroupForMediaCharacteristic:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadMediaSelectionGroupForMediaCharacteristic_completionHandler_,
      mediaCharacteristic.ref.pointer,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @property		preferredMediaSelection
  /// @abstract		Provides an instance of AVMediaSelection with default selections for each of the receiver's media selection groups.
  AVMediaSelection get preferredMediaSelection {
    objc.checkOsVersionInternal(
      'AVAsset.preferredMediaSelection',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_preferredMediaSelection);
    return AVMediaSelection.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property		allMediaSelections
  /// @abstract		Provides an array of all permutations of AVMediaSelection for this asset.
  objc.NSArray get allMediaSelections {
    objc.checkOsVersionInternal('AVAsset.allMediaSelections', iOS: (false, (11, 0, 0)), macOS: (false, (10, 13, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_allMediaSelections);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

late final _sel_hasProtectedContent = objc.registerName("hasProtectedContent");

/// AVAssetProtectedContent
extension AVAssetProtectedContent on AVAsset {
  /// !
  /// @property		hasProtectedContent
  /// @abstract		Indicates whether or not the asset has protected content.
  /// @discussion	Assets containing protected content may not be playable without successful authorization, even if the value of the "playable" property is YES.  See the properties in the AVAssetUsability category for details on how such an asset may be used.  On macOS, clients can use the interfaces in AVPlayerItemProtectedContentAdditions.h to request authorization to play the asset.
  bool get hasProtectedContent {
    objc.checkOsVersionInternal('AVAsset.hasProtectedContent', iOS: (false, (4, 2, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_hasProtectedContent);
  }
}

late final _sel_canContainFragments = objc.registerName("canContainFragments");
late final _sel_containsFragments = objc.registerName("containsFragments");
late final _sel_overallDurationHint = objc.registerName("overallDurationHint");
final _objc_msgSend_1f8hvjs = objc.msgSendPointer
    .cast<ffi.NativeFunction<CMTime Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<CMTime Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_1f8hvjsStret = objc.msgSendStretPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<CMTime>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<void Function(ffi.Pointer<CMTime>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVAssetFragments
extension AVAssetFragments on AVAsset {
  /// !
  /// @property		canContainFragments
  /// @abstract		Indicates whether the asset is capable of being extended by fragments.
  /// @discussion	For QuickTime movie files and MPEG-4 files, the value of canContainFragments is YES if an 'mvex' box is present in the 'moov' box. For those types, the 'mvex' box signals the possible presence of later 'moof' boxes.
  bool get canContainFragments {
    objc.checkOsVersionInternal('AVAsset.canContainFragments', iOS: (false, (9, 0, 0)), macOS: (false, (10, 11, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canContainFragments);
  }

  /// !
  /// @property		containsFragments
  /// @abstract		Indicates whether the asset is extended by at least one fragment.
  /// @discussion	For QuickTime movie files and MPEG-4 files, the value of this property is YES if canContainFragments is YES and at least one 'moof' box is present after the 'moov' box.
  bool get containsFragments {
    objc.checkOsVersionInternal('AVAsset.containsFragments', iOS: (false, (9, 0, 0)), macOS: (false, (10, 11, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_containsFragments);
  }

  /// !
  /// @property		overallDurationHint
  /// @abstract		Indicates the total duration of fragments that either exist now or may be appended in the future in order to extend the duration of the asset.
  /// @discussion	For QuickTime movie files and MPEG-4 files, the value of this property is obtained from the 'mehd' box of the 'mvex' box, if present. If no total fragment duration hint is available, the value of this property is kCMTimeInvalid.
  CMTime get overallDurationHint {
    objc.checkOsVersionInternal('AVAsset.overallDurationHint', iOS: (false, (10, 2, 0)), macOS: (false, (10, 12, 2)));
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_overallDurationHint)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_overallDurationHint);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }
}

late final _sel_isPlayable = objc.registerName("isPlayable");
late final _sel_isExportable = objc.registerName("isExportable");
late final _sel_isReadable = objc.registerName("isReadable");
late final _sel_isComposable = objc.registerName("isComposable");
late final _sel_isCompatibleWithSavedPhotosAlbum = objc.registerName("isCompatibleWithSavedPhotosAlbum");
late final _sel_isCompatibleWithAirPlayVideo = objc.registerName("isCompatibleWithAirPlayVideo");

/// AVAssetUsability
extension AVAssetUsability on AVAsset {
  /// !
  /// @property		playable
  /// @abstract		Indicates whether an AVPlayer can play the contents of the asset in a manner that meets user expectations.
  /// @discussion	A client can attempt playback when playable is NO, this however may lead to a substandard playback experience.
  bool get playable {
    objc.checkOsVersionInternal('AVAsset.isPlayable', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isPlayable);
  }

  /// isExportable
  bool get exportable {
    objc.checkOsVersionInternal('AVAsset.isExportable', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isExportable);
  }

  /// isReadable
  bool get readable {
    objc.checkOsVersionInternal('AVAsset.isReadable', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isReadable);
  }

  /// isComposable
  bool get composable {
    objc.checkOsVersionInternal('AVAsset.isComposable', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isComposable);
  }

  /// isCompatibleWithSavedPhotosAlbum
  bool get compatibleWithSavedPhotosAlbum {
    objc.checkOsVersionInternal(
      'AVAsset.isCompatibleWithSavedPhotosAlbum',
      iOS: (false, (5, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isCompatibleWithSavedPhotosAlbum);
  }

  /// !
  /// @property		compatibleWithAirPlayVideo
  /// @abstract		Indicates whether the asset is compatible with AirPlay Video.
  /// @discussion	YES if an AVPlayerItem initialized with the receiver can be played by an external device via AirPlay Video.
  bool get compatibleWithAirPlayVideo {
    objc.checkOsVersionInternal(
      'AVAsset.isCompatibleWithAirPlayVideo',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isCompatibleWithAirPlayVideo);
  }
}

typedef instancetype = ffi.Pointer<objc.ObjCObject>;
typedef Dartinstancetype = objc.ObjCObjectBase;
late final _sel_assetWithURL_ = objc.registerName("assetWithURL:");
late final _sel_duration = objc.registerName("duration");
late final _sel_preferredRate = objc.registerName("preferredRate");
final _objc_msgSend_2cgrxl = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Float Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_2cgrxlFpret = objc.msgSendFpretPointer
    .cast<ffi.NativeFunction<ffi.Float Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_preferredVolume = objc.registerName("preferredVolume");
late final _sel_preferredTransform = objc.registerName("preferredTransform");
final _objc_msgSend_5qswvj = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<CGAffineTransform Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>
    >()
    .asFunction<CGAffineTransform Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_5qswvjStret = objc.msgSendStretPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<CGAffineTransform>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<CGAffineTransform>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
    >();
late final _sel_naturalSize = objc.registerName("naturalSize");
final _objc_msgSend_1vdfken = objc.msgSendPointer
    .cast<ffi.NativeFunction<objc.CGSize Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<objc.CGSize Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_1vdfkenStret = objc.msgSendStretPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.CGSize>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.CGSize>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
    >();

/// WARNING: AVDisplayCriteria is a stub. To generate bindings for this class, include
/// AVDisplayCriteria in your config's objc-interfaces list.
///
/// AVDisplayCriteria
class AVDisplayCriteria extends objc.ObjCObjectBase {
  AVDisplayCriteria._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVDisplayCriteria] that points to the same underlying object as [other].
  AVDisplayCriteria.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVDisplayCriteria] that wraps the given raw object pointer.
  AVDisplayCriteria.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_preferredDisplayCriteria = objc.registerName("preferredDisplayCriteria");
late final _sel_minimumTimeOffsetFromLive = objc.registerName("minimumTimeOffsetFromLive");
late final _sel_init = objc.registerName("init");
late final _sel_new = objc.registerName("new");
late final _sel_allocWithZone_ = objc.registerName("allocWithZone:");
final _objc_msgSend_1cwp428 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.NSZone>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.NSZone>,
      )
    >();
late final _sel_alloc = objc.registerName("alloc");
late final _sel_self = objc.registerName("self");
ffi.Pointer<objc.ObjCObject> _ObjCBlock_objcObjCObject_ffiVoid_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void> arg0)>>()
    .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_objcObjCObject_ffiVoid_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)
        >(_ObjCBlock_objcObjCObject_ffiVoid_fnPtrTrampoline)
        .cast();
ffi.Pointer<objc.ObjCObject> _ObjCBlock_objcObjCObject_ffiVoid_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
) => (objc.getBlockClosure(block) as ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_objcObjCObject_ffiVoid_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)
        >(_ObjCBlock_objcObjCObject_ffiVoid_closureTrampoline)
        .cast();

/// Construction methods for `objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>`.
abstract final class ObjCBlock_objcObjCObject_ffiVoid {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>(
    pointer,
    retain: retain,
    release: release,
  );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void> arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>(
    objc.newPointerBlock(_ObjCBlock_objcObjCObject_ffiVoid_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)> fromFunction(
    objc.ObjCObjectBase Function(ffi.Pointer<ffi.Void>) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>(
    objc.newClosureBlock(
      _ObjCBlock_objcObjCObject_ffiVoid_closureCallable,
      (ffi.Pointer<ffi.Void> arg0) => fn(arg0).ref.retainAndAutorelease(),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>`.
extension ObjCBlock_objcObjCObject_ffiVoid_CallExtension
    on objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)> {
  objc.ObjCObjectBase call(ffi.Pointer<ffi.Void> arg0) => objc.ObjCObjectBase(
    ref.pointer.ref.invoke
        .cast<
          ffi.NativeFunction<
            ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<ffi.Void> arg0)
          >
        >()
        .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>()(
      ref.pointer,
      arg0,
    ),
    retain: true,
    release: true,
  );
}

late final _sel_retain = objc.registerName("retain");
late final _sel_autorelease = objc.registerName("autorelease");
late final _sel_statusOfValueForKey_error_ = objc.registerName("statusOfValueForKey:error:");
final _objc_msgSend_n4q2pj = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Long Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      int Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
int _ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
) => block.ref.target
    .cast<
      ffi.NativeFunction<
        ffi.Long Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
        )
      >
    >()
    .asFunction<
      int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
    >()(arg0, arg1, arg2);
ffi.Pointer<ffi.Void> _ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Long Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
          )
        >(_ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_fnPtrTrampoline, 0)
        .cast();
int _ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
) =>
    (objc.getBlockClosure(block)
        as int Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        ))(arg0, arg1, arg2);
ffi.Pointer<ffi.Void> _ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Long Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
          )
        >(_ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_closureTrampoline, 0)
        .cast();

/// Construction methods for `objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)>`.
abstract final class ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<
    ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
  >
  castFromPointer(ffi.Pointer<objc.ObjCBlockImpl> pointer, {bool retain = false, bool release = false}) =>
      objc.ObjCBlock<
        ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
      >(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<
    ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
  >
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Long Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
        )
      >
    >
    ptr,
  ) =>
      objc.ObjCBlock<
        ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
      >(
        objc.newPointerBlock(_ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_fnPtrCallable, ptr.cast()),
        retain: false,
        release: true,
      );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<
    ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
  >
  fromFunction(
    AVKeyValueStatus Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>) fn, {
    bool keepIsolateAlive = true,
  }) =>
      objc.ObjCBlock<
        ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
      >(
        objc.newClosureBlock(
          _ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_closureCallable,
          (
            ffi.Pointer<ffi.Void> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
          ) => fn(arg0, objc.NSString.castFromPointer(arg1, retain: true, release: true), arg2).value,
          keepIsolateAlive,
        ),
        retain: false,
        release: true,
      );
}

/// Call operator for `objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)>`.
extension ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_CallExtension
    on
        objc.ObjCBlock<
          ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
        > {
  AVKeyValueStatus call(
    ffi.Pointer<ffi.Void> arg0,
    objc.NSString arg1,
    ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
  ) => AVKeyValueStatus.fromValue(
    ref.pointer.ref.invoke
        .cast<
          ffi.NativeFunction<
            ffi.Long Function(
              ffi.Pointer<objc.ObjCBlockImpl> block,
              ffi.Pointer<ffi.Void> arg0,
              ffi.Pointer<objc.ObjCObject> arg1,
              ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
            )
          >
        >()
        .asFunction<
          int Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
          )
        >()(ref.pointer, arg0, arg1.ref.pointer, arg2),
  );
}

void _ObjCBlock_ffiVoid_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
) => block.ref.target.cast<ffi.NativeFunction<ffi.Void Function()>>().asFunction<void Function()>()();
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>)>(
      _ObjCBlock_ffiVoid_fnPtrTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
) => (objc.getBlockClosure(block) as void Function())();
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_closureCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>)>(
      _ObjCBlock_ffiVoid_closureTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
) {
  (objc.getBlockClosure(block) as void Function())();
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>)> _ObjCBlock_ffiVoid_listenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>)>.listener(
      _ObjCBlock_ffiVoid_listenerTrampoline,
    )..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_blockingTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<ffi.Void> waiter) {
  try {
    (objc.getBlockClosure(block) as void Function())();
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>
_ObjCBlock_ffiVoid_blockingCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>.isolateLocal(
      _ObjCBlock_ffiVoid_blockingTrampoline,
    )..keepIsolateAlive = false;
ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>
_ObjCBlock_ffiVoid_blockingListenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>.listener(
      _ObjCBlock_ffiVoid_blockingTrampoline,
    )..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function()>`.
abstract final class ObjCBlock_ffiVoid {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function()> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function()>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function()> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function()>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function()>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function()> fromFunction(void Function() fn, {bool keepIsolateAlive = true}) =>
      objc.ObjCBlock<ffi.Void Function()>(
        objc.newClosureBlock(_ObjCBlock_ffiVoid_closureCallable, () => fn(), keepIsolateAlive),
        retain: false,
        release: true,
      );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function()> listener(void Function() fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_listenerCallable.nativeFunction.cast(),
      () => fn(),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_1pl9qdv(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function()>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function()> blocking(void Function() fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_blockingCallable.nativeFunction.cast(),
      () => fn(),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_blockingListenerCallable.nativeFunction.cast(),
      () => fn(),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_1pl9qdv(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function()>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function()>`.
extension ObjCBlock_ffiVoid_CallExtension on objc.ObjCBlock<ffi.Void Function()> {
  void call() =>
      ref.pointer.ref.invoke
          .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block)>>()
          .asFunction<void Function(ffi.Pointer<objc.ObjCBlockImpl>)>()(
        ref.pointer,
      );
}

late final _sel_loadValuesAsynchronouslyForKeys_completionHandler_ = objc.registerName(
  "loadValuesAsynchronouslyForKeys:completionHandler:",
);
void _ObjCBlock_ffiVoid_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>(
      _ObjCBlock_ffiVoid_NSError_fnPtrTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSError_closureCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>(
      _ObjCBlock_ffiVoid_NSError_closureTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>))(arg0);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>
_ObjCBlock_ffiVoid_NSError_listenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>.listener(
      _ObjCBlock_ffiVoid_NSError_listenerTrampoline,
    )..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<objc.ObjCObject> arg0,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>))(arg0);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
      >.isolateLocal(_ObjCBlock_ffiVoid_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSError?)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function(objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSError?)> fromFunction(
    void Function(objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSError_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0) =>
          fn(arg0.address == 0 ? null : objc.NSError.castFromPointer(arg0, retain: true, release: true)),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSError?)> listener(
    void Function(objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSError_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0) =>
          fn(arg0.address == 0 ? null : objc.NSError.castFromPointer(arg0, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_xtuoz7(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSError?)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(objc.NSError?)> blocking(
    void Function(objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSError_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0) =>
          fn(arg0.address == 0 ? null : objc.NSError.castFromPointer(arg0, retain: false, release: true)),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSError_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0) =>
          fn(arg0.address == 0 ? null : objc.NSError.castFromPointer(arg0, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_xtuoz7(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSError?)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(objc.NSError?)>`.
extension ObjCBlock_ffiVoid_NSError_CallExtension on objc.ObjCBlock<ffi.Void Function(objc.NSError?)> {
  void call(objc.NSError? arg0) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<objc.ObjCObject> arg0)>
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0?.ref.pointer ?? ffi.nullptr);
}

void _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
) => block.ref.target
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCBlockImpl> arg2,
        )
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCBlockImpl>)
    >()(arg0, arg1, arg2);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCBlockImpl>,
          )
        >(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
) =>
    (objc.getBlockClosure(block)
        as void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCBlockImpl>))(
      arg0,
      arg1,
      arg2,
    );
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCBlockImpl>,
          )
        >(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
) {
  (objc.getBlockClosure(block)
      as void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCBlockImpl>))(
    arg0,
    arg1,
    arg2,
  );
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCBlockImpl>,
  )
>
_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >.listener(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
) {
  try {
    (objc.getBlockClosure(block)
        as void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCBlockImpl>))(
      arg0,
      arg1,
      arg2,
    );
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCBlockImpl>,
  )
>
_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCBlockImpl>,
  )
>
_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >.listener(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>`.
abstract final class ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>
  castFromPointer(ffi.Pointer<objc.ObjCBlockImpl> pointer, {bool retain = false, bool release = false}) =>
      objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>(
        pointer,
        retain: retain,
        release: release,
      );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCBlockImpl> arg2,
        )
      >
    >
    ptr,
  ) => objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>
  fromFunction(
    void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_closureCallable,
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCBlockImpl> arg2) => fn(
        arg0,
        objc.NSArray.castFromPointer(arg1, retain: true, release: true),
        arg2.address == 0 ? null : ObjCBlock_ffiVoid.castFromPointer(arg2, retain: true, release: true),
      ),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>
  listener(
    void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCBlockImpl> arg2) => fn(
        arg0,
        objc.NSArray.castFromPointer(arg1, retain: false, release: true),
        arg2.address == 0 ? null : ObjCBlock_ffiVoid.castFromPointer(arg2, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_jk1ljc(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>(
      wrapper,
      retain: false,
      release: true,
    );
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>
  blocking(
    void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCBlockImpl> arg2) => fn(
        arg0,
        objc.NSArray.castFromPointer(arg1, retain: false, release: true),
        arg2.address == 0 ? null : ObjCBlock_ffiVoid.castFromPointer(arg2, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCBlockImpl> arg2) => fn(
        arg0,
        objc.NSArray.castFromPointer(arg1, retain: false, release: true),
        arg2.address == 0 ? null : ObjCBlock_ffiVoid.castFromPointer(arg2, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_jk1ljc(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>(
      wrapper,
      retain: false,
      release: true,
    );
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>`.
extension ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_CallExtension
    on objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)> {
  void call(ffi.Pointer<ffi.Void> arg0, objc.NSArray arg1, objc.ObjCBlock<ffi.Void Function()>? arg2) => ref
      .pointer
      .ref
      .invoke
      .cast<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl> block,
            ffi.Pointer<ffi.Void> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
            ffi.Pointer<objc.ObjCBlockImpl> arg2,
          )
        >
      >()
      .asFunction<
        void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >()(ref.pointer, arg0, arg1.ref.pointer, arg2?.ref.pointer ?? ffi.nullptr);
}

/// AVAsset
class AVAsset extends objc.NSObject implements objc.NSCopying, AVAsynchronousKeyValueLoading {
  AVAsset._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVAsset', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVAsset] that points to the same underlying object as [other].
  AVAsset.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAsset] that wraps the given raw object pointer.
  AVAsset.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [AVAsset].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_AVAsset);
  }

  /// !
  /// @method		assetWithURL:
  /// @abstract		Returns an instance of AVAsset for inspection of a media resource.
  /// @param		URL
  /// An instance of NSURL that references a media resource.
  /// @result		An instance of AVAsset.
  /// @discussion	Returns a newly allocated instance of a subclass of AVAsset initialized with the specified URL.
  static AVAsset assetWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVAsset.assetWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(_class_AVAsset, _sel_assetWithURL_, URL.ref.pointer);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// duration
  CMTime get duration {
    objc.checkOsVersionInternal('AVAsset.duration', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_duration)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_duration);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// preferredRate
  double get preferredRate {
    objc.checkOsVersionInternal('AVAsset.preferredRate', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_preferredRate)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_preferredRate);
  }

  /// preferredVolume
  double get preferredVolume {
    objc.checkOsVersionInternal('AVAsset.preferredVolume', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_preferredVolume)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_preferredVolume);
  }

  /// preferredTransform
  CGAffineTransform get preferredTransform {
    objc.checkOsVersionInternal('AVAsset.preferredTransform', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CGAffineTransform>();
    objc.useMsgSendVariants
        ? _objc_msgSend_5qswvjStret(_ptr, this.ref.pointer, _sel_preferredTransform)
        : _ptr.ref = _objc_msgSend_5qswvj(this.ref.pointer, _sel_preferredTransform);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<CGAffineTransform>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<CGAffineTransform>(_finalizable);
  }

  /// naturalSize
  objc.CGSize get naturalSize {
    objc.checkOsVersionInternal('AVAsset.naturalSize', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<objc.CGSize>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1vdfkenStret(_ptr, this.ref.pointer, _sel_naturalSize)
        : _ptr.ref = _objc_msgSend_1vdfken(this.ref.pointer, _sel_naturalSize);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGSize>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGSize>(_finalizable);
  }

  /// !
  /// @property	preferredDisplayCriteria
  /// @abstract	Guides to a display mode that is optimal for playing this particular asset.
  AVDisplayCriteria get preferredDisplayCriteria {
    objc.checkOsVersionInternal('AVAsset.preferredDisplayCriteria', iOS: (true, null), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_preferredDisplayCriteria);
    return AVDisplayCriteria.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property		minimumTimeOffsetFromLive
  /// @abstract		Indicates how close to the latest content in a live stream playback can be sustained.
  /// @discussion	For non-live assets this value is kCMTimeInvalid.
  CMTime get minimumTimeOffsetFromLive {
    objc.checkOsVersionInternal(
      'AVAsset.minimumTimeOffsetFromLive',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_minimumTimeOffsetFromLive)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_minimumTimeOffsetFromLive);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// init
  AVAsset init() {
    objc.checkOsVersionInternal('AVAsset.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return AVAsset.castFromPointer(_ret, retain: false, release: true);
  }

  /// new
  static AVAsset new$() {
    final _ret = _objc_msgSend_151sglz(_class_AVAsset, _sel_new);
    return AVAsset.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static AVAsset allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_AVAsset, _sel_allocWithZone_, zone);
    return AVAsset.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static AVAsset alloc() {
    final _ret = _objc_msgSend_151sglz(_class_AVAsset, _sel_alloc);
    return AVAsset.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  AVAsset self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  AVAsset retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  AVAsset autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// statusOfValueForKey:error:
  AVKeyValueStatus statusOfValueForKey(objc.NSString key, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    final _ret = _objc_msgSend_n4q2pj(this.ref.pointer, _sel_statusOfValueForKey_error_, key.ref.pointer, error);
    return AVKeyValueStatus.fromValue(_ret);
  }

  /// loadValuesAsynchronouslyForKeys:completionHandler:
  void loadValuesAsynchronouslyForKeys(objc.NSArray keys, {objc.ObjCBlock<ffi.Void Function()>? completionHandler}) {
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadValuesAsynchronouslyForKeys_completionHandler_,
      keys.ref.pointer,
      completionHandler?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// Returns a new instance of AVAsset constructed with the default `new` method.
  factory AVAsset() => new$();
}

final class CMTimeRange extends ffi.Struct {
  external CMTime start;

  external CMTime duration;
}

final class OpaqueCMClock extends ffi.Opaque {}

final class OpaqueCMTimebase extends ffi.Opaque {}

/// !
/// @enum AVPlayerStatus
/// @abstract
/// These constants are returned by the AVPlayer status property to indicate whether it can successfully play items.
///
/// @constant	 AVPlayerStatusUnknown
/// Indicates that the status of the player is not yet known because it has not tried to load new media resources for
/// playback.
/// @constant	 AVPlayerStatusReadyToPlay
/// Indicates that the player is ready to play AVPlayerItem instances.
/// @constant	 AVPlayerStatusFailed
/// Indicates that the player can no longer play AVPlayerItem instances because of an error. The error is described by
/// the value of the player's error property.
enum AVPlayerStatus {
  AVPlayerStatusUnknown(0),
  AVPlayerStatusReadyToPlay(1),
  AVPlayerStatusFailed(2);

  final int value;
  const AVPlayerStatus(this.value);

  static AVPlayerStatus fromValue(int value) => switch (value) {
    0 => AVPlayerStatusUnknown,
    1 => AVPlayerStatusReadyToPlay,
    2 => AVPlayerStatusFailed,
    _ => throw ArgumentError('Unknown value for AVPlayerStatus: $value'),
  };
}

late final _class_AVPlayer = objc.getClass("AVPlayer");
late final _sel_rate = objc.registerName("rate");
late final _sel_setRate_ = objc.registerName("setRate:");
final _objc_msgSend_v5hmet = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Float)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double)>();
late final _sel_defaultRate = objc.registerName("defaultRate");
late final _sel_setDefaultRate_ = objc.registerName("setDefaultRate:");
late final _sel_play = objc.registerName("play");
late final _sel_pause = objc.registerName("pause");

/// !
/// @enum AVPlayerTimeControlStatus
/// @abstract
/// These constants are the allowable values of AVPlayer's timeControlStatus property. This discussion pertains when automaticallyWaitsToMinimizeStalling is YES, the default setting, and exceptions are discussed in connection with automaticallyWaitsToMinimizeStalling.
///
/// @constant	 AVPlayerTimeControlStatusPaused
/// This state is entered upon receipt of a -pause message, an invocation of -setRate: with a value of 0.0, when a change in overall state requires playback to be halted, such as when an interruption occurs on iOS, as announced by AVAudioSession.
/// In this state, playback is paused indefinitely and will not resume until 1) a subsequent -play message is received or 2) a -setRate: or -playImmediatelyAtRate: message with a non-zero value for rate is received and sufficient media data has been buffered for playback to proceed.
/// @constant	 AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate
/// This state is entered when 1) the playback buffer becomes empty and playback stalls in AVPlayerTimeControlStatusPlaying, 2) when rate is set from zero to non-zero in AVPlayerTimeControlStatusPaused and insufficient media data has been buffered for playback to occur, or 3) when the player has no item to play, i.e. when the receiver's currentItem is nil.
/// In this state, the value of the rate property is not currently effective but instead indicates the rate at which playback will start or resume. Refer to the value of reasonForWaitingToPlay for details about why the receiver is waiting and the conditions that allow waitStatus to change to AVPlayerWaitStatusPlaying.
/// While waiting for buffering, you can attempt to start playback of any available media data via -playImmediatelyAtRate:.
/// @constant	 AVPlayerTimeControlStatusPlaying
/// In this state, playback is currently progressing and rate changes will take effect immediately. Should playback stall because of insufficient media data, timeControlStatus will change to AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate.
enum AVPlayerTimeControlStatus {
  AVPlayerTimeControlStatusPaused(0),
  AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate(1),
  AVPlayerTimeControlStatusPlaying(2);

  final int value;
  const AVPlayerTimeControlStatus(this.value);

  static AVPlayerTimeControlStatus fromValue(int value) => switch (value) {
    0 => AVPlayerTimeControlStatusPaused,
    1 => AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate,
    2 => AVPlayerTimeControlStatusPlaying,
    _ => throw ArgumentError('Unknown value for AVPlayerTimeControlStatus: $value'),
  };
}

late final _sel_timeControlStatus = objc.registerName("timeControlStatus");
final _objc_msgSend_hoknzl = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_reasonForWaitingToPlay = objc.registerName("reasonForWaitingToPlay");
late final _sel_playImmediatelyAtRate_ = objc.registerName("playImmediatelyAtRate:");

/// AVPlayerPlaybackControl
extension AVPlayerPlaybackControl on AVPlayer {
  /// !
  /// @property		rate
  /// @abstract		Indicates the desired rate of playback; 0.0 means "paused", 1.0 indicates a desire to play at the natural rate of the current item.
  /// @discussion
  /// Setting the value of rate to 0.0 pauses playback, causing the value of timeControlStatus to change to AVPlayerTimeControlStatusPaused.
  /// Setting the rate to a non-zero value causes the value of timeControlStatus to become either AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate or AVPlayerTimeControlStatusPlaying, depending on whether sufficient media data has been buffered for playback to occur and whether the player's default behavior of waiting in order to minimize stalling is permitted. See discussion of AVPlayerTimeControlStatus for more details.
  ///
  /// AVPlayer can reset the desired rate to 0.0 when a change in overall state requires playback to be halted, such as when an interruption occurs on iOS, as announced by AVAudioSession, or when the playback buffer becomes empty and playback stalls while automaticallyWaitsToMinimizeStalling is NO.
  ///
  /// The effective rate of playback may differ from the desired rate even while timeControlStatus is AVPlayerTimeControlStatusPlaying, if the processing algorithm in use for managing audio pitch requires quantization of playback rate. For information about quantization of rates for audio processing, see AVAudioProcessingSettings.h. You can always obtain the effective rate of playback from the currentItem's timebase; see the timebase property of AVPlayerItem.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  double get rate {
    objc.checkOsVersionInternal('AVPlayer.rate', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_rate)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_rate);
  }

  /// !
  /// @property		rate
  /// @abstract		Indicates the desired rate of playback; 0.0 means "paused", 1.0 indicates a desire to play at the natural rate of the current item.
  /// @discussion
  /// Setting the value of rate to 0.0 pauses playback, causing the value of timeControlStatus to change to AVPlayerTimeControlStatusPaused.
  /// Setting the rate to a non-zero value causes the value of timeControlStatus to become either AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate or AVPlayerTimeControlStatusPlaying, depending on whether sufficient media data has been buffered for playback to occur and whether the player's default behavior of waiting in order to minimize stalling is permitted. See discussion of AVPlayerTimeControlStatus for more details.
  ///
  /// AVPlayer can reset the desired rate to 0.0 when a change in overall state requires playback to be halted, such as when an interruption occurs on iOS, as announced by AVAudioSession, or when the playback buffer becomes empty and playback stalls while automaticallyWaitsToMinimizeStalling is NO.
  ///
  /// The effective rate of playback may differ from the desired rate even while timeControlStatus is AVPlayerTimeControlStatusPlaying, if the processing algorithm in use for managing audio pitch requires quantization of playback rate. For information about quantization of rates for audio processing, see AVAudioProcessingSettings.h. You can always obtain the effective rate of playback from the currentItem's timebase; see the timebase property of AVPlayerItem.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  set rate(double value) {
    objc.checkOsVersionInternal('AVPlayer.setRate:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_setRate_, value);
  }

  /// !
  /// @property      defaultRate
  /// @abstract      Indicates the rate at which to start playback when play is called; defaults to 1.0.
  /// @discussion
  /// Setting this property does not imply playback starts automatically at this rate. Clients still have to kick off playback using `play`. Note that using setRate to start playback will skip using the value in this property nor would it update this property. Therefore, `setRate:1.0` is no longer recommended as a means to start playback. Use `play` instead. Use `setRate` for operations like scanning where the rate is to be updated instantaneously. Invoking `play` again would restore playback at the rate set in this property.
  ///
  /// The effective rate of playback may still differ from the default rate subject to restrictions imposed by the system. See documentation for the rate property for a discussion on when the desired rate does not translate to effective rate.
  double get defaultRate {
    objc.checkOsVersionInternal('AVPlayer.defaultRate', iOS: (false, (16, 0, 0)), macOS: (false, (13, 0, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_defaultRate)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_defaultRate);
  }

  /// !
  /// @property      defaultRate
  /// @abstract      Indicates the rate at which to start playback when play is called; defaults to 1.0.
  /// @discussion
  /// Setting this property does not imply playback starts automatically at this rate. Clients still have to kick off playback using `play`. Note that using setRate to start playback will skip using the value in this property nor would it update this property. Therefore, `setRate:1.0` is no longer recommended as a means to start playback. Use `play` instead. Use `setRate` for operations like scanning where the rate is to be updated instantaneously. Invoking `play` again would restore playback at the rate set in this property.
  ///
  /// The effective rate of playback may still differ from the default rate subject to restrictions imposed by the system. See documentation for the rate property for a discussion on when the desired rate does not translate to effective rate.
  set defaultRate(double value) {
    objc.checkOsVersionInternal('AVPlayer.setDefaultRate:', iOS: (false, (16, 0, 0)), macOS: (false, (13, 0, 0)));
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_setDefaultRate_, value);
  }

  /// !
  /// @method        play
  /// @abstract      Signals the desire to begin playback at the rate set in the defaultRate.
  /// @discussion    For releases up to iOS version 16.0, macOS versions 13.0, tvOS 16.0 and watchOS 9.0, this is equivalent to setting the value of rate to `1.0`. Starting from iOS version 16.0, macOS versions 13.0, tvOS 16.0 and watchOS 9.0, this will attempt to use the rate set in the `defaultRate` property. The effective rate of playback may differ from the `defaultRate` due to the reasons mentioned in the documentation of the `rate` property. Clients interested in knowing the effective rate can listen for `AVPlayerRateDidChangeNotification` notification.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void play() {
    objc.checkOsVersionInternal('AVPlayer.play', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_play);
  }

  /// !
  /// @method		pause
  /// @abstract		Pauses playback.
  /// @discussion	Equivalent to setting the value of rate to 0.0.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void pause() {
    objc.checkOsVersionInternal('AVPlayer.pause', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_pause);
  }

  /// !
  /// @property		timeControlStatus
  /// @abstract		Indicates whether playback is currently paused indefinitely, suspended while waiting for appropriate conditions, or in progress.
  /// @discussion    For possible values and discussion, see AVPlayerTimeControlStatus.
  ///
  /// When automaticallyWaitsToMinimizeStalling is YES, absent intervention in the form of invocations of -setRate: or -pause or, on iOS, an interruption that requires user intervention before playback can resume, the value of the property timeControlStatus automatically changes between AVPlayerTimeControlStatusPlaying and AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate depending on whether sufficient media data is available to continue playback. This property is key value observable.
  AVPlayerTimeControlStatus get timeControlStatus {
    objc.checkOsVersionInternal('AVPlayer.timeControlStatus', iOS: (false, (10, 0, 0)), macOS: (false, (10, 12, 0)));
    final _ret = _objc_msgSend_hoknzl(this.ref.pointer, _sel_timeControlStatus);
    return AVPlayerTimeControlStatus.fromValue(_ret);
  }

  /// !
  /// @property		reasonForWaitingToPlay
  /// @abstract		Indicates the reason for waiting when the value of timeControlStatus is AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate
  /// @discussion
  /// When the value of timeControlStatus is AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate, this property describes why the player is currently waiting. It is nil otherwise.
  /// You can use the value of reasonForWaitingToPlay to show UI indicating the player's waiting state conditionally.
  /// This property is key value observable.
  /// Possible values are AVPlayerWaitingWithNoItemToPlayReason, AVPlayerWaitingWhileEvaluatingBufferingRateReason, and AVPlayerWaitingToMinimizeStallsReason.
  objc.NSString? get reasonForWaitingToPlay {
    objc.checkOsVersionInternal(
      'AVPlayer.reasonForWaitingToPlay',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_reasonForWaitingToPlay);
    return _ret.address == 0 ? null : objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		playImmediatelyAtRate:
  /// @abstract		Immediately plays the available media data at the specified rate.
  /// @discussion
  /// When the player's currentItem has a value of NO for playbackBufferEmpty, this method causes the value of rate to change to the specified rate, the value of timeControlStatus to change to AVPlayerTimeControlStatusPlaying, and the receiver to play the available media immediately, whether or not prior buffering of media data is sufficient to ensure smooth playback.
  /// If insufficient media data is buffered for playback to start (e.g. if the current item has a value of YES for playbackBufferEmpty), the receiver will act as if the buffer became empty during playback, except that no AVPlayerItemPlaybackStalledNotification will be posted.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void playImmediatelyAtRate(double rate$1) {
    objc.checkOsVersionInternal(
      'AVPlayer.playImmediatelyAtRate:',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_playImmediatelyAtRate_, rate$1);
  }
}

late final _class_AVPlayerItem = objc.getClass("AVPlayerItem");
late final _sel_asset = objc.registerName("asset");
late final _sel_presentationSize = objc.registerName("presentationSize");
late final _sel_timedMetadata = objc.registerName("timedMetadata");
late final _sel_automaticallyLoadedAssetKeys = objc.registerName("automaticallyLoadedAssetKeys");

/// AVPlayerItemInspection
extension AVPlayerItemInspection on AVPlayerItem {
  /// !
  /// @property asset
  /// @abstract Accessor for underlying AVAsset.
  AVAsset get asset {
    objc.checkOsVersionInternal('AVPlayerItem.asset', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_asset);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property tracks
  /// @abstract Provides array of AVPlayerItem tracks. Observable (can change dynamically during playback).
  ///
  /// @discussion
  /// The value of this property will accord with the properties of the underlying media resource when the receiver becomes ready to play.
  /// Before the underlying media resource has been sufficiently loaded, its value is an empty NSArray. Use key-value observation to obtain
  /// a valid array of tracks as soon as it becomes available.
  objc.NSArray get tracks {
    objc.checkOsVersionInternal('AVPlayerItem.tracks', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_tracks);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property duration
  /// @abstract Indicates the duration of the item, not considering either its forwardPlaybackEndTime or reversePlaybackEndTime.
  ///
  /// @discussion
  /// This property is observable. The duration of an item can change dynamically during playback.
  ///
  /// Unless you omit @"duration" from the array of asset keys you pass to +playerItemWithAsset:automaticallyLoadedAssetKeys: or
  /// -initWithAsset:automaticallyLoadedAssetKeys:, the value of this property will accord with the properties of the underlying
  /// AVAsset and the current state of playback once the receiver becomes ready to play.
  ///
  /// Before the underlying duration has been loaded, the value of this property is kCMTimeIndefinite. Use key-value observation to
  /// obtain a valid duration as soon as it becomes available. (Note that the value of duration may remain kCMTimeIndefinite,
  /// e.g. for live streams.)
  CMTime get duration {
    objc.checkOsVersionInternal('AVPlayerItem.duration', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_duration)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_duration);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property presentationSize
  /// @abstract The size of the receiver as presented by the player.
  ///
  /// @discussion
  /// Indicates the size at which the visual portion of the item is presented by the player; can be scaled from this
  /// size to fit within the bounds of an AVPlayerLayer via its videoGravity property. Can be scaled arbitrarily for presentation
  /// via the frame property of an AVPlayerLayer.
  ///
  /// The value of this property will accord with the properties of the underlying media resource when the receiver becomes ready to play.
  /// Before the underlying media resource is sufficiently loaded, its value is CGSizeZero. Use key-value observation to obtain a valid
  /// presentationSize as soon as it becomes available. (Note that the value of presentationSize may remain CGSizeZero, e.g. for audio-only items.)
  objc.CGSize get presentationSize {
    objc.checkOsVersionInternal('AVPlayerItem.presentationSize', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<objc.CGSize>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1vdfkenStret(_ptr, this.ref.pointer, _sel_presentationSize)
        : _ptr.ref = _objc_msgSend_1vdfken(this.ref.pointer, _sel_presentationSize);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGSize>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGSize>(_finalizable);
  }

  /// !
  /// @property timedMetadata
  /// @abstract Provides an NSArray of AVMetadataItems representing the timed metadata encountered most recently within the media as it plays. May be nil.
  /// @discussion
  /// Notifications of changes are available via key-value observation.
  /// As an optimization for playback, AVPlayerItem may omit the processing of timed metadata when no observer of this property is registered. Therefore, when no such observer is registered, the value of the timedMetadata property may remain nil regardless of the contents of the underlying media.
  ///
  /// This property must be accessed on the main thread/queue.
  objc.NSArray? get timedMetadata {
    objc.checkOsVersionInternal('AVPlayerItem.timedMetadata', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_timedMetadata);
    return _ret.address == 0 ? null : objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property automaticallyLoadedAssetKeys
  /// @abstract An array of property keys defined on AVAsset. The value of each key in the array is automatically loaded while the receiver is being made ready to play.
  /// @discussion
  /// The value of each key in automaticallyLoadedAssetKeys will be automatically be loaded by the underlying AVAsset before the receiver achieves the status AVPlayerItemStatusReadyToPlay; i.e. when the item is ready to play, the value of -[[AVPlayerItem asset] statusOfValueForKey:error:] will be AVKeyValueStatusLoaded. If loading of any of the values fails, the status of the AVPlayerItem will change instead to AVPlayerItemStatusFailed..
  objc.NSArray get automaticallyLoadedAssetKeys {
    objc.checkOsVersionInternal(
      'AVPlayerItem.automaticallyLoadedAssetKeys',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_automaticallyLoadedAssetKeys);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

late final _sel_canPlayFastForward = objc.registerName("canPlayFastForward");
late final _sel_canPlaySlowForward = objc.registerName("canPlaySlowForward");
late final _sel_canPlayReverse = objc.registerName("canPlayReverse");
late final _sel_canPlaySlowReverse = objc.registerName("canPlaySlowReverse");
late final _sel_canPlayFastReverse = objc.registerName("canPlayFastReverse");
late final _sel_canStepForward = objc.registerName("canStepForward");
late final _sel_canStepBackward = objc.registerName("canStepBackward");
late final _sel_configuredTimeOffsetFromLive = objc.registerName("configuredTimeOffsetFromLive");
late final _sel_setConfiguredTimeOffsetFromLive_ = objc.registerName("setConfiguredTimeOffsetFromLive:");
final _objc_msgSend_1hznzoi = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, CMTime)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, CMTime)>();
late final _sel_recommendedTimeOffsetFromLive = objc.registerName("recommendedTimeOffsetFromLive");
late final _sel_automaticallyPreservesTimeOffsetFromLive = objc.registerName(
  "automaticallyPreservesTimeOffsetFromLive",
);
late final _sel_setAutomaticallyPreservesTimeOffsetFromLive_ = objc.registerName(
  "setAutomaticallyPreservesTimeOffsetFromLive:",
);
final _objc_msgSend_1s56lr9 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Bool)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, bool)>();

/// AVPlayerItemRateAndSteppingSupport
extension AVPlayerItemRateAndSteppingSupport on AVPlayerItem {
  /// canPlayFastForward
  bool get canPlayFastForward {
    objc.checkOsVersionInternal('AVPlayerItem.canPlayFastForward', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPlayFastForward);
  }

  /// canPlaySlowForward
  bool get canPlaySlowForward {
    objc.checkOsVersionInternal('AVPlayerItem.canPlaySlowForward', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPlaySlowForward);
  }

  /// canPlayReverse
  bool get canPlayReverse {
    objc.checkOsVersionInternal('AVPlayerItem.canPlayReverse', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPlayReverse);
  }

  /// canPlaySlowReverse
  bool get canPlaySlowReverse {
    objc.checkOsVersionInternal('AVPlayerItem.canPlaySlowReverse', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPlaySlowReverse);
  }

  /// canPlayFastReverse
  bool get canPlayFastReverse {
    objc.checkOsVersionInternal('AVPlayerItem.canPlayFastReverse', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPlayFastReverse);
  }

  /// canStepForward
  bool get canStepForward {
    objc.checkOsVersionInternal('AVPlayerItem.canStepForward', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canStepForward);
  }

  /// canStepBackward
  bool get canStepBackward {
    objc.checkOsVersionInternal('AVPlayerItem.canStepBackward', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canStepBackward);
  }

  /// !
  /// @property		configuredTimeOffsetFromLive
  /// @abstract		Indicates how close to the latest content in a live stream playback will begin after a live start or a seek to kCMTimePositiveInfinity.
  /// @discussion	For non-live assets this value is kCMTimeInvalid.
  CMTime get configuredTimeOffsetFromLive {
    objc.checkOsVersionInternal(
      'AVPlayerItem.configuredTimeOffsetFromLive',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_configuredTimeOffsetFromLive)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_configuredTimeOffsetFromLive);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property		configuredTimeOffsetFromLive
  /// @abstract		Indicates how close to the latest content in a live stream playback will begin after a live start or a seek to kCMTimePositiveInfinity.
  /// @discussion	For non-live assets this value is kCMTimeInvalid.
  set configuredTimeOffsetFromLive(CMTime value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setConfiguredTimeOffsetFromLive:',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    _objc_msgSend_1hznzoi(this.ref.pointer, _sel_setConfiguredTimeOffsetFromLive_, value);
  }

  /// !
  /// @property		recommendedTimeOffsetFromLive
  /// @abstract		A recommended value for configuredTimeOffsetFromLive, based on observed network conditions.
  /// @discussion	For non-live assets this value is kCMTimeInvalid.
  CMTime get recommendedTimeOffsetFromLive {
    objc.checkOsVersionInternal(
      'AVPlayerItem.recommendedTimeOffsetFromLive',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_recommendedTimeOffsetFromLive)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_recommendedTimeOffsetFromLive);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property		automaticallyPreservesTimeOffsetFromLive
  /// @abstract		Indicates that after the player spends a period of time buffering media, it will skip forward if necessary to restore the playhead's distance from the live edge of the presentation to what it was when buffering began.
  /// @discussion
  /// If the value of this property is YES and the player must buffer media from the network in order to resume playback, the player will seek forward if necessary before resuming playback to restore the position that the playhead had when rebuffering began, relative to the end of the current AVPlayerItem's seekableTimeRange.
  ///
  /// This behavior applies to media buffering that occurs as a consequence of starting playback, seeking, and recovering from a playback stall.
  ///
  /// Note that if the network cannot deliver media quickly enough to maintain the playback rate, playback may stall interminably.
  ///
  /// This property value has no effect if the asset is not a live stream. The default value of this property is NO.
  bool get automaticallyPreservesTimeOffsetFromLive {
    objc.checkOsVersionInternal(
      'AVPlayerItem.automaticallyPreservesTimeOffsetFromLive',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_automaticallyPreservesTimeOffsetFromLive);
  }

  /// !
  /// @property		automaticallyPreservesTimeOffsetFromLive
  /// @abstract		Indicates that after the player spends a period of time buffering media, it will skip forward if necessary to restore the playhead's distance from the live edge of the presentation to what it was when buffering began.
  /// @discussion
  /// If the value of this property is YES and the player must buffer media from the network in order to resume playback, the player will seek forward if necessary before resuming playback to restore the position that the playhead had when rebuffering began, relative to the end of the current AVPlayerItem's seekableTimeRange.
  ///
  /// This behavior applies to media buffering that occurs as a consequence of starting playback, seeking, and recovering from a playback stall.
  ///
  /// Note that if the network cannot deliver media quickly enough to maintain the playback rate, playback may stall interminably.
  ///
  /// This property value has no effect if the asset is not a live stream. The default value of this property is NO.
  set automaticallyPreservesTimeOffsetFromLive(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setAutomaticallyPreservesTimeOffsetFromLive:',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAutomaticallyPreservesTimeOffsetFromLive_, value);
  }
}

late final _sel_currentTime = objc.registerName("currentTime");
late final _sel_forwardPlaybackEndTime = objc.registerName("forwardPlaybackEndTime");
late final _sel_setForwardPlaybackEndTime_ = objc.registerName("setForwardPlaybackEndTime:");
late final _sel_reversePlaybackEndTime = objc.registerName("reversePlaybackEndTime");
late final _sel_setReversePlaybackEndTime_ = objc.registerName("setReversePlaybackEndTime:");
late final _sel_seekableTimeRanges = objc.registerName("seekableTimeRanges");
void _ObjCBlock_ffiVoid_bool_fnPtrTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, bool arg0) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Bool arg0)>>()
    .asFunction<void Function(bool)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_bool_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool)>(
      _ObjCBlock_ffiVoid_bool_fnPtrTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_bool_closureTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, bool arg0) =>
    (objc.getBlockClosure(block) as void Function(bool))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_bool_closureCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool)>(
      _ObjCBlock_ffiVoid_bool_closureTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_bool_listenerTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, bool arg0) {
  (objc.getBlockClosure(block) as void Function(bool))(arg0);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool)>
_ObjCBlock_ffiVoid_bool_listenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool)>.listener(
      _ObjCBlock_ffiVoid_bool_listenerTrampoline,
    )..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_bool_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  bool arg0,
) {
  try {
    (objc.getBlockClosure(block) as void Function(bool))(arg0);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Bool)>
_ObjCBlock_ffiVoid_bool_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Bool)
      >.isolateLocal(_ObjCBlock_ffiVoid_bool_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Bool)>
_ObjCBlock_ffiVoid_bool_blockingListenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Bool)>.listener(
      _ObjCBlock_ffiVoid_bool_blockingTrampoline,
    )..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(ffi.Bool)>`.
abstract final class ObjCBlock_ffiVoid_bool {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Bool)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Bool arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function(ffi.Bool)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_bool_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool)> fromFunction(
    void Function(bool) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Bool)>(
    objc.newClosureBlock(_ObjCBlock_ffiVoid_bool_closureCallable, (bool arg0) => fn(arg0), keepIsolateAlive),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool)> listener(void Function(bool) fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_bool_listenerCallable.nativeFunction.cast(),
      (bool arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_1s56lr9(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Bool)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool)> blocking(void Function(bool) fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_bool_blockingCallable.nativeFunction.cast(),
      (bool arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_bool_blockingListenerCallable.nativeFunction.cast(),
      (bool arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_1s56lr9(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Bool)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(ffi.Bool)>`.
extension ObjCBlock_ffiVoid_bool_CallExtension on objc.ObjCBlock<ffi.Void Function(ffi.Bool)> {
  void call(bool arg0) => ref.pointer.ref.invoke
      .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Bool arg0)>>()
      .asFunction<void Function(ffi.Pointer<objc.ObjCBlockImpl>, bool)>()(ref.pointer, arg0);
}

late final _sel_seekToTime_completionHandler_ = objc.registerName("seekToTime:completionHandler:");
final _objc_msgSend_1pt0wih = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          CMTime,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        CMTime,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_seekToTime_toleranceBefore_toleranceAfter_completionHandler_ = objc.registerName(
  "seekToTime:toleranceBefore:toleranceAfter:completionHandler:",
);
final _objc_msgSend_4xu1ph = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          CMTime,
          CMTime,
          CMTime,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        CMTime,
        CMTime,
        CMTime,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_cancelPendingSeeks = objc.registerName("cancelPendingSeeks");
late final _sel_currentDate = objc.registerName("currentDate");
late final _sel_seekToDate_completionHandler_ = objc.registerName("seekToDate:completionHandler:");
final _objc_msgSend_1wskeji = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_stepByCount_ = objc.registerName("stepByCount:");
final _objc_msgSend_4sp4xj = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Long)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();
late final _sel_timebase = objc.registerName("timebase");
final _objc_msgSend_93ekp9 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<OpaqueCMTimebase> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<ffi.Pointer<OpaqueCMTimebase> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVPlayerItemTimeControl
extension AVPlayerItemTimeControl on AVPlayerItem {
  /// !
  /// @method			currentTime
  /// @abstract			Returns the current time of the item.
  /// @result			A CMTime
  /// @discussion		Returns the current time of the item. Not key-value observable; use -[AVPlayer addPeriodicTimeObserverForInterval:queue:usingBlock:] instead.
  CMTime currentTime() {
    objc.checkOsVersionInternal('AVPlayerItem.currentTime', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_currentTime)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_currentTime);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property forwardPlaybackEndTime
  /// @abstract
  /// The end time for forward playback.
  ///
  /// @discussion
  /// Specifies the time at which playback should end when the playback rate is positive (see AVPlayer's rate property).
  /// The default value is kCMTimeInvalid, which indicates that no end time for forward playback is specified.
  /// In this case, the effective end time for forward playback is the receiver's duration.
  ///
  /// When the end time is reached, the receiver will post AVPlayerItemDidPlayToEndTimeNotification and the AVPlayer will take
  /// the action indicated by the value of its actionAtItemEnd property (see AVPlayerActionAtItemEnd in AVPlayer.h).
  ///
  /// The value of this property has no effect on playback when the rate is negative.
  CMTime get forwardPlaybackEndTime {
    objc.checkOsVersionInternal(
      'AVPlayerItem.forwardPlaybackEndTime',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_forwardPlaybackEndTime)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_forwardPlaybackEndTime);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property forwardPlaybackEndTime
  /// @abstract
  /// The end time for forward playback.
  ///
  /// @discussion
  /// Specifies the time at which playback should end when the playback rate is positive (see AVPlayer's rate property).
  /// The default value is kCMTimeInvalid, which indicates that no end time for forward playback is specified.
  /// In this case, the effective end time for forward playback is the receiver's duration.
  ///
  /// When the end time is reached, the receiver will post AVPlayerItemDidPlayToEndTimeNotification and the AVPlayer will take
  /// the action indicated by the value of its actionAtItemEnd property (see AVPlayerActionAtItemEnd in AVPlayer.h).
  ///
  /// The value of this property has no effect on playback when the rate is negative.
  set forwardPlaybackEndTime(CMTime value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setForwardPlaybackEndTime:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1hznzoi(this.ref.pointer, _sel_setForwardPlaybackEndTime_, value);
  }

  /// !
  /// @property reversePlaybackEndTime
  /// @abstract
  /// The end time for reverse playback.
  ///
  /// @discussion
  /// Specifies the time at which playback should end when the playback rate is negative (see AVPlayer's rate property).
  /// The default value is kCMTimeInvalid, which indicates that no end time for reverse playback is specified.
  /// In this case, the effective end time for reverse playback is kCMTimeZero.
  ///
  /// When the end time is reached, the receiver will post AVPlayerItemDidPlayToEndTimeNotification and the AVPlayer will take
  /// the action indicated by the value of its actionAtItemEnd property (see AVPlayerActionAtItemEnd in AVPlayer.h).
  ///
  /// The value of this property has no effect on playback when the rate is positive.
  CMTime get reversePlaybackEndTime {
    objc.checkOsVersionInternal(
      'AVPlayerItem.reversePlaybackEndTime',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_reversePlaybackEndTime)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_reversePlaybackEndTime);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property reversePlaybackEndTime
  /// @abstract
  /// The end time for reverse playback.
  ///
  /// @discussion
  /// Specifies the time at which playback should end when the playback rate is negative (see AVPlayer's rate property).
  /// The default value is kCMTimeInvalid, which indicates that no end time for reverse playback is specified.
  /// In this case, the effective end time for reverse playback is kCMTimeZero.
  ///
  /// When the end time is reached, the receiver will post AVPlayerItemDidPlayToEndTimeNotification and the AVPlayer will take
  /// the action indicated by the value of its actionAtItemEnd property (see AVPlayerActionAtItemEnd in AVPlayer.h).
  ///
  /// The value of this property has no effect on playback when the rate is positive.
  set reversePlaybackEndTime(CMTime value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setReversePlaybackEndTime:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1hznzoi(this.ref.pointer, _sel_setReversePlaybackEndTime_, value);
  }

  /// !
  /// @property seekableTimeRanges
  /// @abstract This property provides a collection of time ranges that the player item can seek to. The ranges provided might be discontinous.
  /// @discussion Returns an NSArray of NSValues containing CMTimeRanges.
  objc.NSArray get seekableTimeRanges {
    objc.checkOsVersionInternal('AVPlayerItem.seekableTimeRanges', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_seekableTimeRanges);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method			seekToTime:completionHandler:
  /// @abstract			Moves the playback cursor and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @param				time
  /// @param				completionHandler
  /// @discussion		Use this method to seek to a specified time for the item and to be notified when the seek operation is complete.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter
  /// set to NO. If the new request completes without being interrupted by another seek request or by any other operation the specified
  /// completion handler will be invoked with the finished parameter set to YES.
  /// If the seek time is outside of seekable time ranges as indicated by seekableTimeRanges property, the seek request will be cancelled and the completion handler will be invoked with the finished parameter set to NO.
  ///
  /// This method throws an exception if time is invalid or indefinite.
  void seekToTime(CMTime time, {objc.ObjCBlock<ffi.Void Function(ffi.Bool)>? completionHandler}) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.seekToTime:completionHandler:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1pt0wih(
      this.ref.pointer,
      _sel_seekToTime_completionHandler_,
      time,
      completionHandler?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// !
  /// @method			seekToTime:toleranceBefore:toleranceAfter:completionHandler:
  /// @abstract			Moves the playback cursor within a specified time bound and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @param				time
  /// @param				toleranceBefore
  /// @param				toleranceAfter
  /// @param				completionHandler
  /// @discussion		Use this method to seek to a specified time for the item and to be notified when the seek operation is complete.
  /// The time seeked to will be within the range [time-toleranceBefore, time+toleranceAfter] and may differ from the specified time for efficiency.
  /// Pass kCMTimeZero for both toleranceBefore and toleranceAfter to request sample accurate seeking which may incur additional decoding delay.
  /// Messaging this method with beforeTolerance:kCMTimePositiveInfinity and afterTolerance:kCMTimePositiveInfinity is the same as messaging seekToTime: directly.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter set to NO. If the new
  /// request completes without being interrupted by another seek request or by any other operation the specified completion handler will be invoked with the
  /// finished parameter set to YES.
  /// If the seek time is outside of seekable time ranges as indicated by seekableTimeRanges property, the seek request will be cancelled and the completion handler will be invoked with the finished parameter set to NO.
  ///
  /// This method throws an exception if time is invalid or indefinite or if tolerance before or tolerance after is invalid or negative.
  void seekToTime$1(
    CMTime time, {
    required CMTime toleranceBefore,
    required CMTime toleranceAfter,
    objc.ObjCBlock<ffi.Void Function(ffi.Bool)>? completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.seekToTime:toleranceBefore:toleranceAfter:completionHandler:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_4xu1ph(
      this.ref.pointer,
      _sel_seekToTime_toleranceBefore_toleranceAfter_completionHandler_,
      time,
      toleranceBefore,
      toleranceAfter,
      completionHandler?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// !
  /// @method			cancelPendingSeeks
  /// @abstract			Cancel any pending seek requests and invoke the corresponding completion handlers if present.
  /// @discussion		Use this method to cancel and release the completion handlers of pending seeks. The finished parameter of the completion handlers will
  /// be set to NO.
  void cancelPendingSeeks() {
    objc.checkOsVersionInternal('AVPlayerItem.cancelPendingSeeks', iOS: (false, (5, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_cancelPendingSeeks);
  }

  /// !
  /// @method	currentDate
  /// @abstract	If currentTime is mapped to a particular (real-time) date, return that date.
  /// @result		Returns the date of current playback, or nil if playback is not mapped to any date.
  objc.NSDate? currentDate() {
    objc.checkOsVersionInternal('AVPlayerItem.currentDate', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_currentDate);
    return _ret.address == 0 ? null : objc.NSDate.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		seekToDate:completionHandler:
  /// @abstract		move playhead to a point corresponding to a particular date, and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @discussion
  /// For playback content that is associated with a range of dates, move the
  /// playhead to point within that range and invokes the completion handler when the seek operation is complete.
  /// Will fail if the supplied date is outside the range or if the content is not associated with a range of dates.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter
  /// set to NO. If the new request completes without being interrupted by another seek request or by any other operation, the specified
  /// completion handler will be invoked with the finished parameter set to YES.
  /// @param			date				The new position for the playhead.
  /// @param			completionHandler	The block to invoke when seek operation is complete
  /// @result		Returns true if the playhead was moved to the supplied date.
  bool seekToDate(objc.NSDate date, {objc.ObjCBlock<ffi.Void Function(ffi.Bool)>? completionHandler}) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.seekToDate:completionHandler:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    return _objc_msgSend_1wskeji(
      this.ref.pointer,
      _sel_seekToDate_completionHandler_,
      date.ref.pointer,
      completionHandler?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// !
  /// @method		stepByCount:
  /// @abstract		Moves player's current item's current time forward or backward by the specified number of steps.
  /// @param 		stepCount
  /// The number of steps by which to move. A positive number results in stepping forward, a negative number in stepping backward.
  /// @discussion
  /// The size of each step depends on the enabled AVPlayerItemTracks of the AVPlayerItem.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void stepByCount(int stepCount) {
    objc.checkOsVersionInternal('AVPlayerItem.stepByCount:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_4sp4xj(this.ref.pointer, _sel_stepByCount_, stepCount);
  }

  /// !
  /// @property		timebase
  /// @abstract		The item's timebase.
  /// @discussion
  /// You can examine the timebase to discover the relationship between the item's time and the source clock used for drift synchronization.
  /// This timebase is read-only; you cannot set its time or rate to affect playback.
  ffi.Pointer<OpaqueCMTimebase> get timebase {
    objc.checkOsVersionInternal('AVPlayerItem.timebase', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_93ekp9(this.ref.pointer, _sel_timebase);
  }
}

/// WARNING: AVVideoComposition is a stub. To generate bindings for this class, include
/// AVVideoComposition in your config's objc-interfaces list.
///
/// AVVideoComposition
class AVVideoComposition extends objc.ObjCObjectBase {
  AVVideoComposition._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVVideoComposition] that points to the same underlying object as [other].
  AVVideoComposition.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVVideoComposition] that wraps the given raw object pointer.
  AVVideoComposition.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_videoComposition = objc.registerName("videoComposition");
late final _sel_setVideoComposition_ = objc.registerName("setVideoComposition:");
final _objc_msgSend_xtuoz7 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCObject>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCObject>)
    >();

/// WARNING: AVVideoCompositing is a stub. To generate bindings for this class, include
/// AVVideoCompositing in your config's objc-protocols list.
///
/// AVVideoCompositing
interface class AVVideoCompositing extends objc.ObjCProtocolBase {
  AVVideoCompositing._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVVideoCompositing] that points to the same underlying object as [other].
  AVVideoCompositing.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVVideoCompositing] that wraps the given raw object pointer.
  AVVideoCompositing.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_customVideoCompositor = objc.registerName("customVideoCompositor");
late final _sel_seekingWaitsForVideoCompositionRendering = objc.registerName(
  "seekingWaitsForVideoCompositionRendering",
);
late final _sel_setSeekingWaitsForVideoCompositionRendering_ = objc.registerName(
  "setSeekingWaitsForVideoCompositionRendering:",
);
late final _sel_textStyleRules = objc.registerName("textStyleRules");
late final _sel_setTextStyleRules_ = objc.registerName("setTextStyleRules:");
late final _sel_videoApertureMode = objc.registerName("videoApertureMode");
late final _sel_setVideoApertureMode_ = objc.registerName("setVideoApertureMode:");
late final _sel_appliesPerFrameHDRDisplayMetadata = objc.registerName("appliesPerFrameHDRDisplayMetadata");
late final _sel_setAppliesPerFrameHDRDisplayMetadata_ = objc.registerName("setAppliesPerFrameHDRDisplayMetadata:");

/// AVPlayerItemVisualPresentation
extension AVPlayerItemVisualPresentation on AVPlayerItem {
  /// !
  /// @property 		videoComposition
  /// @abstract 		Indicates the video composition settings to be applied during playback.
  /// @discussion	Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  ///
  /// This property throws an exception if a video composition is set with any of the following values:
  /// - renderSize, renderScale, or frameDuration is less than or equal to zero
  /// - sourceTrackIDForFrameTiming is less than or equal to zero
  /// - uses AVVideoCompositionCoreAnimationTool (works for offline rendering only)
  AVVideoComposition? get videoComposition {
    objc.checkOsVersionInternal('AVPlayerItem.videoComposition', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_videoComposition);
    return _ret.address == 0 ? null : AVVideoComposition.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property 		videoComposition
  /// @abstract 		Indicates the video composition settings to be applied during playback.
  /// @discussion	Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  ///
  /// This property throws an exception if a video composition is set with any of the following values:
  /// - renderSize, renderScale, or frameDuration is less than or equal to zero
  /// - sourceTrackIDForFrameTiming is less than or equal to zero
  /// - uses AVVideoCompositionCoreAnimationTool (works for offline rendering only)
  set videoComposition(AVVideoComposition? value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setVideoComposition:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setVideoComposition_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// !
  /// @property customVideoCompositor
  /// @abstract Indicates the custom video compositor instance.
  /// @discussion
  /// This property is nil if there is no video compositor, or if the internal video compositor is in use. This reference can be used to provide extra context to the custom video compositor instance if required.  The value of this property can change as a result of setting the `videoComposition` property.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  AVVideoCompositing? get customVideoCompositor {
    objc.checkOsVersionInternal(
      'AVPlayerItem.customVideoCompositor',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_customVideoCompositor);
    return _ret.address == 0 ? null : AVVideoCompositing.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property seekingWaitsForVideoCompositionRendering
  /// @abstract Indicates whether the item's timing follows the displayed video frame when seeking with a video composition
  /// @discussion
  /// By default, item timing is updated as quickly as possible, not waiting for media at new times to be rendered when seeking or
  /// during normal playback. The latency that occurs, for example, between the completion of a seek operation and the display of a
  /// video frame at a new time is negligible in most situations. However, when video compositions are in use, the processing of
  /// video for any particular time may introduce noticeable latency. Therefore it may be desirable when a video composition is in
  /// use for the item's timing be updated only after the video frame for a time has been displayed. This allows, for instance, an
  /// AVSynchronizedLayer associated with an AVPlayerItem to remain in synchronization with the displayed video and for the
  /// currentTime property to return the time of the displayed video.
  ///
  /// This property has no effect on items for which videoComposition is nil.
  bool get seekingWaitsForVideoCompositionRendering {
    objc.checkOsVersionInternal(
      'AVPlayerItem.seekingWaitsForVideoCompositionRendering',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_seekingWaitsForVideoCompositionRendering);
  }

  /// !
  /// @property seekingWaitsForVideoCompositionRendering
  /// @abstract Indicates whether the item's timing follows the displayed video frame when seeking with a video composition
  /// @discussion
  /// By default, item timing is updated as quickly as possible, not waiting for media at new times to be rendered when seeking or
  /// during normal playback. The latency that occurs, for example, between the completion of a seek operation and the display of a
  /// video frame at a new time is negligible in most situations. However, when video compositions are in use, the processing of
  /// video for any particular time may introduce noticeable latency. Therefore it may be desirable when a video composition is in
  /// use for the item's timing be updated only after the video frame for a time has been displayed. This allows, for instance, an
  /// AVSynchronizedLayer associated with an AVPlayerItem to remain in synchronization with the displayed video and for the
  /// currentTime property to return the time of the displayed video.
  ///
  /// This property has no effect on items for which videoComposition is nil.
  set seekingWaitsForVideoCompositionRendering(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setSeekingWaitsForVideoCompositionRendering:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setSeekingWaitsForVideoCompositionRendering_, value);
  }

  /// !
  /// @property textStyleRules
  /// @abstract An array of AVTextStyleRules representing text styling that can be applied to subtitles and other legible media.
  /// @discussion
  /// The styling information contained in each AVTextStyleRule object in the array is used only when no equivalent styling information is provided by the media resource being played.  For example, if the text style rules specify Courier font but the media resource specifies Helvetica font, the text will be drawn using Helvetica font.
  ///
  /// This property has an effect only for tracks with media subtype kCMSubtitleFormatType_WebVTT.
  objc.NSArray? get textStyleRules {
    objc.checkOsVersionInternal('AVPlayerItem.textStyleRules', iOS: (false, (6, 0, 0)), macOS: (false, (10, 9, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_textStyleRules);
    return _ret.address == 0 ? null : objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property textStyleRules
  /// @abstract An array of AVTextStyleRules representing text styling that can be applied to subtitles and other legible media.
  /// @discussion
  /// The styling information contained in each AVTextStyleRule object in the array is used only when no equivalent styling information is provided by the media resource being played.  For example, if the text style rules specify Courier font but the media resource specifies Helvetica font, the text will be drawn using Helvetica font.
  ///
  /// This property has an effect only for tracks with media subtype kCMSubtitleFormatType_WebVTT.
  set textStyleRules(objc.NSArray? value) {
    objc.checkOsVersionInternal('AVPlayerItem.setTextStyleRules:', iOS: (false, (6, 0, 0)), macOS: (false, (10, 9, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setTextStyleRules_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// !
  /// @property	videoApertureMode
  /// @abstract	Specifies the video aperture mode to apply during playback.
  /// @discussion
  /// See AVVideoApertureMode constants defined in AVVideoSettings.h. Default is AVVideoApertureModeCleanAperture.
  objc.NSString get videoApertureMode {
    objc.checkOsVersionInternal(
      'AVPlayerItem.videoApertureMode',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_videoApertureMode);
    return objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property	videoApertureMode
  /// @abstract	Specifies the video aperture mode to apply during playback.
  /// @discussion
  /// See AVVideoApertureMode constants defined in AVVideoSettings.h. Default is AVVideoApertureModeCleanAperture.
  set videoApertureMode(objc.NSString value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setVideoApertureMode:',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setVideoApertureMode_, value.ref.pointer);
  }

  /// !
  /// @property	appliesPerFrameHDRDisplayMetadata
  /// @abstract	Controls whether or not to apply the per frame HDR display metadata of the source during playback.
  /// @discussion
  bool get appliesPerFrameHDRDisplayMetadata {
    objc.checkOsVersionInternal(
      'AVPlayerItem.appliesPerFrameHDRDisplayMetadata',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_appliesPerFrameHDRDisplayMetadata);
  }

  /// !
  /// @property	appliesPerFrameHDRDisplayMetadata
  /// @abstract	Controls whether or not to apply the per frame HDR display metadata of the source during playback.
  /// @discussion
  set appliesPerFrameHDRDisplayMetadata(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setAppliesPerFrameHDRDisplayMetadata:',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAppliesPerFrameHDRDisplayMetadata_, value);
  }
}

late final _sel_audioTimePitchAlgorithm = objc.registerName("audioTimePitchAlgorithm");
late final _sel_setAudioTimePitchAlgorithm_ = objc.registerName("setAudioTimePitchAlgorithm:");
late final _sel_isAudioSpatializationAllowed = objc.registerName("isAudioSpatializationAllowed");
late final _sel_setAudioSpatializationAllowed_ = objc.registerName("setAudioSpatializationAllowed:");

enum AVAudioSpatializationFormats {
  AVAudioSpatializationFormatNone(0),
  AVAudioSpatializationFormatMonoAndStereo(3),
  AVAudioSpatializationFormatMultichannel(4),
  AVAudioSpatializationFormatMonoStereoAndMultichannel(7);

  final int value;
  const AVAudioSpatializationFormats(this.value);

  static AVAudioSpatializationFormats fromValue(int value) => switch (value) {
    0 => AVAudioSpatializationFormatNone,
    3 => AVAudioSpatializationFormatMonoAndStereo,
    4 => AVAudioSpatializationFormatMultichannel,
    7 => AVAudioSpatializationFormatMonoStereoAndMultichannel,
    _ => throw ArgumentError('Unknown value for AVAudioSpatializationFormats: $value'),
  };
}

late final _sel_allowedAudioSpatializationFormats = objc.registerName("allowedAudioSpatializationFormats");
final _objc_msgSend_2s2a50 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setAllowedAudioSpatializationFormats_ = objc.registerName("setAllowedAudioSpatializationFormats:");
final _objc_msgSend_12f6ne = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.UnsignedLong)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// WARNING: AVAudioMix is a stub. To generate bindings for this class, include
/// AVAudioMix in your config's objc-interfaces list.
///
/// AVAudioMix
class AVAudioMix extends objc.ObjCObjectBase {
  AVAudioMix._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVAudioMix] that points to the same underlying object as [other].
  AVAudioMix.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAudioMix] that wraps the given raw object pointer.
  AVAudioMix.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_audioMix = objc.registerName("audioMix");
late final _sel_setAudioMix_ = objc.registerName("setAudioMix:");

/// AVPlayerItemAudioProcessing
extension AVPlayerItemAudioProcessing on AVPlayerItem {
  /// !
  /// @property	audioTimePitchAlgorithm
  /// @abstract	Indicates the processing algorithm used to manage audio pitch at varying rates and for scaled audio edits.
  /// @discussion
  /// Constants for various time pitch algorithms, e.g. AVAudioTimePitchSpectral, are defined in AVAudioProcessingSettings.h.
  /// The default value for applications linked on or after iOS 15.0 or macOS 12.0 is AVAudioTimePitchAlgorithmTimeDomain. For iOS versions prior to 15.0 the default value is AVAudioTimePitchAlgorithmLowQualityZeroLatency.
  /// For macOS versions prior to 12.0 the default value is AVAudioTimePitchAlgorithmSpectral.
  objc.NSString get audioTimePitchAlgorithm {
    objc.checkOsVersionInternal(
      'AVPlayerItem.audioTimePitchAlgorithm',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_audioTimePitchAlgorithm);
    return objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property	audioTimePitchAlgorithm
  /// @abstract	Indicates the processing algorithm used to manage audio pitch at varying rates and for scaled audio edits.
  /// @discussion
  /// Constants for various time pitch algorithms, e.g. AVAudioTimePitchSpectral, are defined in AVAudioProcessingSettings.h.
  /// The default value for applications linked on or after iOS 15.0 or macOS 12.0 is AVAudioTimePitchAlgorithmTimeDomain. For iOS versions prior to 15.0 the default value is AVAudioTimePitchAlgorithmLowQualityZeroLatency.
  /// For macOS versions prior to 12.0 the default value is AVAudioTimePitchAlgorithmSpectral.
  set audioTimePitchAlgorithm(objc.NSString value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setAudioTimePitchAlgorithm:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setAudioTimePitchAlgorithm_, value.ref.pointer);
  }

  /// !
  /// @property audioSpatializationAllowed
  /// @abstract Indicates whether audio spatialization is allowed
  /// @discussion
  /// When audio spatialization is allowed for an AVPlayerItem, the AVPlayer may render multichannel audio if available even if the output device doesn't support multichannel audio on its own, via use of a synthetic channel layout. When audio spatialization is not allowed, the AVPlayer must render audio with a channel layout that best matches the capabilities of the output device. This property is not observable. Defaults to YES.
  bool get audioSpatializationAllowed {
    objc.checkOsVersionInternal(
      'AVPlayerItem.isAudioSpatializationAllowed',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isAudioSpatializationAllowed);
  }

  /// !
  /// @property audioSpatializationAllowed
  /// @abstract Indicates whether audio spatialization is allowed
  /// @discussion
  /// When audio spatialization is allowed for an AVPlayerItem, the AVPlayer may render multichannel audio if available even if the output device doesn't support multichannel audio on its own, via use of a synthetic channel layout. When audio spatialization is not allowed, the AVPlayer must render audio with a channel layout that best matches the capabilities of the output device. This property is not observable. Defaults to YES.
  set audioSpatializationAllowed(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setAudioSpatializationAllowed:',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAudioSpatializationAllowed_, value);
  }

  /// !
  /// @property allowedAudioSpatializationFormats
  /// @abstract Indicates the source audio channel layouts allowed by the receiver for spatialization.
  /// @discussion
  /// Spatialization uses psychoacoustic methods to create a more immersive audio rendering when the content is played on specialized headphones and speaker arrangements. When an AVPlayerItem's allowedAudioSpatializationFormats property is set to AVAudioSpatializationFormatMonoAndStereo the AVPlayer will attempt to spatialize content tagged with a stereo channel layout, two-channel content with no layout specified as well as mono. It is considered incorrect to render a binaural recording with spatialization. A binaural recording is captured using two carefully placed microphones at each ear where the intent, when played on headphones, is to reproduce a naturally occurring spatial effect. Content tagged with a binaural channel layout will ignore this property value. When an AVPlayerItem's allowedAudioSpatializationFormats property is set to AVAudioSpatializationFormatMultichannel the AVPlayer will attempt to spatialize any decodable multichannel layout. Setting this property to AVAudioSpatializationFormatMonoStereoAndMultichannel indicates that the sender allows the AVPlayer to spatialize any decodable mono, stereo or multichannel layout. This property is not observable. The default value for this property with video content is AVAudioSpatializationFormatMonoStereoAndMultichannel. Otherwise, audio only content default value is AVAudioSpatializationFormatMultichannel.
  AVAudioSpatializationFormats get allowedAudioSpatializationFormats {
    objc.checkOsVersionInternal(
      'AVPlayerItem.allowedAudioSpatializationFormats',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    final _ret = _objc_msgSend_2s2a50(this.ref.pointer, _sel_allowedAudioSpatializationFormats);
    return AVAudioSpatializationFormats.fromValue(_ret);
  }

  /// !
  /// @property allowedAudioSpatializationFormats
  /// @abstract Indicates the source audio channel layouts allowed by the receiver for spatialization.
  /// @discussion
  /// Spatialization uses psychoacoustic methods to create a more immersive audio rendering when the content is played on specialized headphones and speaker arrangements. When an AVPlayerItem's allowedAudioSpatializationFormats property is set to AVAudioSpatializationFormatMonoAndStereo the AVPlayer will attempt to spatialize content tagged with a stereo channel layout, two-channel content with no layout specified as well as mono. It is considered incorrect to render a binaural recording with spatialization. A binaural recording is captured using two carefully placed microphones at each ear where the intent, when played on headphones, is to reproduce a naturally occurring spatial effect. Content tagged with a binaural channel layout will ignore this property value. When an AVPlayerItem's allowedAudioSpatializationFormats property is set to AVAudioSpatializationFormatMultichannel the AVPlayer will attempt to spatialize any decodable multichannel layout. Setting this property to AVAudioSpatializationFormatMonoStereoAndMultichannel indicates that the sender allows the AVPlayer to spatialize any decodable mono, stereo or multichannel layout. This property is not observable. The default value for this property with video content is AVAudioSpatializationFormatMonoStereoAndMultichannel. Otherwise, audio only content default value is AVAudioSpatializationFormatMultichannel.
  set allowedAudioSpatializationFormats(AVAudioSpatializationFormats value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setAllowedAudioSpatializationFormats:',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    _objc_msgSend_12f6ne(this.ref.pointer, _sel_setAllowedAudioSpatializationFormats_, value.value);
  }

  /// !
  /// @property audioMix
  /// @abstract Indicates the audio mix parameters to be applied during playback
  /// @discussion
  /// The inputParameters of the AVAudioMix must have trackIDs that correspond to a track of the receiver's asset. Otherwise they will be ignored. (See AVAudioMix.h for the declaration of AVAudioMixInputParameters and AVPlayerItem's asset property.)
  AVAudioMix? get audioMix {
    objc.checkOsVersionInternal('AVPlayerItem.audioMix', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_audioMix);
    return _ret.address == 0 ? null : AVAudioMix.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property audioMix
  /// @abstract Indicates the audio mix parameters to be applied during playback
  /// @discussion
  /// The inputParameters of the AVAudioMix must have trackIDs that correspond to a track of the receiver's asset. Otherwise they will be ignored. (See AVAudioMix.h for the declaration of AVAudioMixInputParameters and AVPlayerItem's asset property.)
  set audioMix(AVAudioMix? value) {
    objc.checkOsVersionInternal('AVPlayerItem.setAudioMix:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setAudioMix_, value?.ref.pointer ?? ffi.nullptr);
  }
}

late final _sel_loadedTimeRanges = objc.registerName("loadedTimeRanges");
late final _sel_isPlaybackLikelyToKeepUp = objc.registerName("isPlaybackLikelyToKeepUp");
late final _sel_isPlaybackBufferFull = objc.registerName("isPlaybackBufferFull");
late final _sel_isPlaybackBufferEmpty = objc.registerName("isPlaybackBufferEmpty");
late final _sel_canUseNetworkResourcesForLiveStreamingWhilePaused = objc.registerName(
  "canUseNetworkResourcesForLiveStreamingWhilePaused",
);
late final _sel_setCanUseNetworkResourcesForLiveStreamingWhilePaused_ = objc.registerName(
  "setCanUseNetworkResourcesForLiveStreamingWhilePaused:",
);
late final _sel_preferredForwardBufferDuration = objc.registerName("preferredForwardBufferDuration");
final _objc_msgSend_1ukqyt8 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_1ukqyt8Fpret = objc.msgSendFpretPointer
    .cast<ffi.NativeFunction<ffi.Double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setPreferredForwardBufferDuration_ = objc.registerName("setPreferredForwardBufferDuration:");
final _objc_msgSend_hwm8nu = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Double)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double)>();

/// AVPlayerItemPlayability
extension AVPlayerItemPlayability on AVPlayerItem {
  /// !
  /// @property loadedTimeRanges
  /// @abstract This property provides a collection of time ranges for which the player has the media data readily available. The ranges provided might be discontinuous.
  /// @discussion Returns an NSArray of NSValues containing CMTimeRanges.
  objc.NSArray get loadedTimeRanges {
    objc.checkOsVersionInternal('AVPlayerItem.loadedTimeRanges', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_loadedTimeRanges);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property playbackLikelyToKeepUp
  /// @abstract Indicates whether the item will likely play through without stalling.
  /// @discussion This property communicates a prediction of playability. Factors considered in this prediction
  /// include I/O throughput and media decode performance. It is possible for playbackLikelyToKeepUp to
  /// indicate NO while the property playbackBufferFull indicates YES. In this event the playback buffer has
  /// reached capacity but there isn't the statistical data to support a prediction that playback is likely to
  /// keep up. It is left to the application programmer to decide to continue media playback or not.
  /// See playbackBufferFull below.
  bool get playbackLikelyToKeepUp {
    objc.checkOsVersionInternal(
      'AVPlayerItem.isPlaybackLikelyToKeepUp',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isPlaybackLikelyToKeepUp);
  }

  /// !
  /// @property playbackBufferFull
  /// @abstract Indicates that the internal media buffer is full and that further I/O is suspended.
  /// @discussion This property reports that the data buffer used for playback has reach capacity.
  /// Despite the playback buffer reaching capacity there might not exist sufficient statistical
  /// data to support a playbackLikelyToKeepUp prediction of YES. See playbackLikelyToKeepUp above.
  bool get playbackBufferFull {
    objc.checkOsVersionInternal(
      'AVPlayerItem.isPlaybackBufferFull',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isPlaybackBufferFull);
  }

  /// isPlaybackBufferEmpty
  bool get playbackBufferEmpty {
    objc.checkOsVersionInternal(
      'AVPlayerItem.isPlaybackBufferEmpty',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isPlaybackBufferEmpty);
  }

  /// !
  /// @property canUseNetworkResourcesForLiveStreamingWhilePaused
  /// @abstract Indicates whether the player item can use network resources to keep playback state up to date while paused
  /// @discussion
  /// For live streaming content, the player item may need to use extra networking and power resources to keep playback state up to date when paused.  For example, when this property is set to YES, the seekableTimeRanges property will be periodically updated to reflect the current state of the live stream.
  ///
  /// For clients linked on or after macOS 10.11 or iOS 9.0, the default value is NO.  To minimize power usage, avoid setting this property to YES when you do not need playback state to stay up to date while paused.
  bool get canUseNetworkResourcesForLiveStreamingWhilePaused {
    objc.checkOsVersionInternal(
      'AVPlayerItem.canUseNetworkResourcesForLiveStreamingWhilePaused',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canUseNetworkResourcesForLiveStreamingWhilePaused);
  }

  /// !
  /// @property canUseNetworkResourcesForLiveStreamingWhilePaused
  /// @abstract Indicates whether the player item can use network resources to keep playback state up to date while paused
  /// @discussion
  /// For live streaming content, the player item may need to use extra networking and power resources to keep playback state up to date when paused.  For example, when this property is set to YES, the seekableTimeRanges property will be periodically updated to reflect the current state of the live stream.
  ///
  /// For clients linked on or after macOS 10.11 or iOS 9.0, the default value is NO.  To minimize power usage, avoid setting this property to YES when you do not need playback state to stay up to date while paused.
  set canUseNetworkResourcesForLiveStreamingWhilePaused(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setCanUseNetworkResourcesForLiveStreamingWhilePaused:',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setCanUseNetworkResourcesForLiveStreamingWhilePaused_, value);
  }

  /// !
  /// @property	preferredForwardBufferDuration
  /// @abstract	Indicates the media duration the caller prefers the player to buffer from the network ahead of the playhead to guard against playback disruption.
  /// @discussion	The value is in seconds. If it is set to 0, the player will choose an appropriate level of buffering for most use cases.
  /// Note that setting this property to a low value will increase the chance that playback will stall and re-buffer, while setting it to a high value will increase demand on system resources.
  /// Note that the system may buffer less than the value of this property in order to manage resource consumption.
  double get preferredForwardBufferDuration {
    objc.checkOsVersionInternal(
      'AVPlayerItem.preferredForwardBufferDuration',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_preferredForwardBufferDuration)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_preferredForwardBufferDuration);
  }

  /// !
  /// @property	preferredForwardBufferDuration
  /// @abstract	Indicates the media duration the caller prefers the player to buffer from the network ahead of the playhead to guard against playback disruption.
  /// @discussion	The value is in seconds. If it is set to 0, the player will choose an appropriate level of buffering for most use cases.
  /// Note that setting this property to a low value will increase the chance that playback will stall and re-buffer, while setting it to a high value will increase demand on system resources.
  /// Note that the system may buffer less than the value of this property in order to manage resource consumption.
  set preferredForwardBufferDuration(double value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setPreferredForwardBufferDuration:',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    _objc_msgSend_hwm8nu(this.ref.pointer, _sel_setPreferredForwardBufferDuration_, value);
  }
}

late final _sel_preferredPeakBitRate = objc.registerName("preferredPeakBitRate");
late final _sel_setPreferredPeakBitRate_ = objc.registerName("setPreferredPeakBitRate:");
late final _sel_preferredPeakBitRateForExpensiveNetworks = objc.registerName(
  "preferredPeakBitRateForExpensiveNetworks",
);
late final _sel_setPreferredPeakBitRateForExpensiveNetworks_ = objc.registerName(
  "setPreferredPeakBitRateForExpensiveNetworks:",
);
late final _sel_preferredMaximumResolution = objc.registerName("preferredMaximumResolution");
late final _sel_setPreferredMaximumResolution_ = objc.registerName("setPreferredMaximumResolution:");
final _objc_msgSend_13lgpwz = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGSize)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGSize)>();
late final _sel_preferredMaximumResolutionForExpensiveNetworks = objc.registerName(
  "preferredMaximumResolutionForExpensiveNetworks",
);
late final _sel_setPreferredMaximumResolutionForExpensiveNetworks_ = objc.registerName(
  "setPreferredMaximumResolutionForExpensiveNetworks:",
);
late final _sel_startsOnFirstEligibleVariant = objc.registerName("startsOnFirstEligibleVariant");
late final _sel_setStartsOnFirstEligibleVariant_ = objc.registerName("setStartsOnFirstEligibleVariant:");

/// !
/// @enum			AVVariantPreferences
/// @abstract		These constants can be used in any combination as the value of variantPreferences.
///
/// @constant		AVVariantPreferenceNone
/// Indicates that only the basic behaviors of the player for choosing among variants should be applied, including considerations of available bandwidth, compatibility of the indicated codec or codecs, the dimensions of visual output, and the number of available audio output channels.
/// @constant		AVVariantPreferenceScalabilityToLosslessAudio
/// Directs the item to permit the use of variants with lossless audio encodings, if sufficient bandwidth is available for their use.
enum AVVariantPreferences {
  AVVariantPreferenceNone(0),
  AVVariantPreferenceScalabilityToLosslessAudio(1);

  final int value;
  const AVVariantPreferences(this.value);

  static AVVariantPreferences fromValue(int value) => switch (value) {
    0 => AVVariantPreferenceNone,
    1 => AVVariantPreferenceScalabilityToLosslessAudio,
    _ => throw ArgumentError('Unknown value for AVVariantPreferences: $value'),
  };
}

late final _sel_variantPreferences = objc.registerName("variantPreferences");
final _objc_msgSend_2o73ov = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setVariantPreferences_ = objc.registerName("setVariantPreferences:");
final _objc_msgSend_1o3ak8z = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.UnsignedLong)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// AVPlayerItemVariantControl
extension AVPlayerItemVariantControl on AVPlayerItem {
  /// !
  /// @property preferredPeakBitRate
  /// @abstract Indicates the desired limit of network bandwidth consumption for this item.
  ///
  /// @discussion
  /// Set preferredPeakBitRate to non-zero to indicate that the player should attempt to limit item playback to that bit rate, expressed in bits per second.
  ///
  /// If network bandwidth consumption cannot be lowered to meet the preferredPeakBitRate, it will be reduced as much as possible while continuing to play the item.
  double get preferredPeakBitRate {
    objc.checkOsVersionInternal(
      'AVPlayerItem.preferredPeakBitRate',
      iOS: (false, (8, 0, 0)),
      macOS: (false, (10, 10, 0)),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_preferredPeakBitRate)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_preferredPeakBitRate);
  }

  /// !
  /// @property preferredPeakBitRate
  /// @abstract Indicates the desired limit of network bandwidth consumption for this item.
  ///
  /// @discussion
  /// Set preferredPeakBitRate to non-zero to indicate that the player should attempt to limit item playback to that bit rate, expressed in bits per second.
  ///
  /// If network bandwidth consumption cannot be lowered to meet the preferredPeakBitRate, it will be reduced as much as possible while continuing to play the item.
  set preferredPeakBitRate(double value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setPreferredPeakBitRate:',
      iOS: (false, (8, 0, 0)),
      macOS: (false, (10, 10, 0)),
    );
    _objc_msgSend_hwm8nu(this.ref.pointer, _sel_setPreferredPeakBitRate_, value);
  }

  /// !
  /// @property preferredPeakBitRateForExpensiveNetworks
  /// @abstract Indicates the desired limit of network bandwidth consumption for this item over expensive networks.
  ///
  /// @discussion
  /// When preferredPeakBitRateForExpensiveNetworks is set to non-zero, the player will attempt to limit item playback to that bit rate
  /// when streaming over an expensive network, such as when using a cellular data plan.  (See -[NWPath isExpensive])
  ///
  /// If network bandwidth consumption cannot be lowered to meet the preferredPeakBitRateForExpensiveNetworks, it will be reduced as much as possible while continuing to play the item.
  ///
  /// Note that preferredPeakBitRate still applies unconditionally.  If preferredPeakBitRateForExpensiveNetworks is less restrictive (greater) than preferredPeakBitRate,
  /// preferredPeakBitRateForExpensiveNetworks has no practical effect.
  double get preferredPeakBitRateForExpensiveNetworks {
    objc.checkOsVersionInternal(
      'AVPlayerItem.preferredPeakBitRateForExpensiveNetworks',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_preferredPeakBitRateForExpensiveNetworks)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_preferredPeakBitRateForExpensiveNetworks);
  }

  /// !
  /// @property preferredPeakBitRateForExpensiveNetworks
  /// @abstract Indicates the desired limit of network bandwidth consumption for this item over expensive networks.
  ///
  /// @discussion
  /// When preferredPeakBitRateForExpensiveNetworks is set to non-zero, the player will attempt to limit item playback to that bit rate
  /// when streaming over an expensive network, such as when using a cellular data plan.  (See -[NWPath isExpensive])
  ///
  /// If network bandwidth consumption cannot be lowered to meet the preferredPeakBitRateForExpensiveNetworks, it will be reduced as much as possible while continuing to play the item.
  ///
  /// Note that preferredPeakBitRate still applies unconditionally.  If preferredPeakBitRateForExpensiveNetworks is less restrictive (greater) than preferredPeakBitRate,
  /// preferredPeakBitRateForExpensiveNetworks has no practical effect.
  set preferredPeakBitRateForExpensiveNetworks(double value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setPreferredPeakBitRateForExpensiveNetworks:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_hwm8nu(this.ref.pointer, _sel_setPreferredPeakBitRateForExpensiveNetworks_, value);
  }

  /// !
  /// @property preferredMaximumResolution
  /// @abstract Indicates a preferred upper limit on the resolution of the video to be downloaded (or otherwise transferred) and rendered by the player.
  /// @discussion
  /// The default value is CGSizeZero, which indicates that the client enforces no limit on video resolution. Other values indicate a preferred maximum video resolution.
  /// It only applies to HTTP Live Streaming asset.
  objc.CGSize get preferredMaximumResolution {
    objc.checkOsVersionInternal(
      'AVPlayerItem.preferredMaximumResolution',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    final _ptr = pkg_ffi.calloc<objc.CGSize>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1vdfkenStret(_ptr, this.ref.pointer, _sel_preferredMaximumResolution)
        : _ptr.ref = _objc_msgSend_1vdfken(this.ref.pointer, _sel_preferredMaximumResolution);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGSize>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGSize>(_finalizable);
  }

  /// !
  /// @property preferredMaximumResolution
  /// @abstract Indicates a preferred upper limit on the resolution of the video to be downloaded (or otherwise transferred) and rendered by the player.
  /// @discussion
  /// The default value is CGSizeZero, which indicates that the client enforces no limit on video resolution. Other values indicate a preferred maximum video resolution.
  /// It only applies to HTTP Live Streaming asset.
  set preferredMaximumResolution(objc.CGSize value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setPreferredMaximumResolution:',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    _objc_msgSend_13lgpwz(this.ref.pointer, _sel_setPreferredMaximumResolution_, value);
  }

  /// !
  /// @property preferredMaximumResolutionForExpensiveNetworks
  /// @abstract Indicates a preferred upper limit on the resolution of the video to be downloaded that applies only when the download occurs over expensive networks.
  /// @discussion
  /// The default value is CGSizeZero, which indicates that the client enforces no limit on video resolution. Other values indicate a preferred maximum video resolution.
  /// This limit applies only when streaming over an expensive network, such as when using a cellular data plan.  (See -[NWPath isExpensive])
  ///
  /// It only applies to HTTP Live Streaming asset.
  ///
  /// Note that preferredMaximumResolution still applies unconditionally.  If preferredMaximumResolutionForExpensiveNetworks is less restrictive (higher resolution)
  /// than preferredMaximumResolution, preferredMaximumResolutionForExpensiveNetworks has no practical effect.
  objc.CGSize get preferredMaximumResolutionForExpensiveNetworks {
    objc.checkOsVersionInternal(
      'AVPlayerItem.preferredMaximumResolutionForExpensiveNetworks',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    final _ptr = pkg_ffi.calloc<objc.CGSize>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1vdfkenStret(_ptr, this.ref.pointer, _sel_preferredMaximumResolutionForExpensiveNetworks)
        : _ptr.ref = _objc_msgSend_1vdfken(this.ref.pointer, _sel_preferredMaximumResolutionForExpensiveNetworks);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGSize>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGSize>(_finalizable);
  }

  /// !
  /// @property preferredMaximumResolutionForExpensiveNetworks
  /// @abstract Indicates a preferred upper limit on the resolution of the video to be downloaded that applies only when the download occurs over expensive networks.
  /// @discussion
  /// The default value is CGSizeZero, which indicates that the client enforces no limit on video resolution. Other values indicate a preferred maximum video resolution.
  /// This limit applies only when streaming over an expensive network, such as when using a cellular data plan.  (See -[NWPath isExpensive])
  ///
  /// It only applies to HTTP Live Streaming asset.
  ///
  /// Note that preferredMaximumResolution still applies unconditionally.  If preferredMaximumResolutionForExpensiveNetworks is less restrictive (higher resolution)
  /// than preferredMaximumResolution, preferredMaximumResolutionForExpensiveNetworks has no practical effect.
  set preferredMaximumResolutionForExpensiveNetworks(objc.CGSize value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setPreferredMaximumResolutionForExpensiveNetworks:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_13lgpwz(this.ref.pointer, _sel_setPreferredMaximumResolutionForExpensiveNetworks_, value);
  }

  /// !
  /// @property		startsOnFirstEligibleVariant
  /// @abstract		Directs the player to start playback with the first eligible variant  that appears in the stream's master playlist.
  /// @discussion
  /// This property influences AVPlayer's algorithm for selecting which of the eligible variant streams in an HTTP Live Streaming master playlist is selected when playback first begins.
  /// In all cases, AVPlayer may switch to other variants during playback.
  ///
  /// On releases prior to macOS 10.15, iOS 13, tvOS 13 and watchOS 6, AVPlayer starts HLS playback with the first eligible variant in the master playlist.
  /// On releases starting with macOS 10.15, iOS 13, tvOS 13 and watchOS 6, AVPlayer starts HLS playback by choosing an initial variant that optimizes the startup experience.
  /// On releases starting with macOS 11.0, iOS 14, tvOS 14 and watchOS 7, applications may set this property to YES to request that AVPlayer use the previous behaviour of using the first eligible variant in the master playlist. This would be appropriate, for example, for applications which wish to control initial variant selection by ordering the variants in the master playlist.
  ///
  /// Note that changing this property may impact stream startup performance and quality. In order to be effective this property must be set before initial variant selection occurs.
  /// This property only applies to HTTP Live Streaming assets. The default value of this property is NO.
  bool get startsOnFirstEligibleVariant {
    objc.checkOsVersionInternal(
      'AVPlayerItem.startsOnFirstEligibleVariant',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_startsOnFirstEligibleVariant);
  }

  /// !
  /// @property		startsOnFirstEligibleVariant
  /// @abstract		Directs the player to start playback with the first eligible variant  that appears in the stream's master playlist.
  /// @discussion
  /// This property influences AVPlayer's algorithm for selecting which of the eligible variant streams in an HTTP Live Streaming master playlist is selected when playback first begins.
  /// In all cases, AVPlayer may switch to other variants during playback.
  ///
  /// On releases prior to macOS 10.15, iOS 13, tvOS 13 and watchOS 6, AVPlayer starts HLS playback with the first eligible variant in the master playlist.
  /// On releases starting with macOS 10.15, iOS 13, tvOS 13 and watchOS 6, AVPlayer starts HLS playback by choosing an initial variant that optimizes the startup experience.
  /// On releases starting with macOS 11.0, iOS 14, tvOS 14 and watchOS 7, applications may set this property to YES to request that AVPlayer use the previous behaviour of using the first eligible variant in the master playlist. This would be appropriate, for example, for applications which wish to control initial variant selection by ordering the variants in the master playlist.
  ///
  /// Note that changing this property may impact stream startup performance and quality. In order to be effective this property must be set before initial variant selection occurs.
  /// This property only applies to HTTP Live Streaming assets. The default value of this property is NO.
  set startsOnFirstEligibleVariant(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setStartsOnFirstEligibleVariant:',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setStartsOnFirstEligibleVariant_, value);
  }

  /// !
  /// @property		variantPreferences
  /// @abstract		Indicates preferences for variant switching.
  /// @discussion
  /// Changing variant preferences during playback may result in a variant switch.
  /// The default value is AVVariantPreferenceNone.
  AVVariantPreferences get variantPreferences {
    objc.checkOsVersionInternal(
      'AVPlayerItem.variantPreferences',
      iOS: (false, (14, 5, 0)),
      macOS: (false, (11, 3, 0)),
    );
    final _ret = _objc_msgSend_2o73ov(this.ref.pointer, _sel_variantPreferences);
    return AVVariantPreferences.fromValue(_ret);
  }

  /// !
  /// @property		variantPreferences
  /// @abstract		Indicates preferences for variant switching.
  /// @discussion
  /// Changing variant preferences during playback may result in a variant switch.
  /// The default value is AVVariantPreferenceNone.
  set variantPreferences(AVVariantPreferences value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setVariantPreferences:',
      iOS: (false, (14, 5, 0)),
      macOS: (false, (11, 3, 0)),
    );
    _objc_msgSend_1o3ak8z(this.ref.pointer, _sel_setVariantPreferences_, value.value);
  }
}

/// WARNING: AVMediaSelectionOption is a stub. To generate bindings for this class, include
/// AVMediaSelectionOption in your config's objc-interfaces list.
///
/// AVMediaSelectionOption
class AVMediaSelectionOption extends objc.ObjCObjectBase {
  AVMediaSelectionOption._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMediaSelectionOption] that points to the same underlying object as [other].
  AVMediaSelectionOption.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMediaSelectionOption] that wraps the given raw object pointer.
  AVMediaSelectionOption.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_selectMediaOption_inMediaSelectionGroup_ = objc.registerName(
  "selectMediaOption:inMediaSelectionGroup:",
);
final _objc_msgSend_pfv6jd = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
late final _sel_selectMediaOptionAutomaticallyInMediaSelectionGroup_ = objc.registerName(
  "selectMediaOptionAutomaticallyInMediaSelectionGroup:",
);
late final _sel_currentMediaSelection = objc.registerName("currentMediaSelection");

/// AVPlayerItemMediaSelection
extension AVPlayerItemMediaSelection on AVPlayerItem {
  /// !
  /// @method		selectMediaOption:inMediaSelectionGroup:
  /// @abstract
  /// Selects the media option described by the specified instance of AVMediaSelectionOption in the specified AVMediaSelectionGroup and deselects all other options in that group.
  /// @param 		mediaSelectionOption	The option to select.
  /// @param 		mediaSelectionGroup		The media selection group, obtained from the receiver's asset, that contains the specified option.
  /// @discussion
  /// If the specified media selection option isn't a member of the specified media selection group, no change in presentation state will result.
  /// If the value of the property allowsEmptySelection of the AVMediaSelectionGroup is YES, you can pass nil for mediaSelectionOption to deselect
  /// all media selection options in the group.
  /// Note that if multiple options within a group meet your criteria for selection according to locale or other considerations, and if these options are otherwise indistinguishable to you according to media characteristics that are meaningful for your application, content is typically authored so that the first available option that meets your criteria is appropriate for selection.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void selectMediaOption(
    AVMediaSelectionOption? mediaSelectionOption, {
    required AVMediaSelectionGroup inMediaSelectionGroup,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.selectMediaOption:inMediaSelectionGroup:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    _objc_msgSend_pfv6jd(
      this.ref.pointer,
      _sel_selectMediaOption_inMediaSelectionGroup_,
      mediaSelectionOption?.ref.pointer ?? ffi.nullptr,
      inMediaSelectionGroup.ref.pointer,
    );
  }

  /// !
  /// @method		selectMediaOptionAutomaticallyInMediaSelectionGroup:
  /// @abstract
  /// Selects the media option in the specified media selection group that best matches the AVPlayer's current automatic selection criteria. Also allows automatic selection to be re-applied to the specified group subsequently if the relevant criteria are changed.
  /// @param 		mediaSelectionGroup		The media selection group, obtained from the receiver's asset, that contains the specified option.
  /// @discussion
  /// Has no effect unless the appliesMediaSelectionCriteriaAutomatically property of the associated AVPlayer is YES and unless automatic media selection has previously been overridden via -[AVPlayerItem selectMediaOption:inMediaSelectionGroup:].
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void selectMediaOptionAutomaticallyInMediaSelectionGroup(AVMediaSelectionGroup mediaSelectionGroup) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.selectMediaOptionAutomaticallyInMediaSelectionGroup:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_xtuoz7(
      this.ref.pointer,
      _sel_selectMediaOptionAutomaticallyInMediaSelectionGroup_,
      mediaSelectionGroup.ref.pointer,
    );
  }

  /// !
  /// @property		currentMediaSelection
  /// @abstract		Provides an instance of AVMediaSelection carrying current selections for each of the receiver's media selection groups.
  AVMediaSelection get currentMediaSelection {
    objc.checkOsVersionInternal(
      'AVPlayerItem.currentMediaSelection',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_currentMediaSelection);
    return AVMediaSelection.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVPlayerItemAccessLog is a stub. To generate bindings for this class, include
/// AVPlayerItemAccessLog in your config's objc-interfaces list.
///
/// !
/// @class			AVPlayerItemAccessLog
/// @abstract		An AVPlayerItemAccessLog provides methods to retrieve the access log in a format suitable for serialization.
/// @discussion	An AVPlayerItemAccessLog acculumulates key metrics about network playback and presents them as a collection
/// of AVPlayerItemAccessLogEvent instances. Each AVPlayerItemAccessLogEvent instance collates the data
/// that relates to each uninterrupted period of playback.
///
/// Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.
class AVPlayerItemAccessLog extends objc.NSObject implements objc.NSCopying {
  AVPlayerItemAccessLog._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVPlayerItemAccessLog', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVPlayerItemAccessLog] that points to the same underlying object as [other].
  AVPlayerItemAccessLog.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerItemAccessLog] that wraps the given raw object pointer.
  AVPlayerItemAccessLog.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_accessLog = objc.registerName("accessLog");

/// WARNING: AVPlayerItemErrorLog is a stub. To generate bindings for this class, include
/// AVPlayerItemErrorLog in your config's objc-interfaces list.
///
/// !
/// @class			AVPlayerItemErrorLog
/// @abstract		An AVPlayerItemErrorLog provides methods to retrieve the error log in a format suitable for serialization.
/// @discussion	An AVPlayerItemErrorLog provides data to identify if, and when, network resource playback failures occured.
///
/// Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.
class AVPlayerItemErrorLog extends objc.NSObject implements objc.NSCopying {
  AVPlayerItemErrorLog._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVPlayerItemErrorLog', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVPlayerItemErrorLog] that points to the same underlying object as [other].
  AVPlayerItemErrorLog.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerItemErrorLog] that wraps the given raw object pointer.
  AVPlayerItemErrorLog.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_errorLog = objc.registerName("errorLog");

/// AVPlayerItemLogging
extension AVPlayerItemLogging on AVPlayerItem {
  /// !
  /// @method		accessLog
  /// @abstract		Returns an object that represents a snapshot of the network access log. Can be nil.
  /// @discussion	An AVPlayerItemAccessLog provides methods to retrieve the network access log in a format suitable for serialization.
  /// If nil is returned then there is no logging information currently available for this AVPlayerItem.
  /// An AVPlayerItemNewAccessLogEntryNotification will be posted when new logging information becomes available. However, accessLog might already return a non-nil value even before the first notification is posted.
  /// @result		An autoreleased AVPlayerItemAccessLog instance.
  AVPlayerItemAccessLog? accessLog() {
    objc.checkOsVersionInternal('AVPlayerItem.accessLog', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_accessLog);
    return _ret.address == 0 ? null : AVPlayerItemAccessLog.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		errorLog
  /// @abstract		Returns an object that represents a snapshot of the error log. Can be nil.
  /// @discussion	An AVPlayerItemErrorLog provides methods to retrieve the error log in a format suitable for serialization.
  /// If nil is returned then there is no logging information currently available for this AVPlayerItem.
  /// @result		An autoreleased AVPlayerItemErrorLog instance.
  AVPlayerItemErrorLog? errorLog() {
    objc.checkOsVersionInternal('AVPlayerItem.errorLog', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_errorLog);
    return _ret.address == 0 ? null : AVPlayerItemErrorLog.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVPlayerItemOutput is a stub. To generate bindings for this class, include
/// AVPlayerItemOutput in your config's objc-interfaces list.
///
/// AVPlayerItemOutput
class AVPlayerItemOutput extends objc.ObjCObjectBase {
  AVPlayerItemOutput._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerItemOutput] that points to the same underlying object as [other].
  AVPlayerItemOutput.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerItemOutput] that wraps the given raw object pointer.
  AVPlayerItemOutput.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_addOutput_ = objc.registerName("addOutput:");
late final _sel_removeOutput_ = objc.registerName("removeOutput:");
late final _sel_outputs = objc.registerName("outputs");

/// AVPlayerItemOutputs
extension AVPlayerItemOutputs on AVPlayerItem {
  /// !
  /// @method		addOutput:
  /// @abstract		Adds the specified instance of AVPlayerItemOutput to the receiver's collection of outputs.
  /// @discussion
  /// The class of AVPlayerItemOutput provided dictates the data structure that decoded samples are vended in.
  ///
  /// When an AVPlayerItemOutput is associated with an AVPlayerItem, samples are provided for a media type in accordance with the rules for mixing, composition, or exclusion that the AVPlayer honors among multiple enabled tracks of that media type for its own rendering purposes. For example, video media will be composed according to the instructions provided via AVPlayerItem.videoComposition, if present. Audio media will be mixed according to the parameters provided via AVPlayerItem.audioMix, if present.
  /// @param			output
  /// An instance of AVPlayerItemOutput
  void addOutput(AVPlayerItemOutput output) {
    objc.checkOsVersionInternal('AVPlayerItem.addOutput:', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_addOutput_, output.ref.pointer);
  }

  /// !
  /// @method		removeOutput:
  /// @abstract		Removes the specified instance of AVPlayerItemOutput from the receiver's collection of outputs.
  /// @param			output
  /// An instance of AVPlayerItemOutput
  void removeOutput(AVPlayerItemOutput output) {
    objc.checkOsVersionInternal('AVPlayerItem.removeOutput:', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_removeOutput_, output.ref.pointer);
  }

  /// !
  /// @property		outputs
  /// @abstract		The collection of associated outputs.
  objc.NSArray get outputs {
    objc.checkOsVersionInternal('AVPlayerItem.outputs', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_outputs);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVPlayerItemMediaDataCollector is a stub. To generate bindings for this class, include
/// AVPlayerItemMediaDataCollector in your config's objc-interfaces list.
///
/// AVPlayerItemMediaDataCollector
class AVPlayerItemMediaDataCollector extends objc.ObjCObjectBase {
  AVPlayerItemMediaDataCollector._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerItemMediaDataCollector] that points to the same underlying object as [other].
  AVPlayerItemMediaDataCollector.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerItemMediaDataCollector] that wraps the given raw object pointer.
  AVPlayerItemMediaDataCollector.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_addMediaDataCollector_ = objc.registerName("addMediaDataCollector:");
late final _sel_removeMediaDataCollector_ = objc.registerName("removeMediaDataCollector:");
late final _sel_mediaDataCollectors = objc.registerName("mediaDataCollectors");

/// AVPlayerItemMediaDataCollectors
extension AVPlayerItemMediaDataCollectors on AVPlayerItem {
  /// !
  /// @method		addMediaDataCollector:
  /// @abstract		Adds the specified instance of AVPlayerItemMediaDataCollector to the receiver's collection of mediaDataCollectors.
  /// @discussion
  /// This method may incur additional I/O to collect the requested media data asynchronously.
  /// @param			collector
  /// An instance of AVPlayerItemMediaDataCollector
  void addMediaDataCollector(AVPlayerItemMediaDataCollector collector) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.addMediaDataCollector:',
      iOS: (false, (9, 3, 0)),
      macOS: (false, (10, 11, 3)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_addMediaDataCollector_, collector.ref.pointer);
  }

  /// !
  /// @method		removeMediaDataCollector:
  /// @abstract		Removes the specified instance of AVPlayerItemMediaDataCollector from the receiver's collection of mediaDataCollectors.
  /// @param			collector
  /// An instance of AVPlayerItemMediaDataCollector
  void removeMediaDataCollector(AVPlayerItemMediaDataCollector collector) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.removeMediaDataCollector:',
      iOS: (false, (9, 3, 0)),
      macOS: (false, (10, 11, 3)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_removeMediaDataCollector_, collector.ref.pointer);
  }

  /// !
  /// @property		mediaDataCollectors
  /// @abstract		The collection of associated mediaDataCollectors.
  objc.NSArray get mediaDataCollectors {
    objc.checkOsVersionInternal(
      'AVPlayerItem.mediaDataCollectors',
      iOS: (false, (9, 3, 0)),
      macOS: (false, (10, 11, 3)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_mediaDataCollectors);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

late final _sel_seekToTime_ = objc.registerName("seekToTime:");
late final _sel_seekToTime_toleranceBefore_toleranceAfter_ = objc.registerName(
  "seekToTime:toleranceBefore:toleranceAfter:",
);
final _objc_msgSend_1up52l2 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, CMTime, CMTime, CMTime)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, CMTime, CMTime, CMTime)>();
late final _sel_seekToDate_ = objc.registerName("seekToDate:");
late final _sel_selectedMediaOptionInMediaSelectionGroup_ = objc.registerName(
  "selectedMediaOptionInMediaSelectionGroup:",
);

/// AVPlayerItemDeprecated
extension AVPlayerItemDeprecated on AVPlayerItem {
  /// !
  /// @method			seekToTime:
  /// @abstract			Moves the playback cursor.
  /// @param				time
  /// @discussion		Use this method to seek to a specified time for the item.
  /// The time seeked to may differ from the specified time for efficiency. For sample accurate seeking see seekToTime:toleranceBefore:toleranceAfter:.
  /// If the seek time is outside of seekable time ranges as indicated by seekableTimeRanges property, the seek request will be cancelled.
  void seekToTime(CMTime time) {
    objc.checkOsVersionInternal('AVPlayerItem.seekToTime:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1hznzoi(this.ref.pointer, _sel_seekToTime_, time);
  }

  /// !
  /// @method			seekToTime:toleranceBefore:toleranceAfter:
  /// @abstract			Moves the playback cursor within a specified time bound.
  /// @param				time
  /// @param				toleranceBefore
  /// @param				toleranceAfter
  /// @discussion		Use this method to seek to a specified time for the item.
  /// The time seeked to will be within the range [time-toleranceBefore, time+toleranceAfter] and may differ from the specified time for efficiency.
  /// Pass kCMTimeZero for both toleranceBefore and toleranceAfter to request sample accurate seeking which may incur additional decoding delay.
  /// Messaging this method with beforeTolerance:kCMTimePositiveInfinity and afterTolerance:kCMTimePositiveInfinity is the same as messaging seekToTime: directly.
  /// Seeking is constrained by the collection of seekable time ranges. If you seek to a time outside all of the seekable ranges the seek will result in a currentTime
  /// within the seekable ranges.
  /// If the seek time is outside of seekable time ranges as indicated by seekableTimeRanges property, the seek request will be cancelled.
  void seekToTime$1(CMTime time, {required CMTime toleranceBefore, required CMTime toleranceAfter}) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.seekToTime:toleranceBefore:toleranceAfter:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1up52l2(
      this.ref.pointer,
      _sel_seekToTime_toleranceBefore_toleranceAfter_,
      time,
      toleranceBefore,
      toleranceAfter,
    );
  }

  /// !
  /// @method		seekToDate
  /// @abstract		move playhead to a point corresponding to a particular date.
  /// @discussion
  /// For playback content that is associated with a range of dates, move the
  /// playhead to point within that range. Will fail if the supplied date is outside
  /// the range or if the content is not associated with a range of dates.
  /// @param			date	The new position for the playhead.
  /// @result		Returns true if the playhead was moved to the supplied date.
  bool seekToDate(objc.NSDate date) {
    objc.checkOsVersionInternal('AVPlayerItem.seekToDate:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_19nvye5(this.ref.pointer, _sel_seekToDate_, date.ref.pointer);
  }

  /// !
  /// @method		selectedMediaOptionInMediaSelectionGroup:
  /// @abstract		Indicates the media selection option that's currently selected from the specified group. May be nil.
  /// @param 		mediaSelectionGroup		A media selection group obtained from the receiver's asset.
  /// @result		An instance of AVMediaSelectionOption that describes the currently selection option in the group.
  /// @discussion
  /// If the value of the property allowsEmptySelection of the AVMediaSelectionGroup is YES, the currently selected option in the group may be nil.
  AVMediaSelectionOption? selectedMediaOptionInMediaSelectionGroup(AVMediaSelectionGroup mediaSelectionGroup) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.selectedMediaOptionInMediaSelectionGroup:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_selectedMediaOptionInMediaSelectionGroup_,
      mediaSelectionGroup.ref.pointer,
    );
    return _ret.address == 0 ? null : AVMediaSelectionOption.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVMetricEventStreamPublisher is a stub. To generate bindings for this class, include
/// AVMetricEventStreamPublisher in your config's objc-protocols list.
///
/// AVMetricEventStreamPublisher
interface class AVMetricEventStreamPublisher extends objc.ObjCProtocolBase {
  AVMetricEventStreamPublisher._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMetricEventStreamPublisher] that points to the same underlying object as [other].
  AVMetricEventStreamPublisher.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMetricEventStreamPublisher] that wraps the given raw object pointer.
  AVMetricEventStreamPublisher.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

/// AVMetricEventStreamPublisher
extension AVMetricEventStreamPublisher$1 on AVPlayerItem {}

late final _sel_playerItemWithURL_ = objc.registerName("playerItemWithURL:");
late final _sel_playerItemWithAsset_ = objc.registerName("playerItemWithAsset:");
late final _sel_playerItemWithAsset_automaticallyLoadedAssetKeys_ = objc.registerName(
  "playerItemWithAsset:automaticallyLoadedAssetKeys:",
);
late final _sel_initWithURL_ = objc.registerName("initWithURL:");
late final _sel_initWithAsset_ = objc.registerName("initWithAsset:");
late final _sel_initWithAsset_automaticallyLoadedAssetKeys_ = objc.registerName(
  "initWithAsset:automaticallyLoadedAssetKeys:",
);
late final _sel_copyWithZone_ = objc.registerName("copyWithZone:");
late final _sel_copy = objc.registerName("copy");

/// !
/// @enum AVPlayerItemStatus
/// @abstract
/// These constants are returned by the AVPlayerItem status property to indicate whether it can successfully be played.
///
/// @constant	 AVPlayerItemStatusUnknown
/// Indicates that the status of the player item is not yet known because it has not tried to load new media resources
/// for playback.
/// @constant	 AVPlayerItemStatusReadyToPlay
/// Indicates that the player item is ready to be played.
/// @constant	 AVPlayerItemStatusFailed
/// Indicates that the player item can no longer be played because of an error. The error is described by the value of
/// the player item's error property.
enum AVPlayerItemStatus {
  AVPlayerItemStatusUnknown(0),
  AVPlayerItemStatusReadyToPlay(1),
  AVPlayerItemStatusFailed(2);

  final int value;
  const AVPlayerItemStatus(this.value);

  static AVPlayerItemStatus fromValue(int value) => switch (value) {
    0 => AVPlayerItemStatusUnknown,
    1 => AVPlayerItemStatusReadyToPlay,
    2 => AVPlayerItemStatusFailed,
    _ => throw ArgumentError('Unknown value for AVPlayerItemStatus: $value'),
  };
}

late final _sel_status = objc.registerName("status");
final _objc_msgSend_fmekku = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_error = objc.registerName("error");

/// AVPlayerItem
class AVPlayerItem extends objc.NSObject implements objc.NSCopying {
  AVPlayerItem._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerItem] that points to the same underlying object as [other].
  AVPlayerItem.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerItem] that wraps the given raw object pointer.
  AVPlayerItem.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [AVPlayerItem].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_AVPlayerItem);
  }

  /// init
  AVPlayerItem init() {
    objc.checkOsVersionInternal('AVPlayerItem.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// new
  static AVPlayerItem new$() {
    final _ret = _objc_msgSend_151sglz(_class_AVPlayerItem, _sel_new);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method		playerItemWithURL:
  /// @abstract		Returns an instance of AVPlayerItem for playing a resource at the specified location.
  /// @param			URL
  /// @result		An instance of AVPlayerItem.
  /// @discussion	Equivalent to +playerItemWithAsset:, passing [AVAsset assetWithURL:URL] as the value of asset.
  static AVPlayerItem playerItemWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVPlayerItem.playerItemWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(_class_AVPlayerItem, _sel_playerItemWithURL_, URL.ref.pointer);
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		playerItemWithAsset:
  /// @abstract		Returns an instance of AVPlayerItem for playing an AVAsset.
  /// @param			asset
  /// @result		An instance of AVPlayerItem.
  /// @discussion	Equivalent to +playerItemWithAsset:automaticallyLoadedAssetKeys:, passing @[ @"duration" ] as the value of automaticallyLoadedAssetKeys.
  ///
  /// This method, along with the companion `asset` property, is MainActor-isolated for Swift clients because AVAsset is not Sendable.  If you are using a Sendable subclass of AVAsset, such as AVURLAsset, an overload of this initializer will be chosen automatically to allow you to initialize an AVPlayerItem while not running on the main actor.
  static AVPlayerItem playerItemWithAsset(AVAsset asset) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.playerItemWithAsset:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(_class_AVPlayerItem, _sel_playerItemWithAsset_, asset.ref.pointer);
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		playerItemWithAsset:automaticallyLoadedAssetKeys:
  /// @abstract		Returns an instance of AVPlayerItem for playing an AVAsset.
  /// @param			asset
  /// @param			automaticallyLoadedAssetKeys
  /// An NSArray of NSStrings, each representing a property key defined by AVAsset. See AVAsset.h for property keys, e.g. duration.
  /// @result		An instance of AVPlayerItem.
  /// @discussion	The value of each key in automaticallyLoadedAssetKeys will be automatically be loaded by the underlying AVAsset before the receiver achieves the status AVPlayerItemStatusReadyToPlay; i.e. when the item is ready to play, the value of -[[AVPlayerItem asset] statusOfValueForKey:error:] will be one of the terminal status values greater than AVKeyValueStatusLoading.
  ///
  /// This method, along with the companion `asset` property, is MainActor-isolated for Swift clients because AVAsset is not Sendable.  If you are using a Sendable subclass of AVAsset, such as AVURLAsset, you can use `init(asset:automaticallyLoadedAssetKeys:)` to initialize an AVPlayerItem while not running on the main actor.
  static AVPlayerItem playerItemWithAsset$1(AVAsset asset, {objc.NSArray? automaticallyLoadedAssetKeys}) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.playerItemWithAsset:automaticallyLoadedAssetKeys:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_15qeuct(
      _class_AVPlayerItem,
      _sel_playerItemWithAsset_automaticallyLoadedAssetKeys_,
      asset.ref.pointer,
      automaticallyLoadedAssetKeys?.ref.pointer ?? ffi.nullptr,
    );
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		initWithURL:
  /// @abstract		Initializes an AVPlayerItem with an NSURL.
  /// @param			URL
  /// @result		An instance of AVPlayerItem
  /// @discussion	Equivalent to -initWithAsset:, passing [AVAsset assetWithURL:URL] as the value of asset.
  AVPlayerItem initWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVPlayerItem.initWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithURL_, URL.ref.pointer);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method		initWithAsset:
  /// @abstract		Initializes an AVPlayerItem with an AVAsset.
  /// @param			asset
  /// @result		An instance of AVPlayerItem
  /// @discussion	Equivalent to -initWithAsset:automaticallyLoadedAssetKeys:, passing @[ @"duration" ] as the value of automaticallyLoadedAssetKeys.
  ///
  /// This method, along with the companion `asset` property, is MainActor-isolated for Swift clients because AVAsset is not Sendable.  If you are using a Sendable subclass of AVAsset, such as AVURLAsset, an overload of this initializer will be chosen automatically to allow you to initialize an AVPlayerItem while not running on the main actor.
  AVPlayerItem initWithAsset(AVAsset asset) {
    objc.checkOsVersionInternal('AVPlayerItem.initWithAsset:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithAsset_, asset.ref.pointer);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method		initWithAsset:automaticallyLoadedAssetKeys:
  /// @abstract		Initializes an AVPlayerItem with an AVAsset.
  /// @param			asset
  /// An instance of AVAsset.
  /// @param			automaticallyLoadedAssetKeys
  /// An NSArray of NSStrings, each representing a property key defined by AVAsset. See AVAsset.h for property keys, e.g. duration.
  /// @result		An instance of AVPlayerItem
  /// @discussion	The value of each key in automaticallyLoadedAssetKeys will be automatically be loaded by the underlying AVAsset before the receiver achieves the status AVPlayerItemStatusReadyToPlay; i.e. when the item is ready to play, the value of -[[AVPlayerItem asset] statusOfValueForKey:error:] will be one of the terminal status values greater than AVKeyValueStatusLoading.
  ///
  /// This method, along with the companion `asset` property, is MainActor-isolated for Swift clients because AVAsset is not Sendable.  If you are using a Sendable subclass of AVAsset, such as AVURLAsset, you can use `init(asset:automaticallyLoadedAssetKeys:)` to initialize an AVPlayerItem while not running on the main actor.
  AVPlayerItem initWithAsset$1(AVAsset asset, {objc.NSArray? automaticallyLoadedAssetKeys}) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.initWithAsset:automaticallyLoadedAssetKeys:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_15qeuct(
      this.ref.retainAndReturnPointer(),
      _sel_initWithAsset_automaticallyLoadedAssetKeys_,
      asset.ref.pointer,
      automaticallyLoadedAssetKeys?.ref.pointer ?? ffi.nullptr,
    );
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// copyWithZone:
  objc.ObjCObjectBase copyWithZone(ffi.Pointer<objc.NSZone> zone) {
    objc.checkOsVersionInternal('AVPlayerItem.copyWithZone:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1cwp428(this.ref.pointer, _sel_copyWithZone_, zone);
    return objc.ObjCObjectBase(_ret, retain: false, release: true);
  }

  /// copy
  objc.ObjCObjectBase copy() {
    objc.checkOsVersionInternal('AVPlayerItem.copy', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_copy);
    return objc.ObjCObjectBase(_ret, retain: false, release: true);
  }

  /// !
  /// @property status
  /// @abstract
  /// The ability of the receiver to be used for playback.
  ///
  /// @discussion
  /// The value of this property is an AVPlayerItemStatus that indicates whether the receiver can be used for playback.
  /// When the value of this property is AVPlayerItemStatusFailed, the receiver can no longer be used for playback and
  /// a new instance needs to be created in its place. When this happens, clients can check the value of the error
  /// property to determine the nature of the failure. The value of this property will not be updated after the receiver
  /// is removed from an AVPlayer. This property is key value observable.
  AVPlayerItemStatus get status {
    objc.checkOsVersionInternal('AVPlayerItem.status', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_fmekku(this.ref.pointer, _sel_status);
    return AVPlayerItemStatus.fromValue(_ret);
  }

  /// !
  /// @property error
  /// @abstract
  /// If the receiver's status is AVPlayerItemStatusFailed, this describes the error that caused the failure.
  ///
  /// @discussion
  /// The value of this property is an NSError that describes what caused the receiver to no longer be able to be played.
  /// If the receiver's status is not AVPlayerItemStatusFailed, the value of this property is nil.
  objc.NSError? get error {
    objc.checkOsVersionInternal('AVPlayerItem.error', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_error);
    return _ret.address == 0 ? null : objc.NSError.castFromPointer(_ret, retain: true, release: true);
  }

  /// allocWithZone:
  static AVPlayerItem allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_AVPlayerItem, _sel_allocWithZone_, zone);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static AVPlayerItem alloc() {
    final _ret = _objc_msgSend_151sglz(_class_AVPlayerItem, _sel_alloc);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  AVPlayerItem self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  AVPlayerItem retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  AVPlayerItem autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of AVPlayerItem constructed with the default `new` method.
  factory AVPlayerItem() => new$();
}

late final _sel_currentItem = objc.registerName("currentItem");
late final _sel_replaceCurrentItemWithPlayerItem_ = objc.registerName("replaceCurrentItemWithPlayerItem:");

/// !
/// @enum AVPlayerActionAtItemEnd
/// @abstract
/// These constants are the allowable values of AVPlayer's actionAtItemEnd property.
///
/// @constant	 AVPlayerActionAtItemEndAdvance
/// Indicates that when an AVPlayerItem reaches its end time the player will automatically advance to the next item in its queue.
/// This value is supported only for players of class AVQueuePlayer. An AVPlayer that's not an AVQueuePlayer will raise an NSInvalidArgumentException if an attempt is made to set its actionAtItemEnd to AVPlayerActionAtItemEndAdvance.
/// @constant	 AVPlayerActionAtItemEndPause
/// Indicates that when an AVPlayerItem reaches its end time the player will automatically pause (which is to say, the player's
/// rate will automatically be set to 0).
/// @constant	 AVPlayerActionAtItemEndNone
/// Indicates that when an AVPlayerItem reaches its end time the player will take no action (which is to say, the player's rate
/// will not change, its currentItem will not change, and its currentTime will continue to be incremented or decremented as time
/// elapses, according to its rate). After this, if the player's actionAtItemEnd is set to a value other than AVPlayerActionAtItemEndNone,
/// the player will immediately take the action appropriate to that value.
enum AVPlayerActionAtItemEnd {
  AVPlayerActionAtItemEndAdvance(0),
  AVPlayerActionAtItemEndPause(1),
  AVPlayerActionAtItemEndNone(2);

  final int value;
  const AVPlayerActionAtItemEnd(this.value);

  static AVPlayerActionAtItemEnd fromValue(int value) => switch (value) {
    0 => AVPlayerActionAtItemEndAdvance,
    1 => AVPlayerActionAtItemEndPause,
    2 => AVPlayerActionAtItemEndNone,
    _ => throw ArgumentError('Unknown value for AVPlayerActionAtItemEnd: $value'),
  };
}

late final _sel_actionAtItemEnd = objc.registerName("actionAtItemEnd");
final _objc_msgSend_1x7j5o8 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setActionAtItemEnd_ = objc.registerName("setActionAtItemEnd:");
final _objc_msgSend_1pn4puq = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Long)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// AVPlayerItemControl
extension AVPlayerItemControl on AVPlayer {
  /// currentItem
  AVPlayerItem? get currentItem {
    objc.checkOsVersionInternal('AVPlayer.currentItem', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_currentItem);
    return _ret.address == 0 ? null : AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method			replaceCurrentItemWithPlayerItem:
  /// @abstract		Replaces the player's current item with the specified player item.
  /// @param			item
  /// The AVPlayerItem that will become the player's current item.
  /// @discussion
  /// In all releases of iOS 4, invoking replaceCurrentItemWithPlayerItem: with an AVPlayerItem that's already the receiver's currentItem results in an exception being raised. Starting with iOS 5, it's a no-op.
  /// This method throws an exception if the item already exists in the play queue.
  void replaceCurrentItemWithPlayerItem(AVPlayerItem? item) {
    objc.checkOsVersionInternal(
      'AVPlayer.replaceCurrentItemWithPlayerItem:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_replaceCurrentItemWithPlayerItem_, item?.ref.pointer ?? ffi.nullptr);
  }

  /// !
  /// @property		actionAtItemEnd
  /// @abstract		Indicates the action that the player should perform when playback of an item reaches its end time.
  /// @discussion	This property throws an exception if set to AVPlayerActionAtItemEndAdvance on an AVPlayer which is not an AVQueuePlayer.
  AVPlayerActionAtItemEnd get actionAtItemEnd {
    objc.checkOsVersionInternal('AVPlayer.actionAtItemEnd', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1x7j5o8(this.ref.pointer, _sel_actionAtItemEnd);
    return AVPlayerActionAtItemEnd.fromValue(_ret);
  }

  /// !
  /// @property		actionAtItemEnd
  /// @abstract		Indicates the action that the player should perform when playback of an item reaches its end time.
  /// @discussion	This property throws an exception if set to AVPlayerActionAtItemEndAdvance on an AVPlayer which is not an AVQueuePlayer.
  set actionAtItemEnd(AVPlayerActionAtItemEnd value) {
    objc.checkOsVersionInternal('AVPlayer.setActionAtItemEnd:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pn4puq(this.ref.pointer, _sel_setActionAtItemEnd_, value.value);
  }
}

/// AVPlayerTimeControl
extension AVPlayerTimeControl on AVPlayer {
  /// !
  /// @method			currentTime
  /// @abstract			Returns the current time of the current item.
  /// @result			A CMTime
  /// @discussion		Returns the current time of the current item. Not key-value observable; use -addPeriodicTimeObserverForInterval:queue:usingBlock: instead.
  CMTime currentTime() {
    objc.checkOsVersionInternal('AVPlayer.currentTime', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_currentTime)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_currentTime);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @method			seekToDate:
  /// @abstract			Moves the playback cursor.
  /// @param				date
  /// @discussion		Use this method to seek to a specified time for the current player item.
  /// The time seeked to may differ from the specified time for efficiency. For sample accurate seeking see seekToTime:toleranceBefore:toleranceAfter:.
  void seekToDate(objc.NSDate date) {
    objc.checkOsVersionInternal('AVPlayer.seekToDate:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_seekToDate_, date.ref.pointer);
  }

  /// !
  /// @method			seekToDate:completionHandler:
  /// @abstract			Moves the playback cursor and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @param				date
  /// @param				completionHandler
  /// @discussion		Use this method to seek to a specified time for the current player item and to be notified when the seek operation is complete.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter
  /// set to NO. If the new request completes without being interrupted by another seek request or by any other operation the specified
  /// completion handler will be invoked with the finished parameter set to YES.  If no item is attached, the completion handler will be
  /// invoked immediately with the finished parameter set to NO.
  void seekToDate$1(objc.NSDate date, {required objc.ObjCBlock<ffi.Void Function(ffi.Bool)> completionHandler}) {
    objc.checkOsVersionInternal(
      'AVPlayer.seekToDate:completionHandler:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_seekToDate_completionHandler_,
      date.ref.pointer,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @method			seekToTime:
  /// @abstract			Moves the playback cursor.
  /// @param				time
  /// @discussion		Use this method to seek to a specified time for the current player item.
  /// The time seeked to may differ from the specified time for efficiency. For sample accurate seeking see seekToTime:toleranceBefore:toleranceAfter:.
  void seekToTime(CMTime time) {
    objc.checkOsVersionInternal('AVPlayer.seekToTime:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1hznzoi(this.ref.pointer, _sel_seekToTime_, time);
  }

  /// !
  /// @method			seekToTime:toleranceBefore:toleranceAfter:
  /// @abstract			Moves the playback cursor within a specified time bound.
  /// @param				time
  /// @param				toleranceBefore
  /// @param				toleranceAfter
  /// @discussion		Use this method to seek to a specified time for the current player item.
  /// The time seeked to will be within the range [time-toleranceBefore, time+toleranceAfter] and may differ from the specified time for efficiency.
  /// Pass kCMTimeZero for both toleranceBefore and toleranceAfter to request sample accurate seeking which may incur additional decoding delay.
  /// Messaging this method with beforeTolerance:kCMTimePositiveInfinity and afterTolerance:kCMTimePositiveInfinity is the same as messaging seekToTime: directly.
  void seekToTime$1(CMTime time, {required CMTime toleranceBefore, required CMTime toleranceAfter}) {
    objc.checkOsVersionInternal(
      'AVPlayer.seekToTime:toleranceBefore:toleranceAfter:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1up52l2(
      this.ref.pointer,
      _sel_seekToTime_toleranceBefore_toleranceAfter_,
      time,
      toleranceBefore,
      toleranceAfter,
    );
  }

  /// !
  /// @method			seekToTime:completionHandler:
  /// @abstract			Moves the playback cursor and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @param				time
  /// @param				completionHandler
  /// @discussion		Use this method to seek to a specified time for the current player item and to be notified when the seek operation is complete.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter
  /// set to NO. If the new request completes without being interrupted by another seek request or by any other operation the specified
  /// completion handler will be invoked with the finished parameter set to YES.  If no item is attached, the completion handler will be
  /// invoked immediately with the finished parameter set to NO.
  void seekToTime$2(CMTime time, {required objc.ObjCBlock<ffi.Void Function(ffi.Bool)> completionHandler}) {
    objc.checkOsVersionInternal(
      'AVPlayer.seekToTime:completionHandler:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1pt0wih(this.ref.pointer, _sel_seekToTime_completionHandler_, time, completionHandler.ref.pointer);
  }

  /// !
  /// @method			seekToTime:toleranceBefore:toleranceAfter:completionHandler:
  /// @abstract			Moves the playback cursor within a specified time bound and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @param				time
  /// @param				toleranceBefore
  /// @param				toleranceAfter
  /// @discussion		Use this method to seek to a specified time for the current player item and to be notified when the seek operation is complete.
  /// The time seeked to will be within the range [time-toleranceBefore, time+toleranceAfter] and may differ from the specified time for efficiency.
  /// Pass kCMTimeZero for both toleranceBefore and toleranceAfter to request sample accurate seeking which may incur additional decoding delay.
  /// Messaging this method with beforeTolerance:kCMTimePositiveInfinity and afterTolerance:kCMTimePositiveInfinity is the same as messaging seekToTime: directly.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter set to NO. If the new
  /// request completes without being interrupted by another seek request or by any other operation the specified completion handler will be invoked with the
  /// finished parameter set to YES.  If no item is attached, the completion handler will be invoked immediately with the finished parameter set to NO.
  void seekToTime$3(
    CMTime time, {
    required CMTime toleranceBefore,
    required CMTime toleranceAfter,
    required objc.ObjCBlock<ffi.Void Function(ffi.Bool)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayer.seekToTime:toleranceBefore:toleranceAfter:completionHandler:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_4xu1ph(
      this.ref.pointer,
      _sel_seekToTime_toleranceBefore_toleranceAfter_completionHandler_,
      time,
      toleranceBefore,
      toleranceAfter,
      completionHandler.ref.pointer,
    );
  }
}

late final _sel_automaticallyWaitsToMinimizeStalling = objc.registerName("automaticallyWaitsToMinimizeStalling");
late final _sel_setAutomaticallyWaitsToMinimizeStalling_ = objc.registerName(
  "setAutomaticallyWaitsToMinimizeStalling:",
);
late final _sel_setRate_time_atHostTime_ = objc.registerName("setRate:time:atHostTime:");
final _objc_msgSend_qhsl75 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Float, CMTime, CMTime)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double, CMTime, CMTime)>();
late final _sel_prerollAtRate_completionHandler_ = objc.registerName("prerollAtRate:completionHandler:");
final _objc_msgSend_1blh1va = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Float,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        double,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_cancelPendingPrerolls = objc.registerName("cancelPendingPrerolls");
late final _sel_sourceClock = objc.registerName("sourceClock");
final _objc_msgSend_1lamzyt = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<OpaqueCMClock> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<ffi.Pointer<OpaqueCMClock> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setSourceClock_ = objc.registerName("setSourceClock:");
final _objc_msgSend_1samav9 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<OpaqueCMClock>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<OpaqueCMClock>)
    >();

/// AVPlayerAdvancedRateControl
extension AVPlayerAdvancedRateControl on AVPlayer {
  /// !
  /// @property		automaticallyWaitsToMinimizeStalling
  /// @abstract		Indicates that the player is allowed to delay playback at the specified rate in order to minimize stalling
  /// @discussion
  ///
  /// When this property is YES, whenever 1) the rate is set from zero to non-zero or 2) the playback buffer becomes empty and playback stalls, the player will attempt to determine if, at the specified rate, its currentItem will play to the end without interruptions. Should it determine that such interruptions would occur and these interruptions can be avoided by delaying the start or resumption of playback, the value of timeControlStatus will become AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate and playback will start automatically when the likelihood of stalling has been minimized.
  ///
  /// You may want to set this property to NO when you need precise control over playback start times, e.g., when synchronizing multiple instances of AVPlayer, and you should set it to NO if you use an AVAssetResourceLoader delegate to load media data (more on this below). If the value of this property is NO, reasonForWaitingToPlay cannot assume a value of AVPlayerWaitingToMinimizeStallsReason.
  /// This implies that setting rate to a non-zero value in AVPlayerTimeControlStatusPaused will cause playback to start immediately as long as the playback buffer is not empty. When the playback buffer becomes empty during AVPlayerTimeControlStatusPlaying and playback stalls, playback state will switch to AVPlayerTimeControlStatusPaused and the rate will become 0.0.
  ///
  /// Changing the value of this property to NO while the value of timeControlStatus is AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate with a reasonForWaitingToPlay of AVPlayerWaitingToMinimizeStallsReason will cause the player to attempt playback at the specified rate immediately.
  ///
  /// For clients linked against iOS 10.0 and running on that version or later or linked against macOS 10.12 and running on that version or later, the default value of this property is YES.
  /// In versions of iOS prior to iOS 10.0 and versions of macOS prior to 10.12, this property is unavailable, and the behavior of the AVPlayer corresponds to the type of content being played. For streaming content, including HTTP Live Streaming, the AVPlayer acts as if automaticallyWaitsToMinimizeStalling is YES. For file-based content, including file-based content accessed via progressive http download, the AVPlayer acts as if automaticallyWaitsToMinimizeStalling is NO.
  ///
  /// If you employ an AVAssetResourceLoader delegate that loads media data for playback, you should set the value of your AVPlayers automaticallyWaitsToMinimizeStalling property to NO. Allowing the value of automaticallyWaitsToMinimizeStalling to remain YES when an AVAssetResourceLoader delegate is used for the loading of media data can result in poor start-up times for playback and poor recovery from stalls, because the behaviors provided by AVPlayer when automaticallyWaitsToMinimizeStalling has a value of YES depend on predictions of the future availability of media data that that do not function as expected when data is loaded via a client-controlled means, using the AVAssetResourceLoader delegate interface.
  ///
  /// You can allow the value of automaticallyWaitsToMinimizeStalling to remain YES if you use an AVAssetResourceLoader delegate to manage content keys for FairPlay Streaming, to provide dynamically-generated master playlists for HTTP Live Streaming, or to respond to authentication challenges, but not to load media data for playback.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  bool get automaticallyWaitsToMinimizeStalling {
    objc.checkOsVersionInternal(
      'AVPlayer.automaticallyWaitsToMinimizeStalling',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_automaticallyWaitsToMinimizeStalling);
  }

  /// !
  /// @property		automaticallyWaitsToMinimizeStalling
  /// @abstract		Indicates that the player is allowed to delay playback at the specified rate in order to minimize stalling
  /// @discussion
  ///
  /// When this property is YES, whenever 1) the rate is set from zero to non-zero or 2) the playback buffer becomes empty and playback stalls, the player will attempt to determine if, at the specified rate, its currentItem will play to the end without interruptions. Should it determine that such interruptions would occur and these interruptions can be avoided by delaying the start or resumption of playback, the value of timeControlStatus will become AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate and playback will start automatically when the likelihood of stalling has been minimized.
  ///
  /// You may want to set this property to NO when you need precise control over playback start times, e.g., when synchronizing multiple instances of AVPlayer, and you should set it to NO if you use an AVAssetResourceLoader delegate to load media data (more on this below). If the value of this property is NO, reasonForWaitingToPlay cannot assume a value of AVPlayerWaitingToMinimizeStallsReason.
  /// This implies that setting rate to a non-zero value in AVPlayerTimeControlStatusPaused will cause playback to start immediately as long as the playback buffer is not empty. When the playback buffer becomes empty during AVPlayerTimeControlStatusPlaying and playback stalls, playback state will switch to AVPlayerTimeControlStatusPaused and the rate will become 0.0.
  ///
  /// Changing the value of this property to NO while the value of timeControlStatus is AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate with a reasonForWaitingToPlay of AVPlayerWaitingToMinimizeStallsReason will cause the player to attempt playback at the specified rate immediately.
  ///
  /// For clients linked against iOS 10.0 and running on that version or later or linked against macOS 10.12 and running on that version or later, the default value of this property is YES.
  /// In versions of iOS prior to iOS 10.0 and versions of macOS prior to 10.12, this property is unavailable, and the behavior of the AVPlayer corresponds to the type of content being played. For streaming content, including HTTP Live Streaming, the AVPlayer acts as if automaticallyWaitsToMinimizeStalling is YES. For file-based content, including file-based content accessed via progressive http download, the AVPlayer acts as if automaticallyWaitsToMinimizeStalling is NO.
  ///
  /// If you employ an AVAssetResourceLoader delegate that loads media data for playback, you should set the value of your AVPlayers automaticallyWaitsToMinimizeStalling property to NO. Allowing the value of automaticallyWaitsToMinimizeStalling to remain YES when an AVAssetResourceLoader delegate is used for the loading of media data can result in poor start-up times for playback and poor recovery from stalls, because the behaviors provided by AVPlayer when automaticallyWaitsToMinimizeStalling has a value of YES depend on predictions of the future availability of media data that that do not function as expected when data is loaded via a client-controlled means, using the AVAssetResourceLoader delegate interface.
  ///
  /// You can allow the value of automaticallyWaitsToMinimizeStalling to remain YES if you use an AVAssetResourceLoader delegate to manage content keys for FairPlay Streaming, to provide dynamically-generated master playlists for HTTP Live Streaming, or to respond to authentication challenges, but not to load media data for playback.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  set automaticallyWaitsToMinimizeStalling(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setAutomaticallyWaitsToMinimizeStalling:',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAutomaticallyWaitsToMinimizeStalling_, value);
  }

  /// !
  /// @method			setRate:time:atHostTime:
  /// @abstract		Simultaneously sets the playback rate and the relationship between the current item's current time and host time.
  /// @discussion		You can use this function to synchronize playback with an external activity.
  ///
  /// The current item's timebase is adjusted so that its time will be (or was) itemTime when host time is (or was) hostClockTime.
  /// In other words: if hostClockTime is in the past, the timebase's time will be interpolated as though the timebase has been running at the requested rate since that time.  If hostClockTime is in the future, the timebase will immediately start running at the requested rate from an earlier time so that it will reach the requested itemTime at the requested hostClockTime.  (Note that the item's time will not jump backwards, but instead will sit at itemTime until the timebase reaches that time.)
  ///
  /// Note that setRate:time:atHostTime: is not supported when automaticallyWaitsToMinimizeStalling is YES. For clients linked against iOS 10.0 and later or macOS 12.0 and later, invoking setRate:time:atHostTime: when automaticallyWaitsToMinimizeStalling is YES will raise an NSInvalidArgument exception. Support for HTTP Live Streaming content requires iOS 11, tvOS 11, macOS 10.13 or later.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  ///
  /// @param itemTime	The time to start playback from, specified precisely (i.e., with zero tolerance).
  /// Pass kCMTimeInvalid to use the current item's current time.
  /// @param hostClockTime
  /// The host time at which to start playback.
  /// If hostClockTime is specified, the player will not ensure that media data is loaded before the timebase starts moving.
  /// If hostClockTime is kCMTimeInvalid, the rate and time will be set together, but without external synchronization;
  /// a host time in the near future will be used, allowing some time for media data loading.
  void setRate(double rate, {required CMTime time, required CMTime atHostTime}) {
    objc.checkOsVersionInternal(
      'AVPlayer.setRate:time:atHostTime:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    _objc_msgSend_qhsl75(this.ref.pointer, _sel_setRate_time_atHostTime_, rate, time, atHostTime);
  }

  /// !
  /// @method			prerollAtRate:completionHandler:
  /// @abstract		Begins loading media data to prime the render pipelines for playback from the current time with the given rate.
  /// @discussion		Once the completion handler is called with YES, the player's rate can be set with minimal latency.
  /// The completion handler will be called with NO if the preroll is interrupted by a time change or incompatible rate change, or if preroll is not possible for some other reason.
  /// Call this method only when the rate is currently zero and only after the AVPlayer's status has become AVPlayerStatusReadyToPlay.
  /// This method throws an exception if the status is not AVPlayerStatusReadyToPlay.
  /// @param rate		The intended rate for subsequent playback.
  /// @param completionHandler
  /// The block that will be called when the preroll is either completed or is interrupted.
  void prerollAtRate(double rate, {objc.ObjCBlock<ffi.Void Function(ffi.Bool)>? completionHandler}) {
    objc.checkOsVersionInternal(
      'AVPlayer.prerollAtRate:completionHandler:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    _objc_msgSend_1blh1va(
      this.ref.pointer,
      _sel_prerollAtRate_completionHandler_,
      rate,
      completionHandler?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// !
  /// @method			cancelPendingPrerolls
  /// @abstract		Cancel any pending preroll requests and invoke the corresponding completion handlers if present.
  /// @discussion		Use this method to cancel and release the completion handlers for pending prerolls. The finished parameter of the completion handlers will be set to NO.
  void cancelPendingPrerolls() {
    objc.checkOsVersionInternal('AVPlayer.cancelPendingPrerolls', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_cancelPendingPrerolls);
  }

  /// !
  /// @property		sourceClock
  /// @abstract		Set to override the automatic choice of source clock for item timebases.
  /// @discussion		NULL by default. This is most useful for synchronizing video-only movies with audio played via other means. IMPORTANT NOTE: If you specify a source clock other than the appropriate audio device clock, audio may drift out of sync.
  ffi.Pointer<OpaqueCMClock> get sourceClock {
    objc.checkOsVersionInternal('AVPlayer.sourceClock', iOS: (false, (15, 0, 0)), macOS: (false, (12, 0, 0)));
    return _objc_msgSend_1lamzyt(this.ref.pointer, _sel_sourceClock);
  }

  /// !
  /// @property		sourceClock
  /// @abstract		Set to override the automatic choice of source clock for item timebases.
  /// @discussion		NULL by default. This is most useful for synchronizing video-only movies with audio played via other means. IMPORTANT NOTE: If you specify a source clock other than the appropriate audio device clock, audio may drift out of sync.
  set sourceClock(ffi.Pointer<OpaqueCMClock> value) {
    objc.checkOsVersionInternal('AVPlayer.setSourceClock:', iOS: (false, (15, 0, 0)), macOS: (false, (12, 0, 0)));
    _objc_msgSend_1samav9(this.ref.pointer, _sel_setSourceClock_, value);
  }
}

void _ObjCBlock_ffiVoid_CMTime_fnPtrTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, CMTime arg0) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(CMTime arg0)>>()
    .asFunction<void Function(CMTime)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_CMTime_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime)>(
      _ObjCBlock_ffiVoid_CMTime_fnPtrTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_CMTime_closureTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, CMTime arg0) =>
    (objc.getBlockClosure(block) as void Function(CMTime))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_CMTime_closureCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime)>(
      _ObjCBlock_ffiVoid_CMTime_closureTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_CMTime_listenerTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, CMTime arg0) {
  (objc.getBlockClosure(block) as void Function(CMTime))(arg0);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime)>
_ObjCBlock_ffiVoid_CMTime_listenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime)>.listener(
      _ObjCBlock_ffiVoid_CMTime_listenerTrampoline,
    )..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_CMTime_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  CMTime arg0,
) {
  try {
    (objc.getBlockClosure(block) as void Function(CMTime))(arg0);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime)>
_ObjCBlock_ffiVoid_CMTime_blockingCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime)>.isolateLocal(
      _ObjCBlock_ffiVoid_CMTime_blockingTrampoline,
    )..keepIsolateAlive = false;
ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime)>
_ObjCBlock_ffiVoid_CMTime_blockingListenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime)>.listener(
      _ObjCBlock_ffiVoid_CMTime_blockingTrampoline,
    )..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(CMTime)>`.
abstract final class ObjCBlock_ffiVoid_CMTime {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(CMTime)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(CMTime)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(CMTime)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(CMTime arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function(CMTime)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_CMTime_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(CMTime)> fromFunction(
    void Function(CMTime) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(CMTime)>(
    objc.newClosureBlock(_ObjCBlock_ffiVoid_CMTime_closureCallable, (CMTime arg0) => fn(arg0), keepIsolateAlive),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(CMTime)> listener(void Function(CMTime) fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_CMTime_listenerCallable.nativeFunction.cast(),
      (CMTime arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_1hznzoi(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(CMTime)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(CMTime)> blocking(void Function(CMTime) fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_CMTime_blockingCallable.nativeFunction.cast(),
      (CMTime arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_CMTime_blockingListenerCallable.nativeFunction.cast(),
      (CMTime arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_1hznzoi(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(CMTime)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(CMTime)>`.
extension ObjCBlock_ffiVoid_CMTime_CallExtension on objc.ObjCBlock<ffi.Void Function(CMTime)> {
  void call(CMTime arg0) => ref.pointer.ref.invoke
      .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block, CMTime arg0)>>()
      .asFunction<void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime)>()(ref.pointer, arg0);
}

late final _sel_addPeriodicTimeObserverForInterval_queue_usingBlock_ = objc.registerName(
  "addPeriodicTimeObserverForInterval:queue:usingBlock:",
);
final _objc_msgSend_15um7tj = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          CMTime,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        CMTime,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_addBoundaryTimeObserverForTimes_queue_usingBlock_ = objc.registerName(
  "addBoundaryTimeObserverForTimes:queue:usingBlock:",
);
final _objc_msgSend_2wiv66 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_removeTimeObserver_ = objc.registerName("removeTimeObserver:");

/// AVPlayerTimeObservation
extension AVPlayerTimeObservation on AVPlayer {
  /// !
  /// @method			addPeriodicTimeObserverForInterval:queue:usingBlock:
  /// @abstract		Requests invocation of a block during playback to report changing time.
  /// @param			interval
  /// The interval of invocation of the block during normal playback, according to progress of the current time of the player.
  /// @param			queue
  /// The serial queue onto which block should be enqueued.  If you pass NULL, the main queue (obtained using dispatch_get_main_queue()) will be used.  Passing a
  /// concurrent queue to this method will result in undefined behavior.
  /// @param			block
  /// The block to be invoked periodically.
  /// @result
  /// An object conforming to the NSObject protocol.  You must retain this returned value as long as you want the time observer to be invoked by the player.
  /// Pass this object to -removeTimeObserver: to cancel time observation.
  /// @discussion		The block is invoked periodically at the interval specified, interpreted according to the timeline of the current item.
  /// The block is also invoked whenever time jumps and whenever playback starts or stops.
  /// If the interval corresponds to a very short interval in real time, the player may invoke the block less frequently
  /// than requested. Even so, the player will invoke the block sufficiently often for the client to update indications
  /// of the current time appropriately in its end-user interface.
  /// Each call to -addPeriodicTimeObserverForInterval:queue:usingBlock: should be paired with a corresponding call to -removeTimeObserver:.
  /// Releasing the observer object without a call to -removeTimeObserver: will result in undefined behavior.
  objc.ObjCObjectBase addPeriodicTimeObserverForInterval(
    CMTime interval, {
    objc.NSObject? queue,
    required objc.ObjCBlock<ffi.Void Function(CMTime)> usingBlock,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayer.addPeriodicTimeObserverForInterval:queue:usingBlock:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_15um7tj(
      this.ref.pointer,
      _sel_addPeriodicTimeObserverForInterval_queue_usingBlock_,
      interval,
      queue?.ref.pointer ?? ffi.nullptr,
      usingBlock.ref.pointer,
    );
    return objc.ObjCObjectBase(_ret, retain: true, release: true);
  }

  /// !
  /// @method			addBoundaryTimeObserverForTimes:queue:usingBlock:
  /// @abstract		Requests invocation of a block when specified times are traversed during normal playback.
  /// @param			times
  /// The times for which the observer requests notification, supplied as an array of NSValues carrying CMTimes.
  /// @param			queue
  /// The serial queue onto which block should be enqueued.  If you pass NULL, the main queue (obtained using dispatch_get_main_queue()) will be used.  Passing a
  /// concurrent queue to this method will result in undefined behavior.
  /// @param			block
  /// The block to be invoked when any of the specified times is crossed during normal playback.
  /// @result
  /// An object conforming to the NSObject protocol.  You must retain this returned value as long as you want the time observer to be invoked by the player.
  /// Pass this object to -removeTimeObserver: to cancel time observation.
  /// @discussion		Each call to -addPeriodicTimeObserverForInterval:queue:usingBlock: should be paired with a corresponding call to -removeTimeObserver:.
  /// Releasing the observer object without a call to -removeTimeObserver: will result in undefined behavior.
  objc.ObjCObjectBase addBoundaryTimeObserverForTimes(
    objc.NSArray times, {
    objc.NSObject? queue,
    required objc.ObjCBlock<ffi.Void Function()> usingBlock,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayer.addBoundaryTimeObserverForTimes:queue:usingBlock:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_2wiv66(
      this.ref.pointer,
      _sel_addBoundaryTimeObserverForTimes_queue_usingBlock_,
      times.ref.pointer,
      queue?.ref.pointer ?? ffi.nullptr,
      usingBlock.ref.pointer,
    );
    return objc.ObjCObjectBase(_ret, retain: true, release: true);
  }

  /// !
  /// @method			removeTimeObserver:
  /// @abstract		Cancels a previously registered time observer.
  /// @param			observer
  /// An object returned by a previous call to -addPeriodicTimeObserverForInterval:queue:usingBlock: or -addBoundaryTimeObserverForTimes:queue:usingBlock:.
  /// @discussion		Upon return, the caller is guaranteed that no new time observer blocks will begin executing.  Depending on the calling thread and the queue
  /// used to add the time observer, an in-flight block may continue to execute after this method returns.  You can guarantee synchronous time
  /// observer removal by enqueuing the call to -removeTimeObserver: on that queue.  Alternatively, call dispatch_sync(queue, ^{}) after
  /// -removeTimeObserver: to wait for any in-flight blocks to finish executing.
  /// -removeTimeObserver: should be used to explicitly cancel each time observer added using -addPeriodicTimeObserverForInterval:queue:usingBlock:
  /// and -addBoundaryTimeObserverForTimes:queue:usingBlock:.
  ///
  /// This method throws an exception for any of the following reasons:
  /// - observer was added by a different instance of AVPlayer
  /// - observer was not returned by -addPeriodicTimeObserverForInterval:queue:usingBlock:
  /// - observer was not returned by -addBoundaryTimeObserverForTimes:queue:usingBlock:
  void removeTimeObserver(objc.ObjCObjectBase observer) {
    objc.checkOsVersionInternal('AVPlayer.removeTimeObserver:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_removeTimeObserver_, observer.ref.pointer);
  }
}

late final _sel_volume = objc.registerName("volume");
late final _sel_setVolume_ = objc.registerName("setVolume:");
late final _sel_isMuted = objc.registerName("isMuted");
late final _sel_setMuted_ = objc.registerName("setMuted:");

/// AVPlayerMediaControl
extension AVPlayerMediaControl on AVPlayer {
  /// volume
  double get volume {
    objc.checkOsVersionInternal('AVPlayer.volume', iOS: (false, (7, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_volume)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_volume);
  }

  /// setVolume:
  set volume(double value) {
    objc.checkOsVersionInternal('AVPlayer.setVolume:', iOS: (false, (7, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_setVolume_, value);
  }

  /// isMuted
  bool get muted {
    objc.checkOsVersionInternal('AVPlayer.isMuted', iOS: (false, (7, 0, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isMuted);
  }

  /// setMuted:
  set muted(bool value) {
    objc.checkOsVersionInternal('AVPlayer.setMuted:', iOS: (false, (7, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setMuted_, value);
  }
}

late final _sel_appliesMediaSelectionCriteriaAutomatically = objc.registerName(
  "appliesMediaSelectionCriteriaAutomatically",
);
late final _sel_setAppliesMediaSelectionCriteriaAutomatically_ = objc.registerName(
  "setAppliesMediaSelectionCriteriaAutomatically:",
);

/// WARNING: AVPlayerMediaSelectionCriteria is a stub. To generate bindings for this class, include
/// AVPlayerMediaSelectionCriteria in your config's objc-interfaces list.
///
/// AVPlayerMediaSelectionCriteria
class AVPlayerMediaSelectionCriteria extends objc.ObjCObjectBase {
  AVPlayerMediaSelectionCriteria._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerMediaSelectionCriteria] that points to the same underlying object as [other].
  AVPlayerMediaSelectionCriteria.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerMediaSelectionCriteria] that wraps the given raw object pointer.
  AVPlayerMediaSelectionCriteria.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_setMediaSelectionCriteria_forMediaCharacteristic_ = objc.registerName(
  "setMediaSelectionCriteria:forMediaCharacteristic:",
);
late final _sel_mediaSelectionCriteriaForMediaCharacteristic_ = objc.registerName(
  "mediaSelectionCriteriaForMediaCharacteristic:",
);

/// AVPlayerAutomaticMediaSelection
extension AVPlayerAutomaticMediaSelection on AVPlayer {
  /// appliesMediaSelectionCriteriaAutomatically
  bool get appliesMediaSelectionCriteriaAutomatically {
    objc.checkOsVersionInternal(
      'AVPlayer.appliesMediaSelectionCriteriaAutomatically',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_appliesMediaSelectionCriteriaAutomatically);
  }

  /// setAppliesMediaSelectionCriteriaAutomatically:
  set appliesMediaSelectionCriteriaAutomatically(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setAppliesMediaSelectionCriteriaAutomatically:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAppliesMediaSelectionCriteriaAutomatically_, value);
  }

  /// !
  /// @method     setMediaSelectionCriteria:forMediaCharacteristic:
  /// @abstract   Applies automatic selection criteria for media that has the specified media characteristic.
  /// @param      criteria
  /// An instance of AVPlayerMediaSelectionCriteria.
  /// @param      mediaCharacteristic
  /// The media characteristic for which the selection criteria are to be applied. Supported values include AVMediaCharacteristicAudible, AVMediaCharacteristicLegible, and AVMediaCharacteristicVisual.
  /// @discussion
  /// Criteria will be applied to an AVPlayerItem when:
  /// a) It is made ready to play
  /// b) Specific media selections are made by -[AVPlayerItem selectMediaOption:inMediaSelectionGroup:] in a different group. The automatic choice in one group may be influenced by a specific selection in another group.
  /// c) Underlying system preferences change, e.g. system language, accessibility captions.
  ///
  /// Specific selections made by -[AVPlayerItem selectMediaOption:inMediaSelectionGroup:] within any group will override automatic selection in that group until -[AVPlayerItem selectMediaOptionAutomaticallyInMediaSelectionGroup:] is received.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void setMediaSelectionCriteria(
    AVPlayerMediaSelectionCriteria? criteria, {
    required objc.NSString forMediaCharacteristic,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayer.setMediaSelectionCriteria:forMediaCharacteristic:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_pfv6jd(
      this.ref.pointer,
      _sel_setMediaSelectionCriteria_forMediaCharacteristic_,
      criteria?.ref.pointer ?? ffi.nullptr,
      forMediaCharacteristic.ref.pointer,
    );
  }

  /// !
  /// @method     mediaSelectionCriteriaForMediaCharacteristic:
  /// @abstract   Returns the automatic selection criteria for media that has the specified media characteristic.
  /// @param      mediaCharacteristic
  /// The media characteristic for which the selection criteria is to be returned. Supported values include AVMediaCharacteristicAudible, AVMediaCharacteristicLegible, and AVMediaCharacteristicVisual.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  AVPlayerMediaSelectionCriteria? mediaSelectionCriteriaForMediaCharacteristic(objc.NSString mediaCharacteristic) {
    objc.checkOsVersionInternal(
      'AVPlayer.mediaSelectionCriteriaForMediaCharacteristic:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_mediaSelectionCriteriaForMediaCharacteristic_,
      mediaCharacteristic.ref.pointer,
    );
    return _ret.address == 0 ? null : AVPlayerMediaSelectionCriteria.castFromPointer(_ret, retain: true, release: true);
  }
}

late final _sel_audioOutputDeviceUniqueID = objc.registerName("audioOutputDeviceUniqueID");
late final _sel_setAudioOutputDeviceUniqueID_ = objc.registerName("setAudioOutputDeviceUniqueID:");

/// AVPlayerAudioDeviceSupport
extension AVPlayerAudioDeviceSupport on AVPlayer {
  /// !
  /// @property audioOutputDeviceUniqueID
  /// @abstract
  /// Specifies the unique ID of the Core Audio output device used to play audio.
  /// @discussion
  /// By default, the value of this property is nil, indicating that the default audio output device is used. Otherwise the value of this property is an NSString containing the unique ID of the Core Audio output device to be used for audio output.
  ///
  /// Core Audio's kAudioDevicePropertyDeviceUID is a suitable source of audio output device unique IDs.
  objc.NSString? get audioOutputDeviceUniqueID {
    objc.checkOsVersionInternal('AVPlayer.audioOutputDeviceUniqueID', iOS: (true, null), macOS: (false, (10, 9, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_audioOutputDeviceUniqueID);
    return _ret.address == 0 ? null : objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property audioOutputDeviceUniqueID
  /// @abstract
  /// Specifies the unique ID of the Core Audio output device used to play audio.
  /// @discussion
  /// By default, the value of this property is nil, indicating that the default audio output device is used. Otherwise the value of this property is an NSString containing the unique ID of the Core Audio output device to be used for audio output.
  ///
  /// Core Audio's kAudioDevicePropertyDeviceUID is a suitable source of audio output device unique IDs.
  set audioOutputDeviceUniqueID(objc.NSString? value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setAudioOutputDeviceUniqueID:',
      iOS: (true, null),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setAudioOutputDeviceUniqueID_, value?.ref.pointer ?? ffi.nullptr);
  }
}

late final _sel_allowsExternalPlayback = objc.registerName("allowsExternalPlayback");
late final _sel_setAllowsExternalPlayback_ = objc.registerName("setAllowsExternalPlayback:");
late final _sel_isExternalPlaybackActive = objc.registerName("isExternalPlaybackActive");
late final _sel_usesExternalPlaybackWhileExternalScreenIsActive = objc.registerName(
  "usesExternalPlaybackWhileExternalScreenIsActive",
);
late final _sel_setUsesExternalPlaybackWhileExternalScreenIsActive_ = objc.registerName(
  "setUsesExternalPlaybackWhileExternalScreenIsActive:",
);
late final _sel_externalPlaybackVideoGravity = objc.registerName("externalPlaybackVideoGravity");
late final _sel_setExternalPlaybackVideoGravity_ = objc.registerName("setExternalPlaybackVideoGravity:");

/// AVPlayerExternalPlaybackSupport
extension AVPlayerExternalPlaybackSupport on AVPlayer {
  /// allowsExternalPlayback
  bool get allowsExternalPlayback {
    objc.checkOsVersionInternal(
      'AVPlayer.allowsExternalPlayback',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_allowsExternalPlayback);
  }

  /// setAllowsExternalPlayback:
  set allowsExternalPlayback(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setAllowsExternalPlayback:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAllowsExternalPlayback_, value);
  }

  /// isExternalPlaybackActive
  bool get externalPlaybackActive {
    objc.checkOsVersionInternal(
      'AVPlayer.isExternalPlaybackActive',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isExternalPlaybackActive);
  }

  /// usesExternalPlaybackWhileExternalScreenIsActive
  bool get usesExternalPlaybackWhileExternalScreenIsActive {
    objc.checkOsVersionInternal(
      'AVPlayer.usesExternalPlaybackWhileExternalScreenIsActive',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_usesExternalPlaybackWhileExternalScreenIsActive);
  }

  /// setUsesExternalPlaybackWhileExternalScreenIsActive:
  set usesExternalPlaybackWhileExternalScreenIsActive(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setUsesExternalPlaybackWhileExternalScreenIsActive:',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setUsesExternalPlaybackWhileExternalScreenIsActive_, value);
  }

  /// externalPlaybackVideoGravity
  objc.NSString get externalPlaybackVideoGravity {
    objc.checkOsVersionInternal('AVPlayer.externalPlaybackVideoGravity', iOS: (false, (6, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_externalPlaybackVideoGravity);
    return objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// setExternalPlaybackVideoGravity:
  set externalPlaybackVideoGravity(objc.NSString value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setExternalPlaybackVideoGravity:',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setExternalPlaybackVideoGravity_, value.ref.pointer);
  }
}

late final _sel_outputObscuredDueToInsufficientExternalProtection = objc.registerName(
  "outputObscuredDueToInsufficientExternalProtection",
);

/// AVPlayerProtectedContent
extension AVPlayerProtectedContent on AVPlayer {
  /// !
  /// @property outputObscuredDueToInsufficientExternalProtection
  /// @abstract
  /// Whether or not decoded output is being obscured due to insufficient external protection.
  ///
  /// @discussion
  /// The value of this property indicates whether the player is purposefully obscuring the visual output
  /// of the current item because the requirement for an external protection mechanism is not met by the
  /// current device configuration. It is highly recommended that clients whose content requires external
  /// protection observe this property and set the playback rate to zero and display an appropriate user
  /// interface when the value changes to YES. This property is key value observable.
  ///
  /// Note that the value of this property is dependent on the external protection requirements of the
  /// current item. These requirements are inherent to the content itself and cannot be externally specified.
  /// If the current item does not require external protection, the value of this property will be NO.
  bool get outputObscuredDueToInsufficientExternalProtection {
    objc.checkOsVersionInternal(
      'AVPlayer.outputObscuredDueToInsufficientExternalProtection',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_outputObscuredDueToInsufficientExternalProtection);
  }
}

/// !
/// @typedef AVPlayerHDRMode
/// @abstract  A bitfield type that specifies an HDR mode.
///
/// @constant	AVPlayerHDRModeHLG
/// @abstract	Indicates that HLG (Hybrid Log-Gamma) HDR mode is available.
/// @constant	AVPlayerHDRModeHDR10
/// @abstract	Indicates that HDR10 HDR mode is available.
/// @constant	AVPlayerHDRModeDolbyVision
/// @abstract	Indicates that Dolby Vision HDR mode is available.
enum AVPlayerHDRMode {
  AVPlayerHDRModeHLG(1),
  AVPlayerHDRModeHDR10(2),
  AVPlayerHDRModeDolbyVision(4);

  final int value;
  const AVPlayerHDRMode(this.value);

  static AVPlayerHDRMode fromValue(int value) => switch (value) {
    1 => AVPlayerHDRModeHLG,
    2 => AVPlayerHDRModeHDR10,
    4 => AVPlayerHDRModeDolbyVision,
    _ => throw ArgumentError('Unknown value for AVPlayerHDRMode: $value'),
  };
}

late final _sel_availableHDRModes = objc.registerName("availableHDRModes");
final _objc_msgSend_fttnwg = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_eligibleForHDRPlayback = objc.registerName("eligibleForHDRPlayback");

/// AVPlayerPlaybackCapabilities
extension AVPlayerPlaybackCapabilities on AVPlayer {
  /// !
  /// @property		availableHDRModes
  /// @abstract		An AVPlayerHDRMode value that indicates the HDR modes the device can play to an appropriate display.   A value of 0 indicates that no HDR modes are supported.
  ///
  /// @discussion
  /// This property indicates all of the HDR modes that the device can play.  Each value indicates that an appropriate HDR display is available for the specified HDR mode.  Additionally, the device must be capable of playing the specified HDR type.  This property does not indicate whether video contains HDR content, whether HDR video is currently playing, or whether video is playing on an HDR display.
  static AVPlayerHDRMode getAvailableHDRModes() {
    objc.checkOsVersionInternal('AVPlayer.availableHDRModes', iOS: (false, (11, 2, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_fttnwg(_class_AVPlayer, _sel_availableHDRModes);
    return AVPlayerHDRMode.fromValue(_ret);
  }

  /// !
  /// @property		eligibleForHDRPlayback
  /// @abstract		Indicates whether HDR content can be played to an appropriate display.
  ///
  /// @discussion
  /// This property is YES if an HDR display is available and the device is capable of playing HDR content from an appropriate AVAsset, NO otherwise.  This property does not indicate whether video contains HDR content, whether HDR video is currently playing, or whether video is playing on an HDR display.  This property is not KVO observable.
  static bool getEligibleForHDRPlayback() {
    objc.checkOsVersionInternal(
      'AVPlayer.eligibleForHDRPlayback',
      iOS: (false, (13, 4, 0)),
      macOS: (false, (10, 15, 0)),
    );
    return _objc_msgSend_91o635(_class_AVPlayer, _sel_eligibleForHDRPlayback);
  }
}

late final _sel_preferredVideoDecoderGPURegistryID = objc.registerName("preferredVideoDecoderGPURegistryID");
final _objc_msgSend_9qbz9w = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setPreferredVideoDecoderGPURegistryID_ = objc.registerName("setPreferredVideoDecoderGPURegistryID:");
final _objc_msgSend_1xsl7ae = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Uint64)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// AVPlayerVideoDecoderGPUSupport
extension AVPlayerVideoDecoderGPUSupport on AVPlayer {
  /// !
  /// @property		preferredVideoDecoderGPURegistryID
  /// @abstract		Specifies a registryID associated with a GPU that should be used for video decode.
  ///
  /// @discussion
  /// By default, whenever possible, video decode will be performed on the GPU associated with the display on which the presenting CALayer is located.  Decode will be transitioned to a new GPU if appropriate when the CALayer moves to a new display.  This property overrides this default behavior, forcing decode to prefer an affinity to the GPU specified regardless of which GPU is being used to display the associated CALayer.
  ///
  /// The GPU registryID can be obtained from the GPU MTLDevice using [MTLDevice registryID] or can be obtained from OpenGL or OpenCL.
  int get preferredVideoDecoderGPURegistryID {
    objc.checkOsVersionInternal(
      'AVPlayer.preferredVideoDecoderGPURegistryID',
      iOS: (true, null),
      macOS: (false, (10, 13, 0)),
    );
    return _objc_msgSend_9qbz9w(this.ref.pointer, _sel_preferredVideoDecoderGPURegistryID);
  }

  /// !
  /// @property		preferredVideoDecoderGPURegistryID
  /// @abstract		Specifies a registryID associated with a GPU that should be used for video decode.
  ///
  /// @discussion
  /// By default, whenever possible, video decode will be performed on the GPU associated with the display on which the presenting CALayer is located.  Decode will be transitioned to a new GPU if appropriate when the CALayer moves to a new display.  This property overrides this default behavior, forcing decode to prefer an affinity to the GPU specified regardless of which GPU is being used to display the associated CALayer.
  ///
  /// The GPU registryID can be obtained from the GPU MTLDevice using [MTLDevice registryID] or can be obtained from OpenGL or OpenCL.
  set preferredVideoDecoderGPURegistryID(int value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setPreferredVideoDecoderGPURegistryID:',
      iOS: (true, null),
      macOS: (false, (10, 13, 0)),
    );
    _objc_msgSend_1xsl7ae(this.ref.pointer, _sel_setPreferredVideoDecoderGPURegistryID_, value);
  }
}

late final _sel_preventsDisplaySleepDuringVideoPlayback = objc.registerName("preventsDisplaySleepDuringVideoPlayback");
late final _sel_setPreventsDisplaySleepDuringVideoPlayback_ = objc.registerName(
  "setPreventsDisplaySleepDuringVideoPlayback:",
);

/// AVPlayerVideoDisplaySleepPrevention
extension AVPlayerVideoDisplaySleepPrevention on AVPlayer {
  /// !
  /// @property   preventsDisplaySleepDuringVideoPlayback
  /// @abstract   Indicates whether video playback prevents display and device sleep.
  /// @discussion
  /// Default is YES on iOS, tvOS and in Mac Catalyst apps.  Default is NO on macOS.
  /// Setting this property to NO does not force the display to sleep, it simply stops preventing display sleep.  Other apps or frameworks within your app may still be preventing display sleep for various reasons.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  bool get preventsDisplaySleepDuringVideoPlayback {
    objc.checkOsVersionInternal(
      'AVPlayer.preventsDisplaySleepDuringVideoPlayback',
      iOS: (false, (12, 0, 0)),
      macOS: (false, (10, 14, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_preventsDisplaySleepDuringVideoPlayback);
  }

  /// !
  /// @property   preventsDisplaySleepDuringVideoPlayback
  /// @abstract   Indicates whether video playback prevents display and device sleep.
  /// @discussion
  /// Default is YES on iOS, tvOS and in Mac Catalyst apps.  Default is NO on macOS.
  /// Setting this property to NO does not force the display to sleep, it simply stops preventing display sleep.  Other apps or frameworks within your app may still be preventing display sleep for various reasons.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  set preventsDisplaySleepDuringVideoPlayback(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setPreventsDisplaySleepDuringVideoPlayback:',
      iOS: (false, (12, 0, 0)),
      macOS: (false, (10, 14, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setPreventsDisplaySleepDuringVideoPlayback_, value);
  }
}

late final _sel_preventsAutomaticBackgroundingDuringVideoPlayback = objc.registerName(
  "preventsAutomaticBackgroundingDuringVideoPlayback",
);
late final _sel_setPreventsAutomaticBackgroundingDuringVideoPlayback_ = objc.registerName(
  "setPreventsAutomaticBackgroundingDuringVideoPlayback:",
);

/// AVPlayerAutomaticBackgroundPrevention
extension AVPlayerAutomaticBackgroundPrevention on AVPlayer {
  /// !
  /// @property   preventsAutomaticBackgroundingDuringVideoPlayback
  /// @abstract   Indicates whether video playback prevents the app from automatically getting backgrounded.
  /// @discussion
  /// Default value is YES.
  /// Setting this property to YES prevents an application that is playing video from automatically getting backgrounded.  This property does not prevent the user from backgrounding the application.
  bool get preventsAutomaticBackgroundingDuringVideoPlayback {
    objc.checkOsVersionInternal(
      'AVPlayer.preventsAutomaticBackgroundingDuringVideoPlayback',
      iOS: (true, null),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_preventsAutomaticBackgroundingDuringVideoPlayback);
  }

  /// !
  /// @property   preventsAutomaticBackgroundingDuringVideoPlayback
  /// @abstract   Indicates whether video playback prevents the app from automatically getting backgrounded.
  /// @discussion
  /// Default value is YES.
  /// Setting this property to YES prevents an application that is playing video from automatically getting backgrounded.  This property does not prevent the user from backgrounding the application.
  set preventsAutomaticBackgroundingDuringVideoPlayback(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setPreventsAutomaticBackgroundingDuringVideoPlayback:',
      iOS: (true, null),
      macOS: (true, null),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setPreventsAutomaticBackgroundingDuringVideoPlayback_, value);
  }
}

/// !
/// @typedef AVPlayerAudiovisualBackgroundPlaybackPolicy
/// @discussion This policy describes how AVPlayer behaves when the application transitions to UIApplicationStateBackground while playing video.
///
/// @constant	AVPlayerAudiovisualBackgroundPlaybackPolicyAutomatic
/// Indicates that the system is free to decide. This is the default policy.
///
/// @constant  AVPlayerAudiovisualBackgroundPlaybackPolicyPauses
/// Indicates that the player must be paused on going to background.
///
/// @constant	AVPlayerAudiovisualBackgroundPlaybackPolicyContinuesIfPossible
/// Indicates that the player continues to play if possible in background.
enum AVPlayerAudiovisualBackgroundPlaybackPolicy {
  AVPlayerAudiovisualBackgroundPlaybackPolicyAutomatic(1),
  AVPlayerAudiovisualBackgroundPlaybackPolicyPauses(2),
  AVPlayerAudiovisualBackgroundPlaybackPolicyContinuesIfPossible(3);

  final int value;
  const AVPlayerAudiovisualBackgroundPlaybackPolicy(this.value);

  static AVPlayerAudiovisualBackgroundPlaybackPolicy fromValue(int value) => switch (value) {
    1 => AVPlayerAudiovisualBackgroundPlaybackPolicyAutomatic,
    2 => AVPlayerAudiovisualBackgroundPlaybackPolicyPauses,
    3 => AVPlayerAudiovisualBackgroundPlaybackPolicyContinuesIfPossible,
    _ => throw ArgumentError('Unknown value for AVPlayerAudiovisualBackgroundPlaybackPolicy: $value'),
  };
}

late final _sel_audiovisualBackgroundPlaybackPolicy = objc.registerName("audiovisualBackgroundPlaybackPolicy");
final _objc_msgSend_zjfuws = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setAudiovisualBackgroundPlaybackPolicy_ = objc.registerName("setAudiovisualBackgroundPlaybackPolicy:");
final _objc_msgSend_1e0eiei = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Long)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// AVPlayerBackgroundSupport
extension AVPlayerBackgroundSupport on AVPlayer {
  /// !
  /// @property   audiovisualBackgroundPlaybackPolicy
  /// @abstract   Controls the policy to be used in deciding how playback of audiovisual content should continue while the application transitions to background.
  /// @discussion By default, the system is free to decide the background playback policy (AVPlayerAudiovisualBackgroundPlaybackPolicyAutomatic).
  /// If set to AVPlayerAudiovisualBackgroundPlaybackPolicyPauses, player will be paused on entering background.
  /// If set to AVPlayerAudiovisualBackgroundPlaybackPolicyContinuesIfPossible, the system makes the best effort to continue playback but the app also needs appropriate UIBackgroundModes for the system to let it continue running in the background. Note that this policy only applies to items with enabled video.
  AVPlayerAudiovisualBackgroundPlaybackPolicy get audiovisualBackgroundPlaybackPolicy {
    objc.checkOsVersionInternal(
      'AVPlayer.audiovisualBackgroundPlaybackPolicy',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    final _ret = _objc_msgSend_zjfuws(this.ref.pointer, _sel_audiovisualBackgroundPlaybackPolicy);
    return AVPlayerAudiovisualBackgroundPlaybackPolicy.fromValue(_ret);
  }

  /// !
  /// @property   audiovisualBackgroundPlaybackPolicy
  /// @abstract   Controls the policy to be used in deciding how playback of audiovisual content should continue while the application transitions to background.
  /// @discussion By default, the system is free to decide the background playback policy (AVPlayerAudiovisualBackgroundPlaybackPolicyAutomatic).
  /// If set to AVPlayerAudiovisualBackgroundPlaybackPolicyPauses, player will be paused on entering background.
  /// If set to AVPlayerAudiovisualBackgroundPlaybackPolicyContinuesIfPossible, the system makes the best effort to continue playback but the app also needs appropriate UIBackgroundModes for the system to let it continue running in the background. Note that this policy only applies to items with enabled video.
  set audiovisualBackgroundPlaybackPolicy(AVPlayerAudiovisualBackgroundPlaybackPolicy value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setAudiovisualBackgroundPlaybackPolicy:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_1e0eiei(this.ref.pointer, _sel_setAudiovisualBackgroundPlaybackPolicy_, value.value);
  }
}

/// WARNING: AVPlayerPlaybackCoordinator is a stub. To generate bindings for this class, include
/// AVPlayerPlaybackCoordinator in your config's objc-interfaces list.
///
/// AVPlayerPlaybackCoordinator
class AVPlayerPlaybackCoordinator extends objc.ObjCObjectBase {
  AVPlayerPlaybackCoordinator._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerPlaybackCoordinator] that points to the same underlying object as [other].
  AVPlayerPlaybackCoordinator.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerPlaybackCoordinator] that wraps the given raw object pointer.
  AVPlayerPlaybackCoordinator.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_playbackCoordinator = objc.registerName("playbackCoordinator");

/// PlaybackCoordination
extension PlaybackCoordination on AVPlayer {
  /// @property playbackCoordinator
  /// @abstract The playback coordinator for this player.
  /// @discussion If the playback coordinator is connected to other participants, rate changes and seeks on the current item will be automatically mirrored to all connected participants.
  /// Depending on policies, the coordinatormay also intercept rate changes to non-zero to coordinate playback start with the rest of the group.
  /// Use [AVPlayer playImmediatelyAtRate:] to override the coordinated startup behavior and start playback immediately. This is useful to give users an opportunity to override waiting caused by other participants' suspensions.
  /// Player configuration other than rate and seeks are not communicated to other participants and can be configured independently by each participant.
  /// A player with a connected playbackCoordinator will change behavior in situations that require the player to pause for internal reasons, such as a route change or a stall.
  /// When resuming after these events, the player will not resume at the stop time. Instead, it will attempt to rejoin the group, potentially seeking to match the other participant's progress.
  /// It is left to the owner of the AVPlayer to ensure that all participants are playing the same item. See the discussion of AVPlaybackCoordinator for considerations about item transitions.
  AVPlayerPlaybackCoordinator get playbackCoordinator {
    objc.checkOsVersionInternal('AVPlayer.playbackCoordinator', iOS: (false, (15, 0, 0)), macOS: (false, (12, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_playbackCoordinator);
    return AVPlayerPlaybackCoordinator.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVPlayerVideoOutput is a stub. To generate bindings for this class, include
/// AVPlayerVideoOutput in your config's objc-interfaces list.
///
/// AVPlayerVideoOutput
class AVPlayerVideoOutput extends objc.ObjCObjectBase {
  AVPlayerVideoOutput._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerVideoOutput] that points to the same underlying object as [other].
  AVPlayerVideoOutput.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerVideoOutput] that wraps the given raw object pointer.
  AVPlayerVideoOutput.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_videoOutput = objc.registerName("videoOutput");
late final _sel_setVideoOutput_ = objc.registerName("setVideoOutput:");

/// AVPlayerOutputSupport
extension AVPlayerOutputSupport on AVPlayer {
  /// !
  /// @property	videoOutput
  /// @abstract	The video output for this player, if one was set.
  /// @discussion When an AVPlayerVideoOutput is associated with an AVPlayer, the AVPlayerVideoOutput can then be used to receive video-related samples during playback.
  /// @note		If an output is set while AVPlayer has a current item it may cause different data channels to be selected for that item, which can have a performance impact.
  /// As a result, when possible, it is best to set an output before setting items on an AVPlayer.
  AVPlayerVideoOutput? get videoOutput {
    objc.checkOsVersionInternal('AVPlayer.videoOutput', iOS: (false, (17, 2, 0)), macOS: (false, (14, 2, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_videoOutput);
    return _ret.address == 0 ? null : AVPlayerVideoOutput.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property	videoOutput
  /// @abstract	The video output for this player, if one was set.
  /// @discussion When an AVPlayerVideoOutput is associated with an AVPlayer, the AVPlayerVideoOutput can then be used to receive video-related samples during playback.
  /// @note		If an output is set while AVPlayer has a current item it may cause different data channels to be selected for that item, which can have a performance impact.
  /// As a result, when possible, it is best to set an output before setting items on an AVPlayer.
  set videoOutput(AVPlayerVideoOutput? value) {
    objc.checkOsVersionInternal('AVPlayer.setVideoOutput:', iOS: (false, (17, 2, 0)), macOS: (false, (14, 2, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setVideoOutput_, value?.ref.pointer ?? ffi.nullptr);
  }
}

late final _sel_isClosedCaptionDisplayEnabled = objc.registerName("isClosedCaptionDisplayEnabled");
late final _sel_setClosedCaptionDisplayEnabled_ = objc.registerName("setClosedCaptionDisplayEnabled:");
late final _sel_masterClock = objc.registerName("masterClock");
late final _sel_setMasterClock_ = objc.registerName("setMasterClock:");

/// AVPlayerDeprecated
extension AVPlayerDeprecated on AVPlayer {
  /// !
  /// @property closedCaptionDisplayEnabled
  /// @abstract
  /// Indicates whether display of closed captions is enabled.
  ///
  /// @discussion
  /// This property is deprecated.
  ///
  /// When the value of appliesMediaSelectionCriteriaAutomatically is YES, the receiver will enable closed captions automatically either according to user preferences or, if you provide them, according to AVPlayerMediaSelectionCriteria for the media characteristic AVMediaCharacteristicLegible.
  ///
  /// If you want to determine whether closed captions may be available for a given AVPlayerItem, you can examine the AVMediaSelectionOptions in the AVMediaSelectionGroup for the characteristic AVMediaCharacteristicLegible, as vended by -[AVAsset mediaSelectionGroupForMediaCharacteristic:]. See AVMediaCharacteristicTranscribesSpokenDialogForAccessibility and AVMediaCharacteristicDescribesMusicAndSoundForAccessibility as documented in AVMediaFormat.h for information about how to identify legible media selection options that offer the features of closed captions for accessibility purposes.
  ///
  /// You can select or deselect a specific AVMediaSelectionOption via -[AVPlayerItem selectMediaOption:inMediaSelectionGroup:].
  ///
  /// For further information about Media Accessibility preferences, see MediaAccessibility framework documentation.
  bool get closedCaptionDisplayEnabled {
    objc.checkOsVersionInternal(
      'AVPlayer.isClosedCaptionDisplayEnabled',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isClosedCaptionDisplayEnabled);
  }

  /// !
  /// @property closedCaptionDisplayEnabled
  /// @abstract
  /// Indicates whether display of closed captions is enabled.
  ///
  /// @discussion
  /// This property is deprecated.
  ///
  /// When the value of appliesMediaSelectionCriteriaAutomatically is YES, the receiver will enable closed captions automatically either according to user preferences or, if you provide them, according to AVPlayerMediaSelectionCriteria for the media characteristic AVMediaCharacteristicLegible.
  ///
  /// If you want to determine whether closed captions may be available for a given AVPlayerItem, you can examine the AVMediaSelectionOptions in the AVMediaSelectionGroup for the characteristic AVMediaCharacteristicLegible, as vended by -[AVAsset mediaSelectionGroupForMediaCharacteristic:]. See AVMediaCharacteristicTranscribesSpokenDialogForAccessibility and AVMediaCharacteristicDescribesMusicAndSoundForAccessibility as documented in AVMediaFormat.h for information about how to identify legible media selection options that offer the features of closed captions for accessibility purposes.
  ///
  /// You can select or deselect a specific AVMediaSelectionOption via -[AVPlayerItem selectMediaOption:inMediaSelectionGroup:].
  ///
  /// For further information about Media Accessibility preferences, see MediaAccessibility framework documentation.
  set closedCaptionDisplayEnabled(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setClosedCaptionDisplayEnabled:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setClosedCaptionDisplayEnabled_, value);
  }

  /// masterClock
  ffi.Pointer<OpaqueCMClock> get masterClock {
    objc.checkOsVersionInternal('AVPlayer.masterClock', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_1lamzyt(this.ref.pointer, _sel_masterClock);
  }

  /// setMasterClock:
  set masterClock(ffi.Pointer<OpaqueCMClock> value) {
    objc.checkOsVersionInternal('AVPlayer.setMasterClock:', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    _objc_msgSend_1samav9(this.ref.pointer, _sel_setMasterClock_, value);
  }
}

late final _sel_playerWithURL_ = objc.registerName("playerWithURL:");
late final _sel_playerWithPlayerItem_ = objc.registerName("playerWithPlayerItem:");
late final _sel_initWithPlayerItem_ = objc.registerName("initWithPlayerItem:");
final _objc_msgSend_cou425 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVPlayer
class AVPlayer extends objc.NSObject {
  AVPlayer._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVPlayer', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVPlayer] that points to the same underlying object as [other].
  AVPlayer.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayer] that wraps the given raw object pointer.
  AVPlayer.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [AVPlayer].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_AVPlayer);
  }

  /// init
  AVPlayer init() {
    objc.checkOsVersionInternal('AVPlayer.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method			playerWithURL:
  /// @abstract		Returns an instance of AVPlayer that plays a single audiovisual resource referenced by URL.
  /// @param			URL
  /// @result			An instance of AVPlayer
  /// @discussion		Implicitly creates an AVPlayerItem. Clients can obtain the AVPlayerItem as it becomes the player's currentItem.
  static AVPlayer playerWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVPlayer.playerWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(_class_AVPlayer, _sel_playerWithURL_, URL.ref.pointer);
    return AVPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method			playerWithPlayerItem:
  /// @abstract		Create an AVPlayer that plays a single audiovisual item.
  /// @param			item
  /// @result			An instance of AVPlayer
  /// @discussion		Useful in order to play items for which an AVAsset has previously been created. See -[AVPlayerItem initWithAsset:].
  static AVPlayer playerWithPlayerItem(AVPlayerItem? item) {
    objc.checkOsVersionInternal('AVPlayer.playerWithPlayerItem:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(_class_AVPlayer, _sel_playerWithPlayerItem_, item?.ref.pointer ?? ffi.nullptr);
    return AVPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method			initWithURL:
  /// @abstract		Initializes an AVPlayer that plays a single audiovisual resource referenced by URL.
  /// @param			URL
  /// @result			An instance of AVPlayer
  /// @discussion		Implicitly creates an AVPlayerItem. Clients can obtain the AVPlayerItem as it becomes the player's currentItem.
  AVPlayer initWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVPlayer.initWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithURL_, URL.ref.pointer);
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method			initWithPlayerItem:
  /// @abstract		Create an AVPlayer that plays a single audiovisual item.
  /// @param			item
  /// @result			An instance of AVPlayer
  /// @discussion		Useful in order to play items for which an AVAsset has previously been created. See -[AVPlayerItem initWithAsset:].
  /// This method throws an exception if the item is not an AVPlayerItem, or if the item is
  /// associated with another AVPlayer.
  AVPlayer initWithPlayerItem(AVPlayerItem? item) {
    objc.checkOsVersionInternal('AVPlayer.initWithPlayerItem:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.retainAndReturnPointer(),
      _sel_initWithPlayerItem_,
      item?.ref.pointer ?? ffi.nullptr,
    );
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @property status
  /// @abstract
  /// The ability of the receiver to be used for playback.
  ///
  /// @discussion
  /// The value of this property is an AVPlayerStatus that indicates whether the receiver can be used for playback. When
  /// the value of this property is AVPlayerStatusFailed, the receiver can no longer be used for playback and a new
  /// instance needs to be created in its place. When this happens, clients can check the value of the error property to
  /// determine the nature of the failure. This property is key value observable.
  AVPlayerStatus get status {
    objc.checkOsVersionInternal('AVPlayer.status', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_cou425(this.ref.pointer, _sel_status);
    return AVPlayerStatus.fromValue(_ret);
  }

  /// !
  /// @property error
  /// @abstract
  /// If the receiver's status is AVPlayerStatusFailed, this describes the error that caused the failure.
  ///
  /// @discussion
  /// The value of this property is an NSError that describes what caused the receiver to no longer be able to play items.
  /// If the receiver's status is not AVPlayerStatusFailed, the value of this property is nil.
  objc.NSError? get error {
    objc.checkOsVersionInternal('AVPlayer.error', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_error);
    return _ret.address == 0 ? null : objc.NSError.castFromPointer(_ret, retain: true, release: true);
  }

  /// new
  static AVPlayer new$() {
    final _ret = _objc_msgSend_151sglz(_class_AVPlayer, _sel_new);
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static AVPlayer allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_AVPlayer, _sel_allocWithZone_, zone);
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static AVPlayer alloc() {
    final _ret = _objc_msgSend_151sglz(_class_AVPlayer, _sel_alloc);
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  AVPlayer self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return AVPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  AVPlayer retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return AVPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  AVPlayer autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return AVPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of AVPlayer constructed with the default `new` method.
  factory AVPlayer() => new$();
}

enum AVAssetExportSessionStatus {
  AVAssetExportSessionStatusUnknown(0),
  AVAssetExportSessionStatusWaiting(1),
  AVAssetExportSessionStatusExporting(2),
  AVAssetExportSessionStatusCompleted(3),
  AVAssetExportSessionStatusFailed(4),
  AVAssetExportSessionStatusCancelled(5);

  final int value;
  const AVAssetExportSessionStatus(this.value);

  static AVAssetExportSessionStatus fromValue(int value) => switch (value) {
    0 => AVAssetExportSessionStatusUnknown,
    1 => AVAssetExportSessionStatusWaiting,
    2 => AVAssetExportSessionStatusExporting,
    3 => AVAssetExportSessionStatusCompleted,
    4 => AVAssetExportSessionStatusFailed,
    5 => AVAssetExportSessionStatusCancelled,
    _ => throw ArgumentError('Unknown value for AVAssetExportSessionStatus: $value'),
  };
}

/// !
/// @typedef	AVAssetTrackGroupOutputHandling
/// @abstract	A bitfield type that specifies output handling policies for alternate tracks in a track group.
///
/// @constant	AVAssetTrackGroupOutputHandlingNone
/// @abstract	No specific processing directives are applied to alternate tracks.  The output is produced without regard to alternate track group assignments in the original asset.
/// @constant	AVAssetTrackGroupOutputHandlingPreserveAlternateTracks
/// @abstract	Preserve alternate tracks via pass-through.
enum AVAssetTrackGroupOutputHandling {
  AVAssetTrackGroupOutputHandlingNone(0),
  AVAssetTrackGroupOutputHandlingPreserveAlternateTracks(1);

  static const AVAssetTrackGroupOutputHandlingDefaultPolicy = AVAssetTrackGroupOutputHandlingNone;

  final int value;
  const AVAssetTrackGroupOutputHandling(this.value);

  static AVAssetTrackGroupOutputHandling fromValue(int value) => switch (value) {
    0 => AVAssetTrackGroupOutputHandlingNone,
    1 => AVAssetTrackGroupOutputHandlingPreserveAlternateTracks,
    _ => throw ArgumentError('Unknown value for AVAssetTrackGroupOutputHandling: $value'),
  };

  @override
  String toString() {
    if (this == AVAssetTrackGroupOutputHandlingNone)
      return "AVAssetTrackGroupOutputHandling.AVAssetTrackGroupOutputHandlingNone, AVAssetTrackGroupOutputHandling.AVAssetTrackGroupOutputHandlingDefaultPolicy";
    return super.toString();
  }
}

late final _class_AVAssetExportSession = objc.getClass("AVAssetExportSession");
late final _sel_allExportPresets = objc.registerName("allExportPresets");
late final _sel_exportPresetsCompatibleWithAsset_ = objc.registerName("exportPresetsCompatibleWithAsset:");
late final _sel_determineCompatibilityOfExportPreset_withAsset_outputFileType_completionHandler_ = objc.registerName(
  "determineCompatibilityOfExportPreset:withAsset:outputFileType:completionHandler:",
);
final _objc_msgSend_m7tls4 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();

/// AVAssetExportSessionPresets
extension AVAssetExportSessionPresets on AVAssetExportSession {
  /// !
  /// @method						allExportPresets
  /// @abstract					Returns all available export preset names.
  /// @discussion					Returns an array of NSStrings with the names of all available presets. Note that not all presets are
  /// compatible with all AVAssets.
  /// @result						An NSArray containing an NSString for each of the available preset names.
  static objc.NSArray allExportPresets() {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.allExportPresets',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_151sglz(_class_AVAssetExportSession, _sel_allExportPresets);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method						exportPresetsCompatibleWithAsset:
  /// @abstract					Returns only the identifiers compatible with the given AVAsset object.
  /// @discussion					Not all export presets are compatible with all AVAssets. For example an video only asset is not compatible with an audio only preset.
  /// This method returns only the identifiers for presets that will be compatible with the given asset.
  /// A client should pass in an AVAsset that is ready to be exported.
  /// In order to ensure that the setup and running of an export operation will succeed using a given preset no significant changes
  /// (such as adding or deleting tracks) should be made to the asset between retrieving compatible identifiers and performing the export operation.
  /// This method will access the tracks property of the AVAsset to build the returned NSArray.  To avoid blocking the calling thread,
  /// the tracks property should be loaded using the AVAsynchronousKeyValueLoading protocol before calling this method.
  /// @param asset				An AVAsset object that is intended to be exported.
  /// @result						An NSArray containing NSString values for the identifiers of compatible export types.
  /// The array is a complete list of the valid identifiers that can be used as arguments to
  /// initWithAsset:presetName: with the specified asset.
  static objc.NSArray exportPresetsCompatibleWithAsset(AVAsset asset) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.exportPresetsCompatibleWithAsset:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      _class_AVAssetExportSession,
      _sel_exportPresetsCompatibleWithAsset_,
      asset.ref.pointer,
    );
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method						determineCompatibilityOfExportPreset:withAsset:outputFileType:completionHandler:
  /// @abstract					Performs an inspection on the compatibility of an export preset, AVAsset and output file type.  Calls the completion handler with YES if
  /// the arguments are compatible; NO otherwise.
  /// @discussion					Not all export presets are compatible with all AVAssets and file types.  This method can be used to query compatibility.
  /// In order to ensure that the setup and running of an export operation will succeed using a given preset no significant changes
  /// (such as adding or deleting tracks) should be made to the asset between retrieving compatible identifiers and performing the export operation.
  /// @param presetName			An NSString specifying the name of the preset template for the export.
  /// @param asset				An AVAsset object that is intended to be exported.
  /// @param outputFileType		An AVFileType indicating a file type to check; or nil, to query whether there are any compatible types.
  /// @param handler				A block called with the compatibility result.
  static void determineCompatibilityOfExportPreset(
    objc.NSString presetName, {
    required AVAsset withAsset,
    objc.NSString? outputFileType,
    required objc.ObjCBlock<ffi.Void Function(ffi.Bool)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.determineCompatibilityOfExportPreset:withAsset:outputFileType:completionHandler:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_m7tls4(
      _class_AVAssetExportSession,
      _sel_determineCompatibilityOfExportPreset_withAsset_outputFileType_completionHandler_,
      presetName.ref.pointer,
      withAsset.ref.pointer,
      outputFileType?.ref.pointer ?? ffi.nullptr,
      completionHandler.ref.pointer,
    );
  }
}

late final _sel_supportedFileTypes = objc.registerName("supportedFileTypes");
void _ObjCBlock_ffiVoid_NSArray_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSArray_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>(
      _ObjCBlock_ffiVoid_NSArray_fnPtrTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_NSArray_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSArray_closureCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>(
      _ObjCBlock_ffiVoid_NSArray_closureTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_NSArray_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>))(arg0);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>
_ObjCBlock_ffiVoid_NSArray_listenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>.listener(
      _ObjCBlock_ffiVoid_NSArray_listenerTrampoline,
    )..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_NSArray_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<objc.ObjCObject> arg0,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>))(arg0);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_NSArray_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
      >.isolateLocal(_ObjCBlock_ffiVoid_NSArray_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_NSArray_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_NSArray_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(objc.NSArray)>`.
abstract final class ObjCBlock_ffiVoid_NSArray {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSArray)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function(objc.NSArray)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_NSArray_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray)> fromFunction(
    void Function(objc.NSArray) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSArray)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0) => fn(objc.NSArray.castFromPointer(arg0, retain: true, release: true)),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray)> listener(
    void Function(objc.NSArray) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0) => fn(objc.NSArray.castFromPointer(arg0, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_xtuoz7(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSArray)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray)> blocking(
    void Function(objc.NSArray) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0) => fn(objc.NSArray.castFromPointer(arg0, retain: false, release: true)),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0) => fn(objc.NSArray.castFromPointer(arg0, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_xtuoz7(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSArray)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(objc.NSArray)>`.
extension ObjCBlock_ffiVoid_NSArray_CallExtension on objc.ObjCBlock<ffi.Void Function(objc.NSArray)> {
  void call(objc.NSArray arg0) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<objc.ObjCObject> arg0)>
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0.ref.pointer);
}

late final _sel_determineCompatibleFileTypesWithCompletionHandler_ = objc.registerName(
  "determineCompatibleFileTypesWithCompletionHandler:",
);
final _objc_msgSend_f167m6 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCBlockImpl>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCBlockImpl>)
    >();

/// AVAssetExportSessionFileTypes
extension AVAssetExportSessionFileTypes on AVAssetExportSession {
  /// supportedFileTypes
  objc.NSArray get supportedFileTypes {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.supportedFileTypes',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_supportedFileTypes);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method						determineCompatibleFileTypesWithCompletionHandler:
  /// @abstract					Performs an inspection on the AVAsset and Preset the object was initialized with to determine a list of file types the ExportSession can write.
  /// @param						handler
  /// Called when the inspection completes with an array of file types the ExportSession can write.  Note that this may have a count of zero.
  /// @discussion					This method is different than the supportedFileTypes property in that it performs an inspection of the AVAsset in order to determine its compatibility with each of the session's supported file types.
  void determineCompatibleFileTypesWithCompletionHandler(objc.ObjCBlock<ffi.Void Function(objc.NSArray)> handler) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.determineCompatibleFileTypesWithCompletionHandler:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_f167m6(
      this.ref.pointer,
      _sel_determineCompatibleFileTypesWithCompletionHandler_,
      handler.ref.pointer,
    );
  }
}

late final _sel_timeRange = objc.registerName("timeRange");
final _objc_msgSend_rynxlp = objc.msgSendPointer
    .cast<ffi.NativeFunction<CMTimeRange Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<CMTimeRange Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_rynxlpStret = objc.msgSendStretPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<CMTimeRange>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<CMTimeRange>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
    >();
late final _sel_setTimeRange_ = objc.registerName("setTimeRange:");
final _objc_msgSend_1k8xwk9 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, CMTimeRange)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, CMTimeRange)>();
late final _sel_maxDuration = objc.registerName("maxDuration");
late final _sel_estimatedOutputFileLength = objc.registerName("estimatedOutputFileLength");
final _objc_msgSend_1k101e3 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.LongLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_fileLengthLimit = objc.registerName("fileLengthLimit");
late final _sel_setFileLengthLimit_ = objc.registerName("setFileLengthLimit:");
final _objc_msgSend_1qg6fr7 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.LongLong)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();
void _ObjCBlock_ffiVoid_CMTime_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  CMTime arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(CMTime arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(CMTime, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_CMTime_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime, ffi.Pointer<objc.ObjCObject>)>(
      _ObjCBlock_ffiVoid_CMTime_NSError_fnPtrTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_CMTime_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  CMTime arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(CMTime, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_CMTime_NSError_closureCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime, ffi.Pointer<objc.ObjCObject>)>(
      _ObjCBlock_ffiVoid_CMTime_NSError_closureTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_CMTime_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  CMTime arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(CMTime, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime, ffi.Pointer<objc.ObjCObject>)>
_ObjCBlock_ffiVoid_CMTime_NSError_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_CMTime_NSError_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_CMTime_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  CMTime arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(CMTime, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_CMTime_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime, ffi.Pointer<objc.ObjCObject>)
      >.isolateLocal(_ObjCBlock_ffiVoid_CMTime_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_CMTime_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_CMTime_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_CMTime_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(CMTime arg0, ffi.Pointer<objc.ObjCObject> arg1)>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_CMTime_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)> fromFunction(
    void Function(CMTime, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_CMTime_NSError_closureCallable,
      (CMTime arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: true, release: true)),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)> listener(
    void Function(CMTime, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_CMTime_NSError_listenerCallable.nativeFunction.cast(),
      (CMTime arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_fgo1sw(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)> blocking(
    void Function(CMTime, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_CMTime_NSError_blockingCallable.nativeFunction.cast(),
      (CMTime arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_CMTime_NSError_blockingListenerCallable.nativeFunction.cast(),
      (CMTime arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_fgo1sw(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)>`.
extension ObjCBlock_ffiVoid_CMTime_NSError_CallExtension on objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)> {
  void call(CMTime arg0, objc.NSError? arg1) =>
      ref.pointer.ref.invoke
          .cast<
            ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block, CMTime arg0, ffi.Pointer<objc.ObjCObject> arg1)
            >
          >()
          .asFunction<void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime, ffi.Pointer<objc.ObjCObject>)>()(
        ref.pointer,
        arg0,
        arg1?.ref.pointer ?? ffi.nullptr,
      );
}

late final _sel_estimateMaximumDurationWithCompletionHandler_ = objc.registerName(
  "estimateMaximumDurationWithCompletionHandler:",
);
void _ObjCBlock_ffiVoid_Int64_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  int arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Int64 arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(int, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_Int64_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Int64, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_Int64_NSError_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_Int64_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  int arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(int, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_Int64_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Int64, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_Int64_NSError_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_Int64_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  int arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(int, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Int64, ffi.Pointer<objc.ObjCObject>)>
_ObjCBlock_ffiVoid_Int64_NSError_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Int64, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_Int64_NSError_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_Int64_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  int arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(int, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Int64, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_Int64_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Int64,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_Int64_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Int64, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_Int64_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Int64,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.listener(_ObjCBlock_ffiVoid_Int64_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_Int64_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Int64 arg0, ffi.Pointer<objc.ObjCObject> arg1)>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_Int64_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)> fromFunction(
    void Function(int, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_Int64_NSError_closureCallable,
      (int arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: true, release: true)),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)> listener(
    void Function(int, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_Int64_NSError_listenerCallable.nativeFunction.cast(),
      (int arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapListenerBlock_mpxix1(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)> blocking(
    void Function(int, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_Int64_NSError_blockingCallable.nativeFunction.cast(),
      (int arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_Int64_NSError_blockingListenerCallable.nativeFunction.cast(),
      (int arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinBindings_wrapBlockingBlock_mpxix1(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)>`.
extension ObjCBlock_ffiVoid_Int64_NSError_CallExtension on objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)> {
  void call(int arg0, objc.NSError? arg1) =>
      ref.pointer.ref.invoke
          .cast<
            ffi.NativeFunction<
              ffi.Void Function(
                ffi.Pointer<objc.ObjCBlockImpl> block,
                ffi.Int64 arg0,
                ffi.Pointer<objc.ObjCObject> arg1,
              )
            >
          >()
          .asFunction<void Function(ffi.Pointer<objc.ObjCBlockImpl>, int, ffi.Pointer<objc.ObjCObject>)>()(
        ref.pointer,
        arg0,
        arg1?.ref.pointer ?? ffi.nullptr,
      );
}

late final _sel_estimateOutputFileLengthWithCompletionHandler_ = objc.registerName(
  "estimateOutputFileLengthWithCompletionHandler:",
);

/// AVAssetExportSessionDurationAndLength
extension AVAssetExportSessionDurationAndLength on AVAssetExportSession {
  /// timeRange
  CMTimeRange get timeRange {
    objc.checkOsVersionInternal('AVAssetExportSession.timeRange', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CMTimeRange>();
    objc.useMsgSendVariants
        ? _objc_msgSend_rynxlpStret(_ptr, this.ref.pointer, _sel_timeRange)
        : _ptr.ref = _objc_msgSend_rynxlp(this.ref.pointer, _sel_timeRange);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<CMTimeRange>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<CMTimeRange>(_finalizable);
  }

  /// setTimeRange:
  set timeRange(CMTimeRange value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setTimeRange:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1k8xwk9(this.ref.pointer, _sel_setTimeRange_, value);
  }

  /// maxDuration
  CMTime get maxDuration {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.maxDuration',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 14, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_maxDuration)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_maxDuration);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// estimatedOutputFileLength
  int get estimatedOutputFileLength {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.estimatedOutputFileLength',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    return _objc_msgSend_1k101e3(this.ref.pointer, _sel_estimatedOutputFileLength);
  }

  /// fileLengthLimit
  int get fileLengthLimit {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.fileLengthLimit',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 14, 0)),
    );
    return _objc_msgSend_1k101e3(this.ref.pointer, _sel_fileLengthLimit);
  }

  /// setFileLengthLimit:
  set fileLengthLimit(int value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setFileLengthLimit:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 14, 0)),
    );
    _objc_msgSend_1qg6fr7(this.ref.pointer, _sel_setFileLengthLimit_, value);
  }

  /// !
  /// @method						estimateMaximumDurationWithCompletionHandler:
  /// @abstract					Starts the asynchronous execution of estimating the maximum duration of the export based on the asset, preset, and fileLengthLimit associated with the export session.
  /// @discussion 				If fileLengthLimit is not set on the export session, fileLengthLimit will be assumed to be the maximum file size specified by the preset (if any); else infinite.
  /// @param						handler
  /// A block called with the estimated maximum duration, or kCMTimeInvalid if an error occurs.  The error parameter will be non-nil if an error occurs.
  void estimateMaximumDurationWithCompletionHandler(objc.ObjCBlock<ffi.Void Function(CMTime, objc.NSError?)> handler) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.estimateMaximumDurationWithCompletionHandler:',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    _objc_msgSend_f167m6(this.ref.pointer, _sel_estimateMaximumDurationWithCompletionHandler_, handler.ref.pointer);
  }

  /// !
  /// @method						estimateOutputFileLengthWithCompletionHandler:
  /// @abstract 					Starts the asynchronous execution of estimating the output file length of the export based on the asset, preset, and timeRange associated with the export session.
  /// @discussion 				If timeRange is not set on the export session, timeRange will be assumed to be the full time range of the asset.
  /// @param						handler
  /// A block called with the estimated output file length in bytes, if it can be determined; 0 otherwise.  The error parameter will be non-nil if an error occurs.
  void estimateOutputFileLengthWithCompletionHandler(
    objc.ObjCBlock<ffi.Void Function(ffi.Int64, objc.NSError?)> handler,
  ) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.estimateOutputFileLengthWithCompletionHandler:',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    _objc_msgSend_f167m6(this.ref.pointer, _sel_estimateOutputFileLengthWithCompletionHandler_, handler.ref.pointer);
  }
}

late final _sel_setMetadata_ = objc.registerName("setMetadata:");

/// WARNING: AVMetadataItemFilter is a stub. To generate bindings for this class, include
/// AVMetadataItemFilter in your config's objc-interfaces list.
///
/// AVMetadataItemFilter
class AVMetadataItemFilter extends objc.ObjCObjectBase {
  AVMetadataItemFilter._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMetadataItemFilter] that points to the same underlying object as [other].
  AVMetadataItemFilter.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMetadataItemFilter] that wraps the given raw object pointer.
  AVMetadataItemFilter.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_metadataItemFilter = objc.registerName("metadataItemFilter");
late final _sel_setMetadataItemFilter_ = objc.registerName("setMetadataItemFilter:");

/// AVAssetExportSessionMetadata
extension AVAssetExportSessionMetadata on AVAssetExportSession {
  /// metadata
  objc.NSArray? get metadata {
    objc.checkOsVersionInternal('AVAssetExportSession.metadata', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_metadata);
    return _ret.address == 0 ? null : objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// setMetadata:
  set metadata(objc.NSArray? value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setMetadata:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setMetadata_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// metadataItemFilter
  AVMetadataItemFilter? get metadataItemFilter {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.metadataItemFilter',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_metadataItemFilter);
    return _ret.address == 0 ? null : AVMetadataItemFilter.castFromPointer(_ret, retain: true, release: true);
  }

  /// setMetadataItemFilter:
  set metadataItemFilter(AVMetadataItemFilter? value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setMetadataItemFilter:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setMetadataItemFilter_, value?.ref.pointer ?? ffi.nullptr);
  }
}

late final _sel_audioTrackGroupHandling = objc.registerName("audioTrackGroupHandling");
final _objc_msgSend_whcj6w = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setAudioTrackGroupHandling_ = objc.registerName("setAudioTrackGroupHandling:");
final _objc_msgSend_12zbqu6 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.UnsignedLong)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// AVAssetExportSessionMediaProcessing
extension AVAssetExportSessionMediaProcessing on AVAssetExportSession {
  /// audioTimePitchAlgorithm
  objc.NSString get audioTimePitchAlgorithm {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.audioTimePitchAlgorithm',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_audioTimePitchAlgorithm);
    return objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// setAudioTimePitchAlgorithm:
  set audioTimePitchAlgorithm(objc.NSString value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setAudioTimePitchAlgorithm:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setAudioTimePitchAlgorithm_, value.ref.pointer);
  }

  /// audioMix
  AVAudioMix? get audioMix {
    objc.checkOsVersionInternal('AVAssetExportSession.audioMix', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_audioMix);
    return _ret.address == 0 ? null : AVAudioMix.castFromPointer(_ret, retain: true, release: true);
  }

  /// setAudioMix:
  set audioMix(AVAudioMix? value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setAudioMix:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setAudioMix_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// videoComposition
  AVVideoComposition? get videoComposition {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.videoComposition',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_videoComposition);
    return _ret.address == 0 ? null : AVVideoComposition.castFromPointer(_ret, retain: true, release: true);
  }

  /// setVideoComposition:
  set videoComposition(AVVideoComposition? value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setVideoComposition:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setVideoComposition_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// customVideoCompositor
  AVVideoCompositing? get customVideoCompositor {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.customVideoCompositor',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_customVideoCompositor);
    return _ret.address == 0 ? null : AVVideoCompositing.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property		audioTrackGroupHandling
  /// @abstract		Defines export policy for handling alternate audio tracks
  ///
  /// @discussion
  /// Specifies the handling of audio tracks that are members of the same alternate track group corresponding to an exported audio track in the source asset.
  /// If no audio track group is present, the value of this property has no effect.
  /// If necessary, use the trackGroups property of AVAsset to determine whether any audio track groups are present.
  /// The AVAudioMix property is not allowed to be used when also specifying alternate track output handling.  An exception will be thrown if both are specified.
  AVAssetTrackGroupOutputHandling get audioTrackGroupHandling {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.audioTrackGroupHandling',
      iOS: (false, (16, 0, 0)),
      macOS: (false, (13, 0, 0)),
    );
    final _ret = _objc_msgSend_whcj6w(this.ref.pointer, _sel_audioTrackGroupHandling);
    return AVAssetTrackGroupOutputHandling.fromValue(_ret);
  }

  /// !
  /// @property		audioTrackGroupHandling
  /// @abstract		Defines export policy for handling alternate audio tracks
  ///
  /// @discussion
  /// Specifies the handling of audio tracks that are members of the same alternate track group corresponding to an exported audio track in the source asset.
  /// If no audio track group is present, the value of this property has no effect.
  /// If necessary, use the trackGroups property of AVAsset to determine whether any audio track groups are present.
  /// The AVAudioMix property is not allowed to be used when also specifying alternate track output handling.  An exception will be thrown if both are specified.
  set audioTrackGroupHandling(AVAssetTrackGroupOutputHandling value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setAudioTrackGroupHandling:',
      iOS: (false, (16, 0, 0)),
      macOS: (false, (13, 0, 0)),
    );
    _objc_msgSend_12zbqu6(this.ref.pointer, _sel_setAudioTrackGroupHandling_, value.value);
  }
}

late final _sel_canPerformMultiplePassesOverSourceMediaData = objc.registerName(
  "canPerformMultiplePassesOverSourceMediaData",
);
late final _sel_setCanPerformMultiplePassesOverSourceMediaData_ = objc.registerName(
  "setCanPerformMultiplePassesOverSourceMediaData:",
);
late final _sel_directoryForTemporaryFiles = objc.registerName("directoryForTemporaryFiles");
late final _sel_setDirectoryForTemporaryFiles_ = objc.registerName("setDirectoryForTemporaryFiles:");

/// AVAssetExportSessionMultipass
extension AVAssetExportSessionMultipass on AVAssetExportSession {
  /// !
  /// @property	canPerformMultiplePassesOverSourceMediaData
  /// @abstract
  /// Determines whether the export session can perform multiple passes over the source media to achieve better results.
  ///
  /// @discussion
  /// When the value for this property is YES, the export session can produce higher quality results at the expense of longer export times.  Setting this property to YES may also require the export session to write temporary data to disk during the export.  To control the location of temporary data, use the property directoryForTemporaryFiles.
  ///
  /// The default value is NO.  Not all export session configurations can benefit from performing multiple passes over the source media.  In these cases, setting this property to YES has no effect.
  ///
  /// This property cannot be set after the export has started.
  bool get canPerformMultiplePassesOverSourceMediaData {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.canPerformMultiplePassesOverSourceMediaData',
      iOS: (false, (8, 0, 0)),
      macOS: (false, (10, 10, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPerformMultiplePassesOverSourceMediaData);
  }

  /// !
  /// @property	canPerformMultiplePassesOverSourceMediaData
  /// @abstract
  /// Determines whether the export session can perform multiple passes over the source media to achieve better results.
  ///
  /// @discussion
  /// When the value for this property is YES, the export session can produce higher quality results at the expense of longer export times.  Setting this property to YES may also require the export session to write temporary data to disk during the export.  To control the location of temporary data, use the property directoryForTemporaryFiles.
  ///
  /// The default value is NO.  Not all export session configurations can benefit from performing multiple passes over the source media.  In these cases, setting this property to YES has no effect.
  ///
  /// This property cannot be set after the export has started.
  set canPerformMultiplePassesOverSourceMediaData(bool value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setCanPerformMultiplePassesOverSourceMediaData:',
      iOS: (false, (8, 0, 0)),
      macOS: (false, (10, 10, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setCanPerformMultiplePassesOverSourceMediaData_, value);
  }

  /// !
  /// @property directoryForTemporaryFiles
  /// @abstract
  /// Specifies a directory that is suitable for containing temporary files generated during the export process
  ///
  /// @discussion
  /// AVAssetExportSession may need to write temporary files when configured in certain ways, such as when canPerformMultiplePassesOverSourceMediaData is set to YES.  This property can be used to control where in the filesystem those temporary files are created.  All temporary files will be deleted when the export is completed, is canceled, or fails.
  ///
  /// When the value of this property is nil, the export session will choose a suitable location when writing temporary files.  The default value is nil.
  ///
  /// This property cannot be set after the export has started.  The export will fail if the URL points to a location that is not a directory, does not exist, is not on the local file system, or if a file cannot be created in this directory (for example, due to insufficient permissions or sandboxing restrictions).
  objc.NSURL? get directoryForTemporaryFiles {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.directoryForTemporaryFiles',
      iOS: (false, (8, 0, 0)),
      macOS: (false, (10, 10, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_directoryForTemporaryFiles);
    return _ret.address == 0 ? null : objc.NSURL.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property directoryForTemporaryFiles
  /// @abstract
  /// Specifies a directory that is suitable for containing temporary files generated during the export process
  ///
  /// @discussion
  /// AVAssetExportSession may need to write temporary files when configured in certain ways, such as when canPerformMultiplePassesOverSourceMediaData is set to YES.  This property can be used to control where in the filesystem those temporary files are created.  All temporary files will be deleted when the export is completed, is canceled, or fails.
  ///
  /// When the value of this property is nil, the export session will choose a suitable location when writing temporary files.  The default value is nil.
  ///
  /// This property cannot be set after the export has started.  The export will fail if the URL points to a location that is not a directory, does not exist, is not on the local file system, or if a file cannot be created in this directory (for example, due to insufficient permissions or sandboxing restrictions).
  set directoryForTemporaryFiles(objc.NSURL? value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setDirectoryForTemporaryFiles:',
      iOS: (false, (8, 0, 0)),
      macOS: (false, (10, 10, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setDirectoryForTemporaryFiles_, value?.ref.pointer ?? ffi.nullptr);
  }
}

late final _sel_exportSessionWithAsset_presetName_ = objc.registerName("exportSessionWithAsset:presetName:");
late final _sel_initWithAsset_presetName_ = objc.registerName("initWithAsset:presetName:");
late final _sel_presetName = objc.registerName("presetName");
late final _sel_outputFileType = objc.registerName("outputFileType");
late final _sel_setOutputFileType_ = objc.registerName("setOutputFileType:");
late final _sel_outputURL = objc.registerName("outputURL");
late final _sel_setOutputURL_ = objc.registerName("setOutputURL:");
late final _sel_shouldOptimizeForNetworkUse = objc.registerName("shouldOptimizeForNetworkUse");
late final _sel_setShouldOptimizeForNetworkUse_ = objc.registerName("setShouldOptimizeForNetworkUse:");
late final _sel_allowsParallelizedExport = objc.registerName("allowsParallelizedExport");
late final _sel_setAllowsParallelizedExport_ = objc.registerName("setAllowsParallelizedExport:");
final _objc_msgSend_195k4xu = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_exportAsynchronouslyWithCompletionHandler_ = objc.registerName(
  "exportAsynchronouslyWithCompletionHandler:",
);
late final _sel_progress = objc.registerName("progress");
late final _sel_cancelExport = objc.registerName("cancelExport");

/// !
/// @class		AVAssetExportSession
///
/// @abstract	An AVAssetExportSession creates a new timed media resource from the contents of an
/// existing AVAsset in the form described by a specified export preset.
///
/// @discussion
/// Prior to initializing an instance of AVAssetExportSession, you can invoke
/// +allExportPresets to obtain the complete list of presets available. Use
/// +exportPresetsCompatibleWithAsset: to obtain a list of presets that are compatible
/// with a specific AVAsset.
///
/// To configure an export, initialize an AVAssetExportSession with an AVAsset that contains
/// the source media, an AVAssetExportPreset, the output file type, (a UTI string from
/// those defined in AVMediaFormat.h) and the output URL.
///
/// After configuration is complete, invoke exportAsynchronouslyWithCompletionHandler:
/// to start the export process. This method returns immediately; the export is performed
/// asynchronously. Invoke the -progress method to check on the progress. Note that in
/// some cases, depending on the capabilities of the device, when multiple exports are
/// attempted at the same time some may be queued until others have been completed. When
/// this happens, the status of a queued export will indicate that it's "waiting".
///
/// Whether the export fails, completes, or is cancelled, the completion handler you
/// supply to -exportAsynchronouslyWithCompletionHandler: will be called. Upon
/// completion, the status property indicates whether the export has completed
/// successfully. If it has failed, the value of the error property supplies additional
/// information about the reason for the failure.
class AVAssetExportSession extends objc.NSObject {
  AVAssetExportSession._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVAssetExportSession', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVAssetExportSession] that points to the same underlying object as [other].
  AVAssetExportSession.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAssetExportSession] that wraps the given raw object pointer.
  AVAssetExportSession.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [AVAssetExportSession].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_AVAssetExportSession);
  }

  /// init
  AVAssetExportSession init() {
    objc.checkOsVersionInternal('AVAssetExportSession.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return AVAssetExportSession.castFromPointer(_ret, retain: false, release: true);
  }

  /// new
  static AVAssetExportSession new$() {
    final _ret = _objc_msgSend_151sglz(_class_AVAssetExportSession, _sel_new);
    return AVAssetExportSession.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method						exportSessionWithAsset:presetName:
  /// @abstract					Returns an instance of AVAssetExportSession for the specified source asset and preset.
  /// @param		asset			An AVAsset object that is intended to be exported.
  /// @param		presetName		An NSString specifying the name of the preset template for the export.
  /// @result						An instance of AVAssetExportSession.
  /// @discussion					If the specified asset belongs to a mutable subclass of AVAsset, AVMutableComposition or AVMutableMovie, the results of any export-related operation are undefined if you mutate the asset after the operation commences. These operations include but are not limited to: 1) testing the compatibility of export presets with the asset, 2) calculating the maximum duration or estimated length of the output file, and 3) the export operation itself.
  static AVAssetExportSession? exportSessionWithAsset(AVAsset asset, {required objc.NSString presetName}) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.exportSessionWithAsset:presetName:',
      iOS: (false, (4, 1, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_15qeuct(
      _class_AVAssetExportSession,
      _sel_exportSessionWithAsset_presetName_,
      asset.ref.pointer,
      presetName.ref.pointer,
    );
    return _ret.address == 0 ? null : AVAssetExportSession.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method						initWithAsset:presetName:
  /// @abstract					Initialize an AVAssetExportSession with the specified preset and set the source to the contents of the asset.
  /// @param		asset			An AVAsset object that is intended to be exported.
  /// @param		presetName		An NSString specifying the name of the preset template for the export.
  /// @result						Returns the initialized AVAssetExportSession.
  /// @discussion					If the specified asset belongs to a mutable subclass of AVAsset, AVMutableComposition or AVMutableMovie, the results of any export-related operation are undefined if you mutate the asset after the operation commences. These operations include but are not limited to: 1) testing the compatibility of export presets with the asset, 2) calculating the maximum duration or estimated length of the output file, and 3) the export operation itself.
  AVAssetExportSession? initWithAsset(AVAsset asset, {required objc.NSString presetName}) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.initWithAsset:presetName:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_15qeuct(
      this.ref.retainAndReturnPointer(),
      _sel_initWithAsset_presetName_,
      asset.ref.pointer,
      presetName.ref.pointer,
    );
    return _ret.address == 0 ? null : AVAssetExportSession.castFromPointer(_ret, retain: false, release: true);
  }

  /// presetName
  objc.NSString get presetName {
    objc.checkOsVersionInternal('AVAssetExportSession.presetName', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_presetName);
    return objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// asset
  AVAsset get asset {
    objc.checkOsVersionInternal('AVAssetExportSession.asset', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_asset);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// outputFileType
  objc.NSString? get outputFileType {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.outputFileType',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_outputFileType);
    return _ret.address == 0 ? null : objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// setOutputFileType:
  set outputFileType(objc.NSString? value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setOutputFileType:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setOutputFileType_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// outputURL
  objc.NSURL? get outputURL {
    objc.checkOsVersionInternal('AVAssetExportSession.outputURL', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_outputURL);
    return _ret.address == 0 ? null : objc.NSURL.castFromPointer(_ret, retain: true, release: true);
  }

  /// setOutputURL:
  set outputURL(objc.NSURL? value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setOutputURL:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setOutputURL_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// shouldOptimizeForNetworkUse
  bool get shouldOptimizeForNetworkUse {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.shouldOptimizeForNetworkUse',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_shouldOptimizeForNetworkUse);
  }

  /// setShouldOptimizeForNetworkUse:
  set shouldOptimizeForNetworkUse(bool value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setShouldOptimizeForNetworkUse:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setShouldOptimizeForNetworkUse_, value);
  }

  /// !
  /// @property		allowsParallelizedExport
  /// @abstract		Determines whether or not parallelization can be employed in the export.
  /// @discussion	On select platforms, there may be opportunities to expedite the export by using additional resources in parallel.
  /// If set to YES, export parallelization will be enabled, only if parallelization requirements are met.  There will
  /// be no error signaled if export parallelization is not achievable, and instead the export will proceed as normal
  /// (without parallelization).
  /// If set to NO, export parallelization will not be used.
  bool get allowsParallelizedExport {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.allowsParallelizedExport',
      iOS: (true, null),
      macOS: (false, (14, 0, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_allowsParallelizedExport);
  }

  /// !
  /// @property		allowsParallelizedExport
  /// @abstract		Determines whether or not parallelization can be employed in the export.
  /// @discussion	On select platforms, there may be opportunities to expedite the export by using additional resources in parallel.
  /// If set to YES, export parallelization will be enabled, only if parallelization requirements are met.  There will
  /// be no error signaled if export parallelization is not achievable, and instead the export will proceed as normal
  /// (without parallelization).
  /// If set to NO, export parallelization will not be used.
  set allowsParallelizedExport(bool value) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.setAllowsParallelizedExport:',
      iOS: (true, null),
      macOS: (false, (14, 0, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAllowsParallelizedExport_, value);
  }

  /// status
  AVAssetExportSessionStatus get status {
    objc.checkOsVersionInternal('AVAssetExportSession.status', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_195k4xu(this.ref.pointer, _sel_status);
    return AVAssetExportSessionStatus.fromValue(_ret);
  }

  /// error
  objc.NSError? get error {
    objc.checkOsVersionInternal('AVAssetExportSession.error', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_error);
    return _ret.address == 0 ? null : objc.NSError.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method						exportAsynchronouslyWithCompletionHandler:
  /// @abstract					Starts the asynchronous execution of an export session.
  /// @param						handler
  /// If internal preparation for export fails, the handler will be invoked synchronously.
  /// The handler may also be called asynchronously after -exportAsynchronouslyWithCompletionHandler: returns,
  /// in the following cases:
  /// 1) if a failure occurs during the export, including failures of loading, re-encoding, or writing media data to the output,
  /// 2) if -cancelExport is invoked,
  /// 3) if export session succeeds, having completely written its output to the outputURL.
  /// In each case, AVAssetExportSession.status will signal the terminal state of the asset reader, and if a failure occurs, the NSError
  /// that describes the failure can be obtained from the error property.
  /// @discussion					Initiates an asynchronous export operation and returns immediately.
  void exportAsynchronouslyWithCompletionHandler(objc.ObjCBlock<ffi.Void Function()> handler) {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.exportAsynchronouslyWithCompletionHandler:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_f167m6(this.ref.pointer, _sel_exportAsynchronouslyWithCompletionHandler_, handler.ref.pointer);
  }

  /// progress
  double get progress {
    objc.checkOsVersionInternal('AVAssetExportSession.progress', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_progress)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_progress);
  }

  /// !
  /// @method						cancelExport
  /// @abstract					Cancels the execution of an export session.
  /// @discussion					Cancel can be invoked when the export is running.
  void cancelExport() {
    objc.checkOsVersionInternal(
      'AVAssetExportSession.cancelExport',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_cancelExport);
  }

  /// allocWithZone:
  static AVAssetExportSession allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_AVAssetExportSession, _sel_allocWithZone_, zone);
    return AVAssetExportSession.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static AVAssetExportSession alloc() {
    final _ret = _objc_msgSend_151sglz(_class_AVAssetExportSession, _sel_alloc);
    return AVAssetExportSession.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  AVAssetExportSession self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return AVAssetExportSession.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  AVAssetExportSession retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return AVAssetExportSession.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  AVAssetExportSession autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return AVAssetExportSession.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of AVAssetExportSession constructed with the default `new` method.
  factory AVAssetExportSession() => new$();
}
